{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab9fce2-5707-4a2b-8c79-54299a2894ac",
   "metadata": {},
   "source": [
    "# Shanoir to Fed-BioMed converter - POC 2\n",
    "\n",
    "\n",
    "Goal of the PoC: **provide a way to convert Shanoir dataset folders into Fed-BioMed medical folder dataset**\n",
    "https://notes.inria.fr/HsVQiufgRIGNTZs2umh2DA#\n",
    "\n",
    "**Description of the Shanoir dataset**: in this updated version, we handle a new type of dataset, containing the following specificities:\n",
    "\n",
    "\n",
    "\n",
    "### Structure of  Shanoir Dataset\n",
    "\n",
    "**1. basic Shanoir folder: Shanoir folder containing**:\n",
    "\n",
    " - **1 patient (record done on the 2024-05-03)**\n",
    " - **1 serie**\n",
    " - **several acquisitions constituing a 3d image**\n",
    "\n",
    "   \n",
    "```\n",
    "Fed-BioMed_Example_ShUp_One_DICOM_Study_Phantom/\n",
    "└── 1319E9-238B-11_2024_05_03_13_19_38_651\n",
    "    ├── 1.4.9.12.34.1.8527.4108713574735248556281156520855496517752\n",
    "    │   ├── 1.4.9.12.34.1.8527.1008064111753223271000195301476908655974.dcm\n",
    "    │   ├── 1.4.9.12.34.1.8527.1024888726043321613379622790008460371276.dcm\n",
    "    ...\n",
    "    ├── import-job.json\n",
    "    ├── nominative-data-job.xml\n",
    "    └── upload-job.xml\n",
    "\n",
    "```\n",
    "\n",
    "**2. Another complex dataset, containing**:\n",
    "* **2 patients**\n",
    "* **1 modality each**\n",
    "* **different series regarding the image modality used**\n",
    "\n",
    "```\n",
    "workFolder\n",
    "├── 2032B8-7289-11_2024_08_20_15_19_40_983\n",
    "│   ├── 1.4.9.12.34.1.8527.9190420633949044258273493601325945099590\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1033245378080688965564802929478239431354.dcm\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1036405439974105761803058139139517309811.dcm\n",
    "...\n",
    "│   ├── import-job.json\n",
    "│   ├── nominative-data-job.xml\n",
    "│   └── upload-job.xml\n",
    "├── 8A-118B5-753B5_2024_08_20_15_11_36_849\n",
    "│   ├── 1.4.9.12.34.1.8527.2113412453823604682567869637250601969230\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1017463926793201091226867287913393935142.dcm\n",
    "...\n",
    "│   │   └── 1.4.9.12.34.1.8527.9339932517692019105020851679467540742415.dcm\n",
    "│   ├── 1.4.9.12.34.1.8527.3009454799332674087203494258205245364651\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1000246565108798698400749889204485890049.dcm\n",
    "...\n",
    "│   │   └── 1.4.9.12.34.1.8527.9325608176760251441966417937124838059276.dcm\n",
    "│   ├── 1.4.9.12.34.1.8527.3131876202492289682835393691074293979434\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1109837059386394718736173763001851315204.dcm\n",
    "...\n",
    "│   │   └── 1.4.9.12.34.1.8527.9220051936018747611752876514965567446653.dcm\n",
    "│   ├── 1.4.9.12.34.1.8527.4164112393443258790186552529327488575550\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1137130666940367323865649738623725229183.dcm\n",
    "...\n",
    "│   │   └── 1.4.9.12.34.1.8527.9308443060601907228417563222217683184040.dcm\n",
    "│   ├── 1.4.9.12.34.1.8527.5146138466355875700234504467782152743194\n",
    "│   │   ├── 1.4.9.12.34.1.8527.1239448152484875728572659021360403579923.dcm\n",
    "...\n",
    "│   │   └── 1.4.9.12.34.1.8527.5308747961323743069701581462251244703029.dcm\n",
    "│   ├── import-job.json\n",
    "│   ├── nominative-data-job.xml\n",
    "│   └── upload-job.xml\n",
    "└── tmp\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df987511-a3b6-47af-82d2-8ed0807780c4",
   "metadata": {},
   "source": [
    "**General Assumptions**:\n",
    "\n",
    "1. a patient visit == a patient study\n",
    "2. a single visit per patient (not supporting multiple visits per patients over time)\n",
    "\n",
    "**Difficulties**:\n",
    "1. no notion of `series` in Fed-BioMed\n",
    "2. no notion of `modalities` in Shanoir Dataset\n",
    "3. images difficult to parse from Dicom (Shanoir Dataset) to Niftii (Fed-BioMed) -> how is it done in Shanoir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad5839-85da-410e-ad34-b856665e0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "import matplotlib.pylab as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nibabel\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "# you will also need dcm2niix\n",
    "#!conda install -c conda-forge dcm2niix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be4ac2-1362-42b0-b6b1-d27bc8809678",
   "metadata": {},
   "source": [
    "## 1. Parse Shnoir Folder and get patient information\n",
    "\n",
    "In this section we will try to guess the patient_ids and their modalities given their file name\n",
    "\n",
    "Shanoir dataset specificities:\n",
    "- one patient can have several series\n",
    "- 2 folders can correspond to the same patient (with different modalities)\n",
    "  \n",
    "\n",
    "**NOTA**: date in the folder name doesnot match the one in the seriesDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe128d-e0cd-4e95-851a-72317f94b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shanoir_datasets = {'1': {'name': 'Fed-BioMed_Example_ShUp_One_DICOM_Study_Phantom', 'version': 'v1'},\n",
    "                    '2': {'name': 'Fed-BioMed_Example_ShUp_2', 'version': 'v1'},\n",
    "                   '3': {'name': 'workFolder', 'version': 'v2'} ,\n",
    "                   '4': {'name': 'workFolder_2', 'version': 'v2'},\n",
    "                   '5': {'name': 'workFolder_3', 'version': 'v2'}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ab6df-7be0-4412-8e25-a40ebdeda225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant\n",
    "SHANOIR_DATASET_NUMBER = '5'\n",
    "\n",
    "REMOVE_CORRECTIONS = True\n",
    "TIMEDELTA = timedelta(days=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed0dd8-a991-4787-b5fe-fce3af5d2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# field mapper: created to encompass different way for parsing `import-job.json`, depending on Shanoir dataset versions\n",
    "\n",
    "\n",
    "field_mapper = {'v1': {\n",
    "    'patient_id': lambda demogr: demogr['patients'][0]['patientID'],\n",
    "    'patient_data' : lambda demogr: (demogr['patients'][0]['studies'][0]['series'][i] for i in range(len(demogr['patients'][0]['studies'][0]['series'])))},\n",
    "                'v2': {\n",
    "                    'patient_id': lambda demogr: demogr['subject']['identifier'],\n",
    "                    'patient_data': lambda demogr: (demogr['selectedSeries'][i] for i in range(len(demogr['selectedSeries'])))\n",
    "                }\n",
    "               }\n",
    "\n",
    "# version selected \n",
    "\n",
    "version = shanoir_datasets[SHANOIR_DATASET_NUMBER]['version']\n",
    "\n",
    "# global variables\n",
    "patient_info_func = field_mapper[version]['patient_id']\n",
    "patient_data_func = field_mapper[version]['patient_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e466f2-8651-4660-82a5-9507a43975b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "\n",
    "def list_to_datetime_converter(date: list):\n",
    "    return datetime(date[0], date[1], date[2])\n",
    "\n",
    "def avg_dates(dates: Iterable):\n",
    "  reference_date = datetime(1900, 1, 1)\n",
    "  return str(reference_date + sum([date - reference_date for date in dates], timedelta()) / len(dates))\n",
    "    \n",
    "def get_patient_id_from_file_name(name: str):\n",
    "    \"\"\"Extracts patient_id and date\"\"\"\n",
    "    match = re.search(r'_\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_', name)\n",
    "    if match is None:\n",
    "        print(\"discarding \", name)\n",
    "        return None\n",
    "    patient_id = name[:int(match.span()[0])]\n",
    "    #match_date = re.search(r'\\d{4}_\\d{2}_\\d{2}_\\d{2}_\\d{2}_\\d{2}', match.group())\n",
    "    #date = datetime.strptime(match_date.group(), '%Y_%m_%d_%H_%M_%S')\n",
    "    return patient_id\n",
    "\n",
    "def refine_shanoir_dataset_patients(folder_path:str, time_delta) -> dict:\n",
    "    \"\"\"Detects and refines patients and their modality\n",
    "    Considers that modality belongs to same patient if the folders date are close (less than timedelta arg)\n",
    "    \"\"\"\n",
    "    n_visit = 0\n",
    "    refined_patients = {f't_{n_visit}': {}}\n",
    "    for detected_patient in os.listdir(folder_path):\n",
    "        patient_file_id = get_patient_id_from_file_name(detected_patient)\n",
    "        if patient_file_id is None:\n",
    "            continue\n",
    "        patient_json_id, series = parse_shanoir_json(os.path.join(folder_path, detected_patient, 'import-job.json'))\n",
    "        dates = []\n",
    "        for serie_entry in series:\n",
    "            date = serie_entry['seriesDate']\n",
    "            dates.append(list_to_datetime_converter(date))\n",
    "            \n",
    "        if patient_file_id not in refined_patients[f't_{n_visit}']:\n",
    "                refined_patients[f't_{n_visit}'][patient_file_id] = {'date': dates, 'modalities': [detected_patient]}\n",
    "        else:\n",
    "            check1 = min(dates) - max(refined_patients[f't_{n_visit}'][patient_file_id]['date']) <= time_delta and min(dates) - max(refined_patients[f't_{n_visit}'][patient_file_id]['date']) >= timedelta(0) \n",
    "            check2 = min(refined_patients[f't_{n_visit}'][patient_file_id]['date']) - max(dates) <= time_delta and  min(refined_patients[f't_{n_visit}'][patient_file_id]['date']) - max(dates) >= timedelta(0)\n",
    "            if check1 or check2:\n",
    "                print(\"same patient, different modality detected\")\n",
    "    \n",
    "                refined_patients[f't_{n_visit}'][patient_file_id]['modalities'].append(detected_patient)\n",
    "                refined_patients[f't_{n_visit}'][patient_file_id]['date'].extend(dates)\n",
    "            else:\n",
    "                n_visit += 1\n",
    "                refined_patients[f't_{n_visit}'] = {patient_file_id: {'date': dates, 'modalities': [detected_patient]}}\n",
    "                print(\"same patient, different visit detected\")\n",
    "                print(\"WARNING: several visits for same patient for a given modality is not yet supported by the poc and by Fed-BioMed\")\n",
    "    return refined_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6c5af-be12-4b7b-973a-4f69dd736c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = os.path.join(os.getcwd(), 'data', 'shanoir', shanoir_datasets[SHANOIR_DATASET_NUMBER]['name'])\n",
    "\n",
    "\n",
    "refined_patients = refine_shanoir_dataset_patients(main_folder_path, TIMEDELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2af187-17df-4442-862a-ff0f3c390b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f16bba5-dc08-445a-a14e-8fd7982a9df0",
   "metadata": {},
   "source": [
    "### understanding `import-job.json` structure\n",
    "\n",
    "`import-job.json` is sorted as follows:\n",
    "- `patients` entry holds all the patients considered in the dataset, and their `studies` (*first dataset*)\n",
    "- `studies` entry holds all studies for a given patient. A study has one or several `series` \n",
    "- `series` entry holds one or several patient acquisitions (image data) for a given study. Image data can have several `instances`, which correspond to all files of given patient acquisition. `series` can have different modalities (eg CT, XR, ...)\n",
    "- `subject` entry holds patient details (*second dataset*)\n",
    "- `selectedSeries` holds patient dataset (its `studies`) (*second dataset*)\n",
    "\n",
    "## 2. Creating Fed-BioMed demographics csv file\n",
    "\n",
    "**GENERAL ASSUMPTIONS**\n",
    "\n",
    "we assume that there is only one patient per studies and one study per `import-job.json` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69cc7e-e965-47a3-9fb9-8216361b7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fedbiomed_demographics(shanoir_folder_path: str, refined_patients: dict):\n",
    "    # collect all modalities\n",
    "    modalities_detected = set()\n",
    "    csv_demographics = pd.DataFrame(columns=['patientID',  'date'])  #'protocolName'\n",
    "    \n",
    "    modalities_mapper = {}\n",
    "    demographic_entry = 0\n",
    "    \n",
    "    for patient_file_id, patient_details in refined_patients.items():\n",
    "        # extract information about patient / study from the `import-job.json`\n",
    "        patient_modalities = patient_details['modalities']\n",
    "    \n",
    "        # add patient id\n",
    "        \n",
    "        modalities_mapper.update({patient_file_id: {}})\n",
    "        for patient_modality in patient_modalities:\n",
    "            \n",
    "            patient_id, series = parse_shanoir_json(os.path.join(main_folder_path, patient_modality, 'import-job.json'))\n",
    "            for j, serie_entry in enumerate(series):\n",
    "                \n",
    "                if  modalities_mapper[patient_id].get(serie_entry['modality']) is None:\n",
    "                    modalities_mapper[patient_id][serie_entry['modality']] = []\n",
    "                modalities_mapper[patient_id][serie_entry['modality']].append((serie_entry['seriesInstanceUID'], serie_entry['protocolName'], patient_modality))\n",
    "                modalities_detected.add('modality_' + serie_entry['modality'] + '_' + serie_entry['protocolName'])\n",
    "            \n",
    "                # warning: should not itere over series, since series could be different modalities\n",
    "                #modalities_mapper[patient_id].append((serie_entry['seriesInstanceUID'],  serie_entry['protocolName']))\n",
    "            \n",
    "        csv_demographics.loc[demographic_entry] = [patient_id,  avg_dates(patient_details['date'])]\n",
    "        demographic_entry += 1\n",
    "    return csv_demographics, modalities_mapper, modalities_detected\n",
    "\n",
    "def parse_shanoir_json(import_json_path):\n",
    "\n",
    "    with open(import_json_path, 'r') as f:\n",
    "        demographics = json.load(f)\n",
    "    try:\n",
    "        patient_id = patient_info_func(demographics)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error in `patient_info_func`. Have you used the correct version? Details: \", e)\n",
    "    \n",
    "    try:\n",
    "        series = patient_data_func(demographics)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error in `patient_data_func`. Have you used the correct version? Details: \", e)\n",
    "    return patient_id, series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b0b39-63f4-4a6f-ad14-95095aacc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics, modalities_mapper, modalities_detected = create_fedbiomed_demographics(main_folder_path, refined_patients['t_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd4b09-9e60-4adc-8975-3b52972fb265",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics, modalities_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b72db-e526-4981-8c60-d71eb09c7826",
   "metadata": {},
   "source": [
    "We hence create the demographics csv file for Fed-BioMed medical folder dataset\n",
    "\n",
    "\n",
    "\n",
    "We can have same patientID but with 2 modalities (case where date are different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909fab3-4bf2-4357-b51a-5951a687b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5388fc-a885-4525-9b8a-a233a1678b5e",
   "metadata": {},
   "source": [
    "Display a few layers of the patient MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7550e42-acea-421e-b6e2-01b418512e6d",
   "metadata": {},
   "source": [
    "## 3. Convert dicom images into fedbiomed medical folder\n",
    "\n",
    "### Creating folder to store data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95595dc-7fd8-4dd9-9c0c-90173ad242b3",
   "metadata": {},
   "source": [
    "now we convert the shanoir images into fedbiomed images\n",
    "\n",
    "FedBioMed medical folder dataset  should have the folowing structure:\n",
    "\n",
    "**For Fed-BioMed_Example_ShUp_One_DICOM_Study_Phantom**\n",
    "```\n",
    "├── fbm_medical_folder_dataset\n",
    "        ├── 1319E9-238B-11\n",
    "        │   └── modality_MR_t1_se_tra\n",
    "        │       ├── t1_se_tra.json\n",
    "        │       └── t1_se_tra.nii\n",
    "        └── participants.csv\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "with :\n",
    "\n",
    "- `1319E9-238B-11` being the patient folder\n",
    "- `modality_MR_t1_se_tra` the modality image (in the provided dataset we only have one modailty: MR) with the protocol\n",
    "- `participants.csv` the demographic file\n",
    "\n",
    "**For Fed-BioMed second example**\n",
    "\n",
    "```\n",
    "fbm_medical_folder_dataset_workFolder_2\n",
    "├── 2032B8-7289-11\n",
    "│   └── modality_CT_CRANE_NR\n",
    "│       ├── CRANE_NR.json\n",
    "│       └── CRANE_NR.nii\n",
    "├── 8A-118B5-753B5\n",
    "│   ├── modality_MR_gre_field_mapping\n",
    "│   │   ├── gre_field_mapping_e2_ph.json\n",
    "│   │   └── gre_field_mapping_e2_ph.nii\n",
    "│   ├── modality_MR_localizer\n",
    "│   │   ├── localizer.json\n",
    "│   │   └── localizer.nii\n",
    "│   ├── modality_MR_loca_t2_tse_SAG\n",
    "│   │   ├── loca_t2_tse_SAG.json\n",
    "│   │   └── loca_t2_tse_SAG.nii\n",
    "│   ├── modality_MR_MPRAGE_iso\n",
    "│   │   ├── MPRAGE_iso.json\n",
    "│   │   └── MPRAGE_iso.nii\n",
    "│   └── modality_MR_t2_flair_3d_iso_PRESAT\n",
    "│       ├── t2_flair_3d_iso_PRESAT.json\n",
    "│       └── t2_flair_3d_iso_PRESAT.nii\n",
    "└── participants.csv\n",
    "\n",
    "\n",
    "```\n",
    "Here I name the new nifti image file without dots (`.`), using only the protocol name (due to a [limitation of Fed-BioMed - issue 1105 ](https://github.com/fedbiomed/fedbiomed/issues/1105))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2099195-56c0-48f8-a4b4-fb53dc8a7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_fedbiomed_medical_dataset(medical_folder_dataset_path, demographics, modalities_mapper, remove_corrections: bool = True):\n",
    "    # create demographics file\n",
    "    demographics.to_csv(os.path.join(medical_folder_dataset_path, 'participants.csv'))\n",
    "\n",
    "    for patient_id in modalities_mapper:\n",
    "        patient_folder = os.path.join(medical_folder_dataset_path, patient_id)\n",
    "        os.makedirs(patient_folder, exist_ok=True)\n",
    "        \n",
    "        for modality in modalities_mapper[patient_id]:\n",
    "            for i in range(len(modalities_mapper[patient_id][modality])):\n",
    "                serie, protocol, detected_patient = modalities_mapper[patient_id][modality][i]\n",
    "            \n",
    "                modality_folder = os.path.join(medical_folder_dataset_path, patient_id, f'modality_{modality}_{protocol}')\n",
    "                os.makedirs(modality_folder, exist_ok=True)\n",
    "                print(f\"[LOG] - parsing {os.path.join(main_folder_path, detected_patient, serie)}\")\n",
    "\n",
    "                os.environ['OUTPUT_FOLDER'] =  modality_folder\n",
    "                os.environ['PATIENT_FOLDER'] = os.path.join(main_folder_path, detected_patient, serie)\n",
    "            \n",
    "                !dcm2niix --terse -m y  -f %p -o $OUTPUT_FOLDER $PATIENT_FOLDER\n",
    "                !echo $?\n",
    "                # -y argument is for disabling the flipping\n",
    "                # check if dicom to niftii converter has created several images, and remove the inappropriate one(s)\n",
    "    \n",
    "                if remove_corrections and len(os.listdir(modality_folder)) > 2:\n",
    "                    for file in os.listdir(modality_folder):\n",
    "                        if file.endswith('Tilt_1.nii'):\n",
    "                            # remove gantry tilt file generated\n",
    "                            os.remove(os.path.join(modality_folder, file))\n",
    "                            print(f\"[LOG] file removed: {file}\")\n",
    "                        if file.endswith('Eq_1.nii'):\n",
    "                            # remove file got through equalization (if any)\n",
    "                            os.remove(os.path.join(modality_folder, file))\n",
    "                            print(f\"[LOG] file removed: {file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab29adc-a9d4-4996-8ff1-9230f3803905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove existing Fed-BioMed data folder \n",
    "medical_folder_dataset_path = os.path.join('data', 'shanoir', f'fbm_medical_folder_dataset_{os.path.basename(main_folder_path)}')\n",
    "\n",
    "if os.path.exists(medical_folder_dataset_path):\n",
    "    shutil.rmtree(medical_folder_dataset_path)\n",
    "\n",
    "# create new folder for fedbiomed's medical folder dataset\n",
    "os.makedirs(medical_folder_dataset_path,)\n",
    "\n",
    "\n",
    "create_fedbiomed_medical_dataset(medical_folder_dataset_path, demographics, modalities_mapper, remove_corrections = REMOVE_CORRECTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4ef2e-2a17-4076-a208-a7f50c0bd507",
   "metadata": {},
   "source": [
    "Now we can load the newly created dataset into Fed-BioMed !\n",
    "\n",
    "## 4. Load FedBioMed dataset into Fed-BioMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb256d-1487-4ec8-894a-0c1d326daa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fb808-8248-485c-9d9d-2687860f7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"FEDBIOMED_DIR\"] = '../github/fedbiomed'\n",
    "\n",
    "os.environ[\"FEDBIOMED_DIR\"] = '..'\n",
    "! $FEDBIOMED_DIR/scripts/fedbiomed_run node gui --data-folder $PWD start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc069e06-af7c-4a07-8ced-e046436c4685",
   "metadata": {},
   "source": [
    "**Warning**: the Shanoir dataset `workFolder` has an uncorrect structure: It cannot be loaded in Fed-BioMed due to the fact that patients have different modality each\n",
    "\n",
    "For this dataset, we are going to complete patient dataset by copying data when modality is unavailable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a755a8ee-dc11-4660-9739-86c92f2bc45f",
   "metadata": {},
   "source": [
    "## 3. Open Questions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3db2d5-ff3b-445d-8e0f-56662dd1b613",
   "metadata": {},
   "source": [
    "## Dicom to niftii specificities:\n",
    "\n",
    "- differences in the origins\n",
    "- gantry tilt\n",
    "- distance interslice\n",
    "- localizer edge case (dicom specificities)\n",
    "\n",
    "\n",
    "### differences in the origin\n",
    "\n",
    "**NIFTII**\n",
    "\n",
    "Uses the Tolairach-Tournoux Coordinates\n",
    "- X: Increasing value toward the Right\n",
    "- Y: Increasing value toward the Anterior\n",
    "- Z: Increasing value toward the Superior\n",
    "\n",
    "**DICOM**\n",
    "\n",
    "- X: Increasing value toward the Left\n",
    "- Y: Increasing value toward the Posterior\n",
    "- Z: Increasing value toward the Superior\n",
    "\n",
    "\n",
    "Hence resulting in a 90degree rotation\n",
    "<img src=\"./imgs/300px-Dcm2nii_Mni_v_dicom.jpg\" alt=\"img1\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b5054-d3cc-4bb8-a9d6-9f8f0a34590c",
   "metadata": {},
   "source": [
    "### Gantry tilt\n",
    "An angle formed between x-ray tube plane and the vertical plane. Ranges usualy between [-25degee, 25degree].\n",
    "\n",
    "Useful for a better vizualisation of some features in the human body\n",
    "\n",
    "Dicom has a specific entry for gantry tilt [0018, 1120], whereas NIFTII doesnot handle such case\n",
    "\n",
    "\n",
    "On the image, left is the image with gantry tilt, and right without\n",
    "![img2](./imgs/gantry_tilt.webp)\n",
    "\n",
    "\n",
    "\n",
    "Use of the CT scan with a gantry tilt\n",
    "\n",
    "![img3](./imgs/gantry_tilt_scan.png)\n",
    "\n",
    "\n",
    "\n",
    "**Action**: I would suggest to keep the image without gantry tilt, so size of the niftii images are consistant with ohter dicom images (size will differ with the other images obtained through other modalities, making not possible to use it for )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c63741-31db-42cc-a75b-275b2c351ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoms_gt_folder = 'data/shanoir/workFolder/2032B8-7289-11_2024_08_20_15_19_40_983/1.4.9.12.34.1.8527.9190420633949044258273493601325945099590'\n",
    "dicoms_gt_json = 'data/shanoir/workFolder/2032B8-7289-11_2024_08_20_15_19_40_983/import-job.json'\n",
    "with open(dicoms_gt_json, 'r') as f:\n",
    "    dicoms_gt_details = json.load(f)\n",
    "\n",
    "\n",
    "dicoms_gt = [f for f in os.listdir(dicoms_gt_folder) if f.endswith('.dcm')]\n",
    "niftii_no_gt = 'fbm_medical_folder_dataset_workFolder/2032B8-7289-11/modality_CT_CRANE_NR/CRANE_NR.nii'\n",
    "niftii_gt = 'fbm_medical_folder_dataset_workFolder/2032B8-7289-11/modality_CT_CRANE_NR/CRANE_NR_Tilt_1.nii'\n",
    "\n",
    "niftii_no_gt = nibabel.load(niftii_no_gt)\n",
    "niftii_gt = nibabel.load(niftii_gt)\n",
    "\n",
    "f, axarr = plt.subplots(3, 3)\n",
    "d1 = dicoms_gt_details['selectedSeries'][0]['instances'][0]['sopInstanceUID']\n",
    "d2 = dicoms_gt_details['selectedSeries'][0]['instances'][5]['sopInstanceUID']\n",
    "d3 = dicoms_gt_details['selectedSeries'][0]['instances'][-1]['sopInstanceUID']\n",
    "\n",
    "f.suptitle(\"Gantry tilt handling in dicom and niftii images\", fontweight='semibold')\n",
    "axarr[0,0].imshow(dicom.dcmread(os.path.join(dicoms_gt_folder, d1 + '.dcm')).pixel_array)\n",
    "axarr[0,1].imshow(dicom.dcmread(os.path.join(dicoms_gt_folder, d2 + '.dcm')).pixel_array)\n",
    "axarr[0,2].imshow(dicom.dcmread(os.path.join(dicoms_gt_folder, d3 + '.dcm')).pixel_array)\n",
    "\n",
    "\n",
    "axarr[1, 0].imshow(niftii_no_gt.dataobj[:,:,0])\n",
    "axarr[1,1].imshow(niftii_no_gt.dataobj[:,:,5])\n",
    "axarr[1,2].imshow(niftii_no_gt.dataobj[:,:,-1])\n",
    "\n",
    "axarr[2, 0].imshow(niftii_gt.dataobj[:,:,0])\n",
    "axarr[2,1].imshow(niftii_gt.dataobj[:,:,5])\n",
    "axarr[2,2].imshow(niftii_gt.dataobj[:,:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c90fe3-2553-43d6-a5cd-643958d7b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriving gantry tilt (at [0x0018, 0x1120])\n",
    "for d in (d1, d2, d3):\n",
    "    print(\"gantry tilt value: \", dicom.dcmread(os.path.join(dicoms_gt_folder, d + '.dcm'))[0x0018, 0x1120].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cac0a-0847-4dd0-bf68-472ec6c6b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_shape = max(niftii_no_gt.dataobj.shape, niftii_gt.dataobj.shape)\n",
    "min_shape = min(niftii_no_gt.dataobj.shape, niftii_gt.dataobj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efcad6-26bc-43a6-8a38-d88f49cea807",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 0\n",
    "z = np.zeros((max_shape[0], max_shape[1], 3))\n",
    "\n",
    "v = np.array(niftii_no_gt.dataobj)\n",
    "v.resize(max_shape)\n",
    "z[:,:, 0] = v[:, :, dim]  #red\n",
    "z[:, :, 1] = niftii_gt.dataobj[:, :, dim]  #green\n",
    "\n",
    "\n",
    "plt.imshow(z)\n",
    "plt.title(\"niftii with no gantry tilt correction (red) vs with gantry tilt correction (green)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf43a9-4150-4951-ba30-a755e0fba0f5",
   "metadata": {},
   "source": [
    "## distance insterslice\n",
    "\n",
    "While variation in distance between slice in dicom are accepted, it is not the case in niftii\n",
    "\n",
    "Field \"slice location\" is not compatible with \n",
    "\n",
    "In this case, The converter applies an equalizer to the image (extrapollation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4c240-069e-475c-968a-d25e5451e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dicoms_di_folder = 'workFolder/8A-118B5-753B5_2024_08_20_15_11_36_849/1.4.9.12.34.1.8527.5146138466355875700234504467782152743194'\n",
    "dicoms_di_json = 'workFolder/8A-118B5-753B5_2024_08_20_15_11_36_849/import-job.json'\n",
    "\n",
    "# extracting the import-job.json\n",
    "with open(dicoms_di_json, 'r') as f:\n",
    "    dicoms_di_details = json.load(f)\n",
    "\n",
    "\n",
    "dicoms_di = [f for f in os.listdir(dicoms_di_folder) if f.endswith('.dcm')]\n",
    "niftii_no_eq = 'fbm_medical_folder_dataset_workFolder/8A-118B5-753B5/modality_MR_localizer/localizer.nii'\n",
    "niftii_eq = 'fbm_medical_folder_dataset_workFolder/8A-118B5-753B5/modality_MR_localizer/localizer_Eq_1.nii'\n",
    "\n",
    "niftii_no_eq = nibabel.load(niftii_no_eq)\n",
    "niftii_eq = nibabel.load(niftii_eq)\n",
    "\n",
    "f, axarr = plt.subplots(3, 5)\n",
    "\n",
    "for i in range(5):\n",
    "    d1 = dicoms_di_details['selectedSeries'][0]['instances'][i]['sopInstanceUID']\n",
    "    \n",
    "    \n",
    "    f.suptitle(\"interslice distance dicom and niftii images (equalizer applied or not)\", fontweight='semibold')\n",
    "    axarr[0,i].imshow(dicom.dcmread(os.path.join(dicoms_di_folder, d1 + '.dcm')).pixel_array)\n",
    "    \n",
    "    \n",
    "    #axarr[0, 1].imshow(ds2.pixel_array)\n",
    "    #axarr[0, 2].imshow(ds3.pixel_array)\n",
    "    axarr[1, i].imshow(niftii_no_eq.dataobj[:,:,i])\n",
    "\n",
    "    \n",
    "    axarr[2, i].imshow(niftii_eq.dataobj[:,:,i])\n",
    "    if i == 1:\n",
    "        copied_array = copy.deepcopy(niftii_eq.dataobj[:,:,1])\n",
    "    elif i > 1:\n",
    "        copied_array += niftii_eq.dataobj[:,:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00de3f-a464-4918-b325-23d67004d4ea",
   "metadata": {},
   "source": [
    "Investigating: Getting the slice location for each dicom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a13b2-72d0-480b-bf14-34ffa8e9242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d1 = dicoms_di_details['selectedSeries'][0]['instances'][i]['sopInstanceUID']\n",
    "    print(\"image number\", dicom.dcmread(os.path.join(dicoms_di_folder, d1 + '.dcm'))[0x0020,0x0013].value)\n",
    "    print(\"slice location\", dicom.dcmread(os.path.join(dicoms_di_folder, d1 + '.dcm'))[0x0020,0x1041].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060d542-86b8-42dc-b904-fd8d7fcdc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicoms_gt_folder = 'workFolder/2032B8-7289-11_2024_08_20_15_19_40_983/1.4.9.12.34.1.8527.9190420633949044258273493601325945099590'\n",
    "dicoms_gt_folder = 'workFolder/8A-118B5-753B5_2024_08_20_15_11_36_849/1.4.9.12.34.1.8527.3131876202492289682835393691074293979434'\n",
    "dicoms_gt_json = 'workFolder/8A-118B5-753B5_2024_08_20_15_11_36_849/import-job.json'\n",
    "with open(dicoms_gt_json, 'r') as f:\n",
    "    dicoms_gt_details = json.load(f)\n",
    "\n",
    "dicoms_gt = [f for f in os.listdir(dicoms_gt_folder) if f.endswith('.dcm')]\n",
    "for i, dicom_img in enumerate(dicoms_gt_folder):\n",
    "    d = dicoms_gt_details['selectedSeries'][1]['instances'][i]['sopInstanceUID']\n",
    "    dicom.dcmread(os.path.join(dicoms_gt_folder, d + '.dcm'))\n",
    "    print(\"image number\", dicom.dcmread(os.path.join(dicoms_gt_folder, d + '.dcm'))[0x0020,0x0013].value)\n",
    "    print(\"slice location\", dicom.dcmread(os.path.join(dicoms_gt_folder, d + '.dcm'))[0x0020,0x1041].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076d780-fad3-4f24-8bb9-941b31acf2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoms_gt[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3490cf-ef1d-430a-999f-744eb5f27a04",
   "metadata": {},
   "source": [
    "Other issues:\n",
    "\n",
    "Some of the images in directory are not in the `import-job.json` file: \n",
    "\n",
    "**should we consider them anyway?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165bbaf-b1bb-46e4-88de-b2ceba5a274e",
   "metadata": {},
   "source": [
    "### Localizer edge case\n",
    "\n",
    "Localizer (scout) images are the first scans acquired for any scanning session, and are used to plan the location for subsequent images. Localizers are not used in subsequent analyses (due to resolution, artefacts, etc). Localizers are often acquired with three orthogonal image planes (sagittal, coronal and axial). The NIfTI format requires that all slices in a volume are co-planar, so these localizers will generate naming conflicts. The solution is to use '-i y' which will ignore (not convert) localizers (it will also ignore derived images and 2D slices). This command helps exclude images that are not required for subsequent analyses.\n",
    "\n",
    "This could expalain why localizer data are hard to process.\n",
    "\n",
    "**Should we handle case where images are for localizer?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c79c4f-4f26-4306-9495-6acded74b9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
