{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f742d07",
   "metadata": {},
   "source": [
    "# Fed-BioMed Researcher - Saving and Loading breakpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc415906",
   "metadata": {},
   "source": [
    "This example uses `MNIST` dataset deployed on the nodes. Please see `README` in the notebooks directory for the instructions to load `MNSIT` dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbee69",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44df12",
   "metadata": {},
   "source": [
    "Declare a torch training plan MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the training plan. \n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, }, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa6d68",
   "metadata": {},
   "source": [
    "Let's call ${FEDBIOMED_DIR} the base directory where you cloned Fed-BioMed.\n",
    "Breakpoints will be saved under `Experiment_xxxx` folder at `${FEDBIOMED_DIR}/var/experiments/Experiment_xxxx/breakpoints_yyyy` (by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None,\n",
    "                 save_breakpoints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193d7a3",
   "metadata": {},
   "source": [
    "You can interrupt the `exp.run()` after one round, and then reload the breakpoint and continue the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d750db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f65dee7",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4f7f2",
   "metadata": {},
   "source": [
    "## Delete experiment\n",
    "\n",
    "Here we simulate the removing of the ongoing experiment\n",
    "fret not! we have saved breakpoint, so we can retrieve parameters\n",
    "of the experiment using `load_breakpoint` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1184ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764cd6e",
   "metadata": {},
   "source": [
    "## Resume an experiment\n",
    "\n",
    "While experiment is running, you can shut it down (after the first round) and resume the experiment from the next cell. Or wait for the experiment completion.\n",
    "\n",
    "\n",
    "**To load the latest breakpoint of the latest experiment**\n",
    "\n",
    "Run :\n",
    "`Experiment.load_breakpoint()`. It reloads latest breakpoint, and will bypass `search` method\n",
    "\n",
    "and then use `.run` method as you would do with an existing experiment.\n",
    "\n",
    "**To load a specific breakpoint** specify breakpoint folder.\n",
    "\n",
    "- absolute path: use `Experiment.load_breakpoint(f\"{config.root}/var/experiments/Experiment_xxxx/breakpoint_yyyy\")`. Replace `xxxx` and `yyyy` by the real values.\n",
    "- relative path from a notebook: a notebook is running from the `fbm-researcher/notebooks` directory\n",
    "so use `Experiment.load_breakpoint(\"../../fbm-researcher/var/experiments/Experiment_xxxx/breakpoint_yyyy)`. Replace `xxxx` and `yyyy` by the real values.\n",
    "- relative path from a script: if launching the script from the\n",
    "  default `Researcher` directory (eg: `python fbm-researcher/notebooks/general-breakpoint-save-resume.py`) then use a path relative to the current directory eg: `Experiment.load_breakpoint(f\"../../fbm-researcher/var/experiments/Experiment_xxxx/breakpoint_yyyy\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cff513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "\n",
    "loaded_exp = Experiment.load_breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one can also use relative path\n",
    "from fedbiomed.researcher.config import config\n",
    "Experiment.load_breakpoint(f\"../../fbm-researcher/var/experiments/Experiment_0000/breakpoint_0001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Experimentation folder: {loaded_exp.experimentation_folder()}')\n",
    "print(f'Loaded experiment path: {loaded_exp.experimentation_path()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66af119",
   "metadata": {},
   "source": [
    "Continue training for the experiment loaded from breakpoint. If you ran all the rounds and load the last breakpoint, there won't be any more round to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_exp.run(rounds=3, increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcd35e",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b24d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=loaded_exp\n",
    "print(\"______________ loaded training replies_________________\")\n",
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e16831",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available via `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88498c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", loaded_exp.aggregated_params().keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for training rounds : \")\n",
    "for round in loaded_exp.aggregated_params().keys():\n",
    "  print(\"round {r}\".format(r=round))\n",
    "  print(\"\\t- parameter data: \", loaded_exp.aggregated_params()[round]['params'].keys())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab76e3e624c52aae5e80807d730e4eaa4ecc8ddffbfd9d62b69327b02ed88a35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
