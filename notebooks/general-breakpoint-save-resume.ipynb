{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f742d07",
   "metadata": {},
   "source": [
    "# Fed-BioMed Researcher - Saving and Loading breakpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d9e1e",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc415906",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node start`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbee69",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44df12",
   "metadata": {},
   "source": [
    "Declare a torch training plan MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the training plan. \n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9d1ae",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, }, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa6d68",
   "metadata": {},
   "source": [
    "Define an experiment with saved breakpoints\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds\n",
    "- specify `save_breakpoints` for saving breakpoint at the end of each round.\n",
    "\n",
    "Let's call ${FEDBIOMED_DIR} the base directory where you cloned Fed-BioMed.\n",
    "Breakpoints will be saved under `Experiment_xxxx` folder at `${FEDBIOMED_DIR}/var/experiments/Experiment_xxxx/breakpoints_yyyy` (by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None,\n",
    "                 save_breakpoints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193d7a3",
   "metadata": {},
   "source": [
    "You can interrupt the `exp.run()` after one round, and then reload the breakpoint and continue the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d750db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4f7f2",
   "metadata": {},
   "source": [
    "## Delete experiment\n",
    "\n",
    "Here we simulate the removing of the ongoing experiment\n",
    "fret not! we have saved breakpoint, so we can retrieve parameters\n",
    "of the experiment using `load_breakpoint` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1184ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764cd6e",
   "metadata": {},
   "source": [
    "## Resume an experiment\n",
    "\n",
    "While experiment is running, you can shut it down (after the first round) and resume the experiment from the next cell. Or wait for the experiment completion.\n",
    "\n",
    "\n",
    "**To load the latest breakpoint of the latest experiment**\n",
    "\n",
    "Run :\n",
    "`Experiment.load_breakpoint()`. It reloads latest breakpoint, and will bypass `search` method\n",
    "\n",
    "and then use `.run` method as you would do with an existing experiment.\n",
    "\n",
    "**To load a specific breakpoint** specify breakpoint folder.\n",
    "\n",
    "- absolute path: use `Experiment.load_breakpoint(\"${FEDBIOMED_DIR}/var/experiments/Experiment_xxxx/breakpoint_yyyy)`. Replace `xxxx` and `yyyy` by the real values.\n",
    "- relative path from a notebook: a notebook is running from the `${FEDBIOMED_DIR}/notebooks` directory\n",
    "so use `Experiment.load_breakpoint(\"../var/experiments/Experiment_xxxx/breakpoint_yyyy)`. Replace `xxxx` and `yyyy` by the real values.\n",
    "- relative path from a script: if launching the script from the\n",
    "  ${FEDBIOMED_DIR} directory (eg: `python ./notebooks/general-breakpoint-save-resume.py`) then use a path relative to the current directory eg: `Experiment.load_breakpoint(\"./var/experiments/Experiment_xxxx/breakpoint_yyyy)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cff513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "\n",
    "loaded_exp = Experiment.load_breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Experimentation folder: {loaded_exp.experimentation_folder()}')\n",
    "print(f'Loaded experiment path: {loaded_exp.experimentation_path()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66af119",
   "metadata": {},
   "source": [
    "Continue training for the experiment loaded from breakpoint. If you ran all the rounds and load the last breakpoint, there won't be any more round to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_exp.run(rounds=3, increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"______________ loaded training replies_________________\")\n",
    "print(\"\\nList the training rounds : \", loaded_exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = loaded_exp.training_replies()[rounds - 1].data()\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "loaded_exp.training_replies()[rounds - 1].dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e16831",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available via `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88498c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", loaded_exp.aggregated_params().keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for training rounds : \")\n",
    "for round in loaded_exp.aggregated_params().keys():\n",
    "  print(\"round {r}\".format(r=round))\n",
    "  print(\"\\t- params_path: \", loaded_exp.aggregated_params()[round]['params_path'])\n",
    "  print(\"\\t- parameter data: \", loaded_exp.aggregated_params()[round]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837406a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
