{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c59bed7",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher to train a federated scikit learn model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9d920",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "Binary Classification\n",
    "### Purpose of the exercise :\n",
    "Three datasets `c1.csv` , `c2.csv` and `c3.csv` has been generated with a target column of 2 different classes.\n",
    "We will fit a Perceptron (classifier) using Federated Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a27982",
   "metadata": {},
   "source": [
    "### Get the data \n",
    "\n",
    "We use the make_classification dataset from sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06060ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.make_classification(n_samples=300, n_features=20,n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0,shuffle=True, random_state=123)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = X[:150,:]\n",
    "C2 = X[150:250,:]\n",
    "C3 = X[250:300,:]\n",
    "\n",
    "y1 = y[:150].reshape([150,1])\n",
    "y2 = y[150:250].reshape([100,1])\n",
    "y3 = y[250:300].reshape([50,1])\n",
    "\n",
    "C1.shape ,C2.shape , C3.shape , y1.shape, y2.shape, y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n1 = np.concatenate((C1, y1), axis=1)\n",
    "np.savetxt('path/toc1.csv',n1,delimiter=',')\n",
    "\n",
    "n2 = np.concatenate((C2, y2), axis=1)\n",
    "np.savetxt('path/toc2.csv',n2,delimiter=',')\n",
    "\n",
    "n3 = np.concatenate((C3, y3), axis=1)\n",
    "np.savetxt('path/toc3.csv',n3,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`\n",
    "\n",
    "### Setting the node up\n",
    "Before running this notebook you need to configure 2 nodes: <br/>\n",
    "* **Node 1 :** `./scripts/fedbiomed_run node add`\n",
    "  * Select option 1 to add a csv file to the node\n",
    "  * Choose the name, tags and description of the dataset (you can write 'perp' always and it will be good)\n",
    "  * Pick the c1.csv file in your machine.\n",
    "  * Check that your data has been added in node 1 by executing `./scripts/fedbiomed_run node list`\n",
    "  * Run the node using `./scripts/fedbiomed_run node start`. <br/>\n",
    "\n",
    "* **Node 2 :** Open a second terminal and run ./scripts/fedbiomed_run node add config n2.ini\n",
    "  * Select option 1 to add a csv file to the node\n",
    "  * Choose the name, tags and description of the dataset (you can write 'perp' always and it will be good)\n",
    "  * Pick the c2.csv file in your machine.\n",
    "  * Check that your data has been added in node 2 by executing `./scripts/fedbiomed_run node config n2.ini list `\n",
    "  * Run the node using `./scripts/fedbiomed_run node config n2.ini start`.\n",
    " \n",
    "\n",
    " Wait until you get `Starting task manager`. it means node is online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**model_args** is a dictionnary containing your model arguments, in case of SGDRegressor this will be max_iter and tol.\n",
    "\n",
    "**training_args** is a dictionnary with parameters , related to Federated Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "n_classes = 2\n",
    "\n",
    "model_args = {'max_iter':1000, 'tol': 1e-3 , \n",
    "               'n_features' : n_features, 'n_classes' : n_classes}\n",
    "\n",
    "training_args = {   \n",
    "    'num_updates': 750,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hereafter the template of the class you should provide to Fedbiomed :\n",
    "    \n",
    "**training_data** : you must return here the (X,y) that must be of the same type of \n",
    "your method partial_fit parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedPerceptron\n",
    "from fedbiomed.common.data import DataManager\n",
    "\n",
    "\n",
    "class PerceptronTraining(FedPerceptron):\n",
    "    def training_data(self):\n",
    "        NUMBER_COLS = 20\n",
    "        dataset = pd.read_csv(self.dataset_path,header=None,delimiter=',')\n",
    "        X = dataset.iloc[:,0:NUMBER_COLS].values\n",
    "        y = dataset.iloc[:,NUMBER_COLS]       \n",
    "        return DataManager(dataset=X,target=y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['perp']\n",
    "rounds = 2\n",
    "\n",
    "# search for corresponding datasets across nodes datasets\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=PerceptronTraining,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lets validate the trained model with the test dataset c3.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('path/to/c3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = data.iloc[:,:n_features]\n",
    "y_test = data.iloc[:,n_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "F1 score computed with federated algorithm :\n",
    "\n",
    "For that, we are exporting `exp.aggregated_params()` containing models parameters collected at the end of each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb32ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "loss_metric = f1_score\n",
    "    \n",
    "testing_error = []\n",
    "\n",
    "for i in range(rounds):\n",
    "    fed_model = exp.training_plan().model()\n",
    "    fed_model.coef_ = exp.aggregated_params()[i]['params']['coef_']\n",
    "    fed_model.intercept_ = exp.aggregated_params()[i]['params']['intercept_']\n",
    "    metric = loss_metric(fed_model.predict(X_test),y_test.ravel())\n",
    "    print('F1 score metric: ', metric, )\n",
    "    testing_error.append(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  SGD regressor\n",
    "\n",
    "### Data \n",
    "\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed to solve a federated regression problem with scikit-learn.\n",
    "\n",
    "In this tutorial we are using the wrapper of Fed-BioMed for the SGD regressor (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html).\n",
    "The goal of the notebook is to train a model on a realistic dataset of (synthetic) medical information mimicking the ADNI dataset (http://adni.loni.usc.edu/). \n",
    "\n",
    "### Creating nodes\n",
    "\n",
    "To proceed with the tutorial, we create 3 clients with corresponding dataframes of clinical information in .csv format. Each client has 300 data points composed by several features corresponding to clinical and medical imaging informations. **The data is entirely synthetic and randomly sampled to mimick the variability of the real ADNI dataset**. The training partitions are availables at the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1R39Ir60oQi8ZnmHoPz5CoGCrVIglcO9l/view?usp=sharing\n",
    "\n",
    "The federated task we aim at solve is to predict a clinical variable (the mini-mental state examination, MMSE) from a combination of demographic and imaging features. The regressors variables are the following features:\n",
    "\n",
    "['SEX', 'AGE', 'PTEDUCAT', 'WholeBrain.bl', 'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "\n",
    "and the target variable is:\n",
    "\n",
    "['MMSE.bl']\n",
    "    \n",
    "\n",
    "To create the federated dataset, we follow the standard procedure for node creation/population of Fed-BioMed. \n",
    "After activating the fedbiomed network with the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment network`\n",
    "\n",
    "and \n",
    "\n",
    "`./scripts/fedbiomed_run network`\n",
    "\n",
    "we create a first node by using the commands\n",
    "\n",
    "`source ./scripts/fedbiomed_environment node`\n",
    "\n",
    "`./scripts/fedbiomed_run node start`\n",
    "\n",
    "We then poulate the node with the data of first client:\n",
    "\n",
    "`./scripts/fedbiomed_run node config conf.ini add`\n",
    "\n",
    "Thn, we select option 1 (csv dataset) to add the .csv partition of client 1, by just picking the .csv of client 1. We use `adni` as tag to save the selected dataset. We can further check that the data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "\n",
    "Following the same procedure, we create the other two nodes with the datasets of client 2 and client 3 respectively. To do so, we add and launch a `Node`using others configuration files\n",
    "\n",
    "### Fed-BioMed Researcher\n",
    "\n",
    "We are now ready to start the reseracher enviroment with the command `source ./scripts/fedbiomed_environment researcher`, and open the Jupyter notebook with `./scripts/fedbiomed_run researcher`. \n",
    "\n",
    "We can first query the network for the adni dataset. In this case, the nodes are sharing the respective partitions unsing the same tag `adni`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code for network and data loader of the sklearn SGDRegressor can now be deployed in Fed-BioMed.\n",
    "We first import the necessary module `SGDSkLearnModel` from `fedbiomed`:\n",
    "\n",
    "**__init__** : we add here the needed sklearn libraries\n",
    "       \n",
    "**training_data** : you must return here a tuple (data,targets) that must be of the same type of \n",
    "your method partial_fit parameters. \n",
    "\n",
    "We note that this model performs a common standardization across federated datasets by **centering with respect to the same parameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedSGDRegressor\n",
    "from fedbiomed.common.data import DataManager\n",
    "\n",
    "class SGDRegressorTrainingPlan(FedSGDRegressor):\n",
    "    def training_data(self):\n",
    "        dataset = pd.read_csv(self.dataset_path,delimiter=';')\n",
    "        regressors_col = ['AGE', 'WholeBrain.bl',\n",
    "                          'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "        target_col = ['MMSE.bl']\n",
    "        \n",
    "        # mean and standard deviation for normalizing dataset\n",
    "        # it has been computed over the whole dataset\n",
    "        scaling_mean = np.array([72.3, 0.7, 0.0, 0.0, 0.0, 0.0])\n",
    "        scaling_sd = np.array([7.3e+00, 5.0e-02, 1.1e-02, 1.0e-03, 2.0e-03, 1.0e-03])\n",
    "        \n",
    "        X = (dataset[regressors_col].values-scaling_mean)/scaling_sd\n",
    "        y = dataset[target_col]\n",
    "        return DataManager(dataset=X, target=y.values.ravel())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**model_args** is a dictionary containing your model arguments, in case of SGDRegressor this will be max_iter and tol. n_features is provided to correctly initialize the SGDRegressor coef_ array.\n",
    "\n",
    "**training_args** is a dictionary with parameters related to Federated Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.common.metrics import MetricTypes\n",
    "RANDOM_SEED = 1234\n",
    "\n",
    "\n",
    "model_args = {\n",
    "    'max_iter':2000,\n",
    "    'tol': 1e-5,\n",
    "    'eta0':0.05,\n",
    "    'n_features': 6,\n",
    "    'random_state': RANDOM_SEED\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'num_updates': 5000,\n",
    "    'test_ratio':.3,\n",
    "    'test_metric': MetricTypes.MEAN_SQUARE_ERROR,\n",
    "    'test_on_local_updates': True,\n",
    "    'test_on_global_updates': True\n",
    "}"
   ],
  },
  {
   "cell_type": "markdown",
   "source": [
    "The experiment can be now defined, by providing the `adni` tag, and running the local training on nodes with model defined in `model_path`, standard `aggregator` (FedAvg) and `client_selection_strategy` (all nodes used). Federated learning is going to be perfomed through 10 optimization rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['adni']\n",
    "\n",
    "# Add more rounds for results with better accuracy\n",
    "#\n",
    "#rounds = 40\n",
    "rounds = 2\n",
    "\n",
    "# select nodes participating to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SGDRegressorTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start federated training\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.aggregated_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fed_model = exp.training_plan().model()\n",
    "fed_model.intercept_ = exp.aggregated_params()[rounds-1]['params']['intercept_']\n",
    "fed_model.coef_ = exp.aggregated_params()[rounds-1]['params']['coef_']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGDClassifier\n",
    "### Purpose of the exercise :\n",
    "\n",
    "Three datasets `c1_3class.csv` , `c2_3class.csv` and `c3_3class.csv` has been generated with a target column of 3 different classes.\n",
    "We will fit a SGCClassifier (classifier) using Federated Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the data \n",
    "\n",
    "We use the make_classification dataset from sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X,y = datasets.make_classification(n_samples=300, n_features=20,n_informative = 3, n_classes=3,n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0,shuffle=True, random_state=123)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "C1 = X[:150,:]\n",
    "C2 = X[150:250,:]\n",
    "C3 = X[250:300,:]\n",
    "\n",
    "y1 = y[:150].reshape([150,1])\n",
    "y2 = y[150:250].reshape([100,1])\n",
    "y3 = y[250:300].reshape([50,1])\n",
    "\n",
    "C1.shape ,C2.shape , C3.shape , y1.shape, y2.shape, y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n1 = np.concatenate((C1, y1), axis=1)\n",
    "np.savetxt('path/to/c1_3class.csv',n1,delimiter=',')\n",
    "\n",
    "n2 = np.concatenate((C2, y2), axis=1)\n",
    "np.savetxt('path/to/c2_3class.csv',n2,delimiter=',')\n",
    "\n",
    "n3 = np.concatenate((C3, y3), axis=1)\n",
    "np.savetxt('path/to/c3_3class.csv',n3,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`\n",
    "\n",
    "### Setting the node up\n",
    "Before running this notebook you need to configure 2 nodes: <br/>\n",
    "* **Node 1 :** `./scripts/fedbiomed_run node add`\n",
    "  * Select option 1 to add a csv file to the node\n",
    "  * Choose the name, tags and description of the dataset (you can write **'perp1'** always and it will be good)\n",
    "  * Pick the c1.csv file in your machine.\n",
    "  * Check that your data has been added in node 1 by executing `./scripts/fedbiomed_run node list`\n",
    "  * Run the node using `./scripts/fedbiomed_run node start`. <br/>\n",
    "\n",
    "* **Node 2 :** Open a second terminal and run ./scripts/fedbiomed_run node add config n2.ini\n",
    "  * Select option 1 to add a csv file to the node\n",
    "  * Choose the name, tags and description of the dataset (you can write **'perp1'** always and it will be good)\n",
    "  * Pick the c2.csv file in your machine.\n",
    "  * Check that your data has been added in node 2 by executing `./scripts/fedbiomed_run node config n2.ini list `\n",
    "  * Run the node using `./scripts/fedbiomed_run node config n2.ini start`.\n",
    " \n",
    "\n",
    " Wait until you get `Starting task manager`. it means node is online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**model_args** is a dictionnary containing your model arguments, in case of SGDRegressor this will be max_iter and tol.\n",
    "\n",
    "**training_args** is a dictionnary with parameters , related to Federated Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_features = 20\n",
    "n_classes = 3\n",
    "\n",
    "model_args = {'max_iter':1000, 'tol': 1e-3 , \n",
    "               'n_features' : n_features, 'n_classes' : n_classes}\n",
    "\n",
    "training_args = {   \n",
    "    'num_updates': 750,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hereafter the template of the class you should provide to Fedbiomed :\n",
    "    \n",
    "**training_data** : you must return here the (X,y) that must be of the same type of \n",
    "your method partial_fit parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedSGDClassifier\n",
    "from fedbiomed.common.data import DataManager\n",
    "\n",
    "\n",
    "class SGDClassifierTrainingPlan(FedSGDClassifier):\n",
    "    def training_data(self):\n",
    "        NUMBER_COLS = 20\n",
    "        dataset = pd.read_csv(self.dataset_path,header=None,delimiter=',')\n",
    "        X = dataset.iloc[:,0:NUMBER_COLS].values\n",
    "        y = dataset.iloc[:,NUMBER_COLS]       \n",
    "        return DataManager(dataset=X,target=y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['perp1']\n",
    "rounds = 2\n",
    "\n",
    "# search for corresponding datasets across nodes datasets\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SGDClassifierTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254e59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5213ef5-c98f-4e17-8e9e-de47446fe3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('path/to/c3_3class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fb760-d724-4aca-a562-657a31f59430",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.iloc[:,:n_features]\n",
    "y_test = data.iloc[:,n_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45801cb4-d281-4941-adc3-2d26090fc9e6",
   "metadata": {},
   "source": [
    "F1 score computed with federated algorithm :\n",
    "\n",
    "For that, we are exporting `exp.aggregated_params()` containing models parameters collected at the end of each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8610a-97d1-460b-8bab-54f778876b6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "loss_metric = f1_score\n",
    "    \n",
    "testing_error = []\n",
    "\n",
    "for i in range(rounds):\n",
    "    fed_model = exp.training_plan().model()\n",
    "    fed_model.coef_ = exp.aggregated_params()[i]['params']['coef_']\n",
    "    fed_model.intercept_ = exp.aggregated_params()[i]['params']['intercept_']\n",
    "    print(f'Model trained in round {i}')\n",
    "    print('-------------------------')\n",
    "    print(classification_report(y_test, fed_model.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178d3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
