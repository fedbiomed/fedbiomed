{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb2f0eb-dc70-4a75-9535-228957f176e5",
   "metadata": {},
   "source": [
    "# Declearn Optimizers with Scikit learn \n",
    "\n",
    "## 1. Perceptron Classifier\n",
    "Below we showcase an example of a Perceptron Classifier with the MNIST dataset.\n",
    "\n",
    "See introduction notebooks for instructions on setup of MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d4a034-8623-4185-8d84-8a2d345bb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedPerceptron\n",
    "from fedbiomed.common.data import DataManager\n",
    "import numpy as np\n",
    "\n",
    "from fedbiomed.common.optimizers import Optimizer\n",
    "from fedbiomed.common.optimizers.declearn import AdamModule, FedProxRegularizer\n",
    "\n",
    "class SkLearnClassifierTrainingPlan(FedPerceptron):\n",
    "    def init_dependencies(self):\n",
    "        \"\"\"Define additional dependencies.\n",
    "        \n",
    "        In this case, we rely on torchvision functions for preprocessing the images.\n",
    "        \"\"\"\n",
    "        return [\"from torchvision import datasets, transforms\",\n",
    "                \"from fedbiomed.common.optimizers import Optimizer\",\n",
    "                \"from fedbiomed.common.optimizers.declearn import AdamModule, FedProxRegularizer\",]\n",
    "\n",
    "    def training_data(self):\n",
    "        \"\"\"Prepare data for training.\n",
    "        \n",
    "        This function loads a MNIST dataset from the node's filesystem, applies some\n",
    "        preprocessing and converts the full dataset to a numpy array. \n",
    "        Finally, it returns a DataManager created with these numpy arrays.\n",
    "        \"\"\"\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        \n",
    "        X_train = dataset.data.numpy()\n",
    "        X_train = X_train.reshape(-1, 28*28)\n",
    "        Y_train = dataset.targets.numpy()\n",
    "        return DataManager(dataset=X_train, target=Y_train,  shuffle=False)\n",
    "    \n",
    "    # Defines and return a declearn optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return Optimizer(lr=.1 ,modules=[AdamModule()], regularizers=[FedProxRegularizer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf51bd8-8810-49ce-a1b2-309b691576fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {'n_features': 28*28,\n",
    "              'n_classes' : 10,\n",
    "              'eta0':1e-6,\n",
    "              'random_state':1234,\n",
    "              'alpha':0.1 }\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 3, \n",
    "    'batch_maxnum': 20,  # can be used to debugging to limit the number of batches per epoch\n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "#    'log_interval': 1,  # output a logging message every log_interval batches\n",
    "    'loader_args': { 'batch_size': 4, }, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ebe8b-fff7-491c-b22b-7ef857e8fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 3\n",
    "\n",
    "# select nodes participating in this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SkLearnClassifierTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49ef42-1414-4801-8659-9b07eba41649",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033d08d",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e87007",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. SGD Regressor\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed to solve a federated regression problem with scikit-learn, using declearn optimizers. This tutorial uses Adni Dataset. Please see README in the main notebooks directory to load Adni dataset into nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5411d74",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fed-BioMed Researcher\n",
    "\n",
    "We are now ready to start the reseracher enviroment with the command `source ./scripts/fedbiomed_environment researcher`, and open the Jupyter notebook with `./scripts/fedbiomed_run researcher start`. \n",
    "\n",
    "We can first query the network for the adni dataset. In this case, the nodes are sharing the respective partitions unsing the same tag `adni`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd2a0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "from fedbiomed.researcher.config import config\n",
	"req = Requests(config)\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729cfee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import FedSGDRegressor\n",
    "from fedbiomed.common.data import DataManager\n",
    "\n",
    "from fedbiomed.common.optimizers import Optimizer\n",
    "from fedbiomed.common.optimizers.declearn import AdamModule, FedProxRegularizer\n",
    "\n",
    "\n",
    "class SGDRegressorTrainingPlan(FedSGDRegressor):\n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "                \"from declearn.optimizer import Optimizer\",\n",
    "                \"from fedbiomed.common.optimizers.declearn import AdamModule\",\n",
    "                \"from fedbiomed.common.optimizers.declearn import FedProxRegularizer\"]\n",
    "        return deps\n",
    "\n",
    "    def training_data(self):\n",
    "        dataset = pd.read_csv(self.dataset_path, delimiter='[;,]')\n",
    "        regressors_col = ['AGE', 'WholeBrain.bl',\n",
    "                          'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "        target_col = ['MMSE.bl']\n",
    "        \n",
    "        # mean and standard deviation for normalizing dataset\n",
    "        # it has been computed over the whole dataset\n",
    "        scaling_mean = np.array([72.3, 0.7, 0.0, 0.0, 0.0, 0.0])\n",
    "        scaling_sd = np.array([7.3e+00, 5.0e-02, 1.1e-02, 1.0e-03, 2.0e-03, 1.0e-03])\n",
    "        \n",
    "        X = (dataset[regressors_col].values-scaling_mean)/scaling_sd\n",
    "        y = dataset[target_col]\n",
    "        return DataManager(dataset=X, target=y.values.ravel(),  shuffle=True)\n",
    "\n",
    "    # Defines and return a declearn optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return Optimizer(lrate=.1 ,modules=[AdamModule()], regularizers=[FedProxRegularizer()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177db3bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**model_args** is a dictionary containing your model arguments, in case of SGDRegressor this will be max_iter and tol. n_features is provided to correctly initialize the SGDRegressor coef_ array.\n",
    "\n",
    "**training_args** is a dictionary with parameters related to Federated Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4007f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.metrics import MetricTypes\n",
    "RANDOM_SEED = 1234\n",
    "\n",
    "\n",
    "model_args = {\n",
    "    'max_iter':2000,\n",
    "    'tol': 1e-5,\n",
    "    'eta0':0.05,\n",
    "    'n_features': 6,\n",
    "    'random_state': RANDOM_SEED\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 5,\n",
    "    'loader_args': { 'batch_size': 32, },\n",
    "    'test_ratio':.3,\n",
    "    'test_metric': MetricTypes.MEAN_SQUARE_ERROR,\n",
    "    'test_on_local_updates': True,\n",
    "    'test_on_global_updates': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1341",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['adni']\n",
    "\n",
    "# Add more rounds for results with better accuracy\n",
    "#\n",
    "#rounds = 40\n",
    "rounds = 5\n",
    "\n",
    "# select nodes participating to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SGDRegressorTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff55da",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start federated training\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ecfab",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d5026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2a782",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing the Regressor model\n",
    "\n",
    "Once the federated model is obtained, it is possible to test it locally on an independent testing partition.\n",
    "The test dataset is available at this link:\n",
    "\n",
    "https://drive.google.com/file/d/1zNUGp6TMn6WSKYVC8FQiQ9lJAUdasxk1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5335f2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d9b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Download the testing dataset on the local temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500a4f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fedbiomed.common.constants import ComponentType\n",
    "from fedbiomed.researcher.config import config\n",
    "\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=19kxuI146WA2fhcOU2_AvF8dy-ppJkzW7\"\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory(dir=config.vars['TMP_DIR'])\n",
    "base_dir = tmpdir.name\n",
    "\n",
    "test_file = os.path.join(base_dir, \"test_data.zip\")\n",
    "gdown.download(resource, test_file, quiet=False)\n",
    "\n",
    "zf = zipfile.ZipFile(test_file)\n",
    "\n",
    "for file in zf.infolist():\n",
    "    zf.extract(file, base_dir)\n",
    "\n",
    "# loading testing dataset\n",
    "test_data = pd.read_csv(os.path.join(base_dir,'adni_validation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f579d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73be6dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb078c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we extract the relevant regressors and target from the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca90a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "regressors_col = ['AGE', 'WholeBrain.bl', 'Ventricles.bl',\n",
    "                  'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "target_col = ['MMSE.bl']\n",
    "X_test = test_data[regressors_col].values\n",
    "y_test = test_data[target_col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6d380",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To inspect the model evolution across FL rounds, we export `exp.aggregated_params()` containing models parameters collected at the end of each round. The MSE (Mean Squarred Error) should be decreasing at each iteration with the federated parameters obtained at each round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb32ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaling_mean = np.array([72.3, 0.7, 0.0, 0.0, 0.0, 0.0])\n",
    "scaling_sd = np.array([7.3e+00, 5.0e-02, 1.1e-02, 1.0e-03, 2.0e-03, 1.0e-03])\n",
    "\n",
    "testing_error = []\n",
    "\n",
    "\n",
    "# we create here several instances of SGDRegressor using same sklearn arguments\n",
    "# we have used for Federated Learning training\n",
    "fed_model = exp.training_plan().model()\n",
    "regressor_args = {key: model_args[key] for key in model_args.keys() if key in fed_model.get_params().keys()}\n",
    "\n",
    "for i in range(rounds):\n",
    "    fed_model.coef_ = exp.aggregated_params()[i]['params']['coef_'].copy()\n",
    "    fed_model.intercept_ = exp.aggregated_params()[i]['params']['intercept_'].copy()  \n",
    "    mse = np.mean((fed_model.predict((X_test-scaling_mean)/scaling_sd) - y_test)**2)\n",
    "    testing_error.append(mse)\n",
    "\n",
    "plt.plot(testing_error)\n",
    "plt.title('FL testing loss')\n",
    "plt.xlabel('FL round')\n",
    "plt.ylabel('testing loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60406da1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We finally inspect the predictions of the final federated model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191befa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = fed_model.predict((X_test-scaling_mean)/scaling_sd)\n",
    "plt.scatter(y_predicted, y_test, label='model prediction')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('target')\n",
    "plt.title('Federated model testing prediction')\n",
    "\n",
    "first_diag = np.arange(np.min(y_test.flatten()),\n",
    "                       np.max(y_test.flatten()+1))\n",
    "plt.scatter(first_diag, first_diag, label='correct Target')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e398dcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = X_test / scaling_sd\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7af803",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b38c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test[:,1] / scaling_sd[1] - a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff686e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
