{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8321db",
   "metadata": {},
   "source": [
    "This notebook was created as an example to use Federated Learning on GWAS data. \n",
    "\n",
    "It specifically uses Polygenic Risk Scores (PRS) accompanied with demographical non-genetic data to calculate the likelihood of an individual getting diagnosed with a specific disease. Data is collected for a variety of diseases with multiple different methods. This specific example uses the data obtained by LDpred2 (Linkage Disequilibrium matrix) method for a patients likelihood for CAD (Coronary Artery Disease).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774af36",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fea6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import utilities as util\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8d74a",
   "metadata": {},
   "source": [
    "Load the Polygenic Risk Score and Non-genetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628231ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### user input params\n",
    "PRS_score_path = './PRS'\n",
    "non_genetic_data_path = './non_genetic_data'\n",
    "label_path = './eid_label'\n",
    "category_list =['primary_demographics','lifestyle','physical_measures']#'physical_measures' 'lifestyle'\n",
    "disease = 'CAD'\n",
    "PRS_Method = 'LDpred2'# DBSLMM, SBLUP, PRSice2, P+T, LDpred2\n",
    "save_dir = './PRSIMD_results_MRfactors'\n",
    "\n",
    "# Display the disease being studied\n",
    "print(\"Disease being studied:\", disease)\n",
    "\n",
    "# Display the method used for PRS calculation\n",
    "print(\"PRS Method used:\", PRS_Method)# Concatenate score, non_genetic_data, and label into a single DataFrame and save as CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef92329",
   "metadata": {},
   "source": [
    "*(Optional)* Parse and print some information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(PRS_score_path, PRS_Method, Disease,non_genetic_data_path, label_path, category_list):\n",
    "    score_dict = {}\n",
    "    non_genetic_data_dict = {}\n",
    "    label_dict = {}\n",
    "    valt = {'train':'train','validation':'val', 'test':'test'}\n",
    "    for _set in ['train','validation','test']:\n",
    "        score, _ = util.readbyLines(os.path.join(PRS_score_path, _set + '_score_' + PRS_Method + '_' + Disease + '.txt'),datatype=\"float\")\n",
    "        score_dict[_set] =  Variable(torch.FloatTensor(score))\n",
    "        \n",
    "        collect = []\n",
    "        for categ in category_list:\n",
    "            collect.append( pd.read_table(os.path.join(non_genetic_data_path, 'data_mat', Disease.lower(), categ + '_' + valt[_set] + '_data.txt')))\n",
    "            data = pd.concat(collect, axis=1)\n",
    "            data['Age when attended assessment centre'] /= 10 # used age group\n",
    "            data['Age when attended assessment centre'] = data['Age when attended assessment centre'].astype('int')\n",
    "        #non_genetic_data_dict[_set] = Variable(torch.FloatTensor(data))\n",
    "        non_genetic_data_dict[_set] = data\n",
    "      \n",
    "        y = pd.read_table(os.path.join(label_path, Disease.lower()+'_' + valt[_set] + '_y.txt'),header=None).values.ravel()      \n",
    "        label_dict[_set] = Variable(torch.LongTensor(y.astype('long'))) \n",
    "    \n",
    "    return score_dict, non_genetic_data_dict, label_dict\n",
    "\n",
    "score, non_genetic_data, label = loading_data(PRS_score_path, PRS_Method, Disease, non_genetic_data_path, label_path, category_list)\n",
    "\n",
    "# Load the Polygenic Risk Score and Non-genetic Data\n",
    "print(\"PRS score and non-genetic data loaded successfully.\")\n",
    "# Display the first few rows of the loaded data\n",
    "print(\"PRS Score (train):\", score['train'][:5])\n",
    "print(\"Non-genetic data (train):\", non_genetic_data['train'].head())\n",
    "# Display the labels for the training set\n",
    "print(\"Labels (train):\", label['train'][:5])\n",
    "\n",
    "# Display the shape of the loaded data\n",
    "print(\"Shape of PRS score (train):\", score['train'].shape)\n",
    "print(\"Shape of non-genetic data (train):\", non_genetic_data['train'].shape)\n",
    "print(\"Shape of labels (train):\", label['train'].shape)\n",
    "# Display the categories of non-genetic data\n",
    "print(\"Categories of non-genetic data:\", category_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bbbd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_info_for_model_construction(non_genetic_data, Disease, non_genetic_data_path, category_list):    \n",
    "    collect = []\n",
    "    for cate in category_list:\n",
    "        collect.append(pd.read_table(os.path.join(non_genetic_data_path, Disease.lower()+'_'+cate+'.txt')))\n",
    "    df_factors_infor = pd.concat(collect,axis=0)\n",
    "    n_factors = df_factors_infor.shape[0]\n",
    "    \n",
    "    # get the info for model initialization\n",
    "    col_name = non_genetic_data['train'].columns.values\n",
    "    n_cols_factor = [] # the number of columns that each factor data accounted\n",
    "    count = 0\n",
    "    for name in df_factors_infor['field_name'].values:  \n",
    "        for col in col_name:\n",
    "            tmp = col.split(':')   \n",
    "            if name == tmp[0]:\n",
    "                count+=1\n",
    "      \n",
    "        n_cols_factor.append(count)\n",
    "        count = 0\n",
    "                   \n",
    "    return n_factors, n_cols_factor\n",
    "\n",
    "n_factors, n_cols_factor = get_data_info_for_model_construction(non_genetic_data, Disease, non_genetic_data_path, category_list)\n",
    "\n",
    "# Display the number of factors and their column counts\n",
    "print(\"Number of factors:\", n_factors)\n",
    "print(\"Number of columns for each factor:\", n_cols_factor)\n",
    "print(\"Double check the sum of factors:\", sum(n_cols_factor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4917eea",
   "metadata": {},
   "source": [
    "Generate the merged CSV file to add to our hospital node.\n",
    "\n",
    "In this example, the CSV and the node is already generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea901b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate score, non_genetic_data, and label into a single DataFrame and save as CSV\n",
    "\n",
    "# Example for the 'train' set; repeat for 'validation' and 'test' as needed\n",
    "score_df = pd.DataFrame(score['train'].numpy(), columns=['PRS_score'])\n",
    "label_df = pd.DataFrame(label['train'].numpy(), columns=['target'])\n",
    "merged_df = pd.concat([score_df.reset_index(drop=True), non_genetic_data['train'].reset_index(drop=True), label_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "merged_df.to_csv('train_merged.csv', index=False)\n",
    "print('Merged CSV saved as train_merged.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49749b4a",
   "metadata": {},
   "source": [
    "Define the Training Plan with the customized Logistic Regression Model\n",
    "\n",
    "***(TODO)*** Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8d87c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "\n",
    "class LogisticRegressionTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    # model for the genetic factor\n",
    "    class logistic_regression_model(nn.Module):\n",
    "        def __init__(self, disease, n_factors, n_cols_factor):\n",
    "            super().__init__()\n",
    "            \n",
    "            # self.w = nn.Parameter(torch.FloatTensor(torch.randn(2,1))) \n",
    "            # self.b = nn.Parameter(torch.FloatTensor(torch.randn(2,1))) \n",
    "            \n",
    "            self.w = nn.Parameter(torch.FloatTensor(torch.randn(1,1))) \n",
    "            self.b = nn.Parameter(torch.FloatTensor(torch.randn(1,1))) \n",
    "\n",
    "\n",
    "            self.activation = torch.tanh\n",
    "            self.disease = disease\n",
    "            self.n_factors = n_factors\n",
    "            self.n_cols_factor = n_cols_factor\n",
    "            \n",
    "            n_cols = np.sum(self.n_cols_factor)       \n",
    "            self.W = nn.Parameter(torch.FloatTensor(torch.randn(2, n_cols)))       \n",
    "            self.Gamma = nn.Parameter(torch.FloatTensor(torch.randn(2, n_factors+1))) \n",
    "            \n",
    "        def forward(self, f_data):\n",
    "            \n",
    "            score = f_data[:, 0]\n",
    "            f_data = f_data[:, 1:]  # Exclude the score column\n",
    "\n",
    "            logit_out = 1/(1+torch.exp(-(self.w * score + self.b))) \n",
    "            ne_logit_out = 1-logit_out\n",
    "            # logit_genetic = torch.cat((ne_logit_out,logit_out),dim=0)\n",
    "            logit_genetic = torch.stack((ne_logit_out, logit_out), dim=1)\n",
    "\n",
    "\n",
    "            # f_data is the non-genetic data, which is a 2D tensor of shape (batch_size, n_cols)\n",
    "            f_data = f_data.unsqueeze(1)\n",
    "            f_data = f_data.repeat(1,2,1)\n",
    "            eleW_product = self.W * f_data # (n_classes, n_cols) * (batch_size, n_classes, n_cols) \n",
    "            \n",
    "            start = 0     \n",
    "            phi_collect = []       \n",
    "            for i in self.n_cols_factor:\n",
    "                \n",
    "                one_factor = eleW_product[:,:, start: start+i]\n",
    "            \n",
    "                if one_factor.shape[2] > 1:\n",
    "                    one_factor = torch.sum(one_factor, dim=2)\n",
    "                else:\n",
    "                    one_factor = one_factor.squeeze(2)\n",
    "                phi_collect.append(one_factor)\n",
    "                \n",
    "                start += i\n",
    "            \n",
    "            \n",
    "            phi = torch.stack(phi_collect,dim=2)  \n",
    "            phi = self.activation(phi)\n",
    "            phi_bias = torch.ones(phi.shape[0],phi.shape[1],1)\n",
    "            phi = torch.cat((phi, phi_bias),dim=2)\n",
    "\n",
    "            Gamma_times_Phi = self.Gamma * phi\n",
    "            \n",
    "            temp = torch.sum(Gamma_times_Phi, dim=2)\n",
    "            temp = torch.exp(temp)\n",
    "            temp_sum = torch.sum(temp, dim=1)\n",
    "            temp_sum = temp_sum.unsqueeze(1)    \n",
    "            temp_sum = temp_sum.repeat(1,2)     \n",
    "            logit_non_genetic = temp / temp_sum\n",
    "        \n",
    "            return (logit_genetic*0.5 + logit_non_genetic*0.5)\n",
    "\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "                \"from torchvision.transforms import ToTensor\",\n",
    "                'from torch.optim import Adam, AdamW, SGD',\n",
    "                \"import torch.nn.functional as F\",\n",
    "                \"import pandas as pd\",\n",
    "                \"import numpy as np\",\n",
    "                ]\n",
    "\n",
    "        return deps\n",
    "    \n",
    "    def init_model(self, model_args: dict):\n",
    "        \"\"\"Defines your model here\"\"\"\n",
    "        model = self.logistic_regression_model(disease=model_args.get('disease', 'CAD'), \n",
    "                                                n_factors=model_args.get('n_factors', 32), \n",
    "                                                n_cols_factor=model_args.get('n_cols_factor', [1, 1, 3, 2, 2, 5, 2, 1, 2, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])    \n",
    "                                                )       \n",
    "        return model\n",
    "    \n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        \"\"\"Defines your optimizer here\"\"\"\n",
    "        optimizer = Adam(self.model().parameters(), \n",
    "                         weight_decay = optimizer_args.get('weight_decay', 0.0001), \n",
    "                         amsgrad = optimizer_args.get('amsgrad', True))\n",
    "        return optimizer\n",
    "\n",
    "    def training_data(self):\n",
    "        \"\"\"Defines data handling/parsing here\"\"\"\n",
    "        dataset = pd.read_csv(self.dataset_path, delimiter=',')\n",
    "\n",
    "        cols_except_last = dataset.columns[:-1].tolist()\n",
    "        regressors_col = cols_except_last\n",
    "        target_col = ['target']\n",
    "\n",
    "        return DataManager(dataset=dataset[regressors_col], target=dataset[target_col])\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        \"\"\"Defines cost function and how to compute loss\"\"\"\n",
    "        predictions = self.model().forward(data)\n",
    "        logistic_re_loss = F.cross_entropy(predictions, target)\n",
    "        return logistic_re_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58a285",
   "metadata": {},
   "source": [
    "Define the Model and Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and training arguments\n",
    "\n",
    "model_args = {\n",
    "    # 'disease': disease,\n",
    "    # 'n_factors': n_factors,\n",
    "    # 'n_cols_factor': n_cols_factor,\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { \n",
    "        'batch_size': 128, \n",
    "    },\n",
    "    'optimizer_args': {\n",
    "        'weight_decay': 0.0001,\n",
    "        'amsgrad': True,\n",
    "    },\n",
    "    #'num_updates': 2,\n",
    "    'epochs': 300,\n",
    "    'dry_run': False,\n",
    "    'log_interval': 10,\n",
    "    'test_ratio' : 0.1,\n",
    "    'test_on_global_updates': True,\n",
    "    'test_on_local_updates': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e87e64",
   "metadata": {},
   "source": [
    "Define and Run the experiment with Polygenic Risk Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99f0b1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-07-17 17:41:13,628 fedbiomed INFO - Starting researcher service..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2025-07-17 17:41:13,630 fedbiomed INFO - Waiting 3s for nodes to connect..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2025-07-17 17:41:13,631 fedbiomed ERROR - Researcher gRPC server has stopped. Please try to restart: Failed to bind to address localhost:50051; set GRPC_VERBOSITY=debug environment variable to see detailed error message."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Fed-BioMed researcher stopped due to exception:\n",
      "ErrorNumbers.FB628: Error while getting all nodes connected:  Communication client is not initialized.\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "FedbiomedSilentTerminationError",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    },
    {
     "data": {
      "text/plain": [
       "2025-07-18 08:47:32,622 fedbiomed WARNING - Node NODE_25b7ce16-eb31-4fd3-a13e-11953cc11422 is disconnected. Request/task that are created for this node will be flushed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['lr_train']\n",
    "num_rounds = 5\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=LogisticRegressionTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 tensorboard=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logistic-regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
