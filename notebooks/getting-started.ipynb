{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Connected with result code 0`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:42:51,751 fedbiomed INFO - Component environment:\n",
      "2021-12-07 10:42:51,752 fedbiomed INFO - - type = ComponentType.RESEARCHER\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+'/')\n",
    "model_file = tmp_dir_model.name + '/class_export_mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : write **only** the code to export in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /user/scansiz/home/Desktop/Inria/development/MR/fedbiomed/var/tmp/tmpnrjge6lr/class_export_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "               \"from torch.utils.data import DataLoader\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:43:02,064 fedbiomed INFO - Messaging researcher_de471b3b-10f9-4849-8a9b-b6c60cccebef successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x7f86536e8580>\n",
      "2021-12-07 10:43:02,090 fedbiomed INFO - Searching dataset with data tags: ['#MNIST', '#dataset'] for all nodes\n",
      "2021-12-07 10:43:02,093 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / DEBUG - Message received: {'researcher_id': 'researcher_de471b3b-10f9-4849-8a9b-b6c60cccebef', 'tags': ['#MNIST', '#dataset'], 'command': 'search'}\n",
      "2021-12-07 10:43:12,102 fedbiomed INFO - Node selected for training -> node_44f64619-6a88-4b60-9888-5dcdcca85005\n",
      "2021-12-07 10:43:12,247 fedbiomed DEBUG - torchnn saved model filename: /user/scansiz/home/Desktop/Inria/development/MR/fedbiomed/var/tmpexl7uui3/my_model_9480b7f8-f482-4bdf-88e3-59f0797335d5.py\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #nodes=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='MyTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "from torch.utils.data import DataLoader\n",
      "from torchvision import datasets, transforms\n",
      "from torchvision import datasets, transforms\n",
      "from torch.utils.data import DataLoader\n",
      "\n",
      "class MyTrainingPlan(TorchTrainingPlan):\n",
      "    def __init__(self):\n",
      "        super(MyTrainingPlan, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
      "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
      "        self.dropout1 = nn.Dropout(0.25)\n",
      "        self.dropout2 = nn.Dropout(0.5)\n",
      "        self.fc1 = nn.Linear(9216, 128)\n",
      "        self.fc2 = nn.Linear(128, 10)\n",
      "        \n",
      "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
      "        # In this case, we need the torch DataLoader classes\n",
      "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
      "        deps = [\"from torchvision import datasets, transforms\",\n",
      "               \"from torch.utils.data import DataLoader\"]\n",
      "        self.add_dependency(deps)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = self.conv1(x)\n",
      "        x = F.relu(x)\n",
      "        x = self.conv2(x)\n",
      "        x = F.relu(x)\n",
      "        x = F.max_pool2d(x, 2)\n",
      "        x = self.dropout1(x)\n",
      "        x = torch.flatten(x, 1)\n",
      "        x = self.fc1(x)\n",
      "        x = F.relu(x)\n",
      "        x = self.dropout2(x)\n",
      "        x = self.fc2(x)\n",
      "        \n",
      "        \n",
      "        output = F.log_softmax(x, dim=1)\n",
      "        return output\n",
      "\n",
      "    def training_data(self, batch_size = 48):\n",
      "        # Custom torch Dataloader for MNIST data\n",
      "        transform = transforms.Compose([transforms.ToTensor(),\n",
      "        transforms.Normalize((0.1307,), (0.3081,))])\n",
      "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
      "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
      "        data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
      "        return data_loader\n",
      "    \n",
      "    def training_step(self, data, target):\n",
      "        output = self.forward(data)\n",
      "        loss   = torch.nn.functional.nll_loss(output, target)\n",
      "        return loss\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/user/scansiz/home/Desktop/Inria/development/MR/fedbiomed/var/tmpexl7uui3/my_model_9480b7f8-f482-4bdf-88e3-59f0797335d5.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.model_file(display = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:43:26,088 fedbiomed INFO - Sampled nodes in round 0 ['node_44f64619-6a88-4b60-9888-5dcdcca85005']\n",
      "2021-12-07 10:43:26,088 fedbiomed INFO - Send message to node node_44f64619-6a88-4b60-9888-5dcdcca85005 - {'researcher_id': 'researcher_de471b3b-10f9-4849-8a9b-b6c60cccebef', 'job_id': '999e3d91-c881-4bfc-98ac-e2fe75a70953', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/12/07/my_model_9480b7f8-f482-4bdf-88e3-59f0797335d5.py', 'params_url': 'http://localhost:8844/media/uploads/2021/12/07/my_model_4f9b79fc-f33d-406f-96d3-a6eedeaa91d6.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_44f64619-6a88-4b60-9888-5dcdcca85005': ['dataset_bc32a9f9-74d3-4457-bdf1-611c76792980']}}\n",
      "2021-12-07 10:43:26,089 fedbiomed DEBUG - researcher_de471b3b-10f9-4849-8a9b-b6c60cccebef\n",
      "2021-12-07 10:43:26,126 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / DEBUG - Message received: {'researcher_id': 'researcher_de471b3b-10f9-4849-8a9b-b6c60cccebef', 'job_id': '999e3d91-c881-4bfc-98ac-e2fe75a70953', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/12/07/my_model_9480b7f8-f482-4bdf-88e3-59f0797335d5.py', 'params_url': 'http://localhost:8844/media/uploads/2021/12/07/my_model_4f9b79fc-f33d-406f-96d3-a6eedeaa91d6.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_44f64619-6a88-4b60-9888-5dcdcca85005': ['dataset_bc32a9f9-74d3-4457-bdf1-611c76792980']}}\n",
      "2021-12-07 10:43:26,128 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / DEBUG - [TASKS QUEUE] Item:{'researcher_id': 'researcher_de471b3b-10f9-4849-8a9b-b6c60cccebef', 'job_id': '999e3d91-c881-4bfc-98ac-e2fe75a70953', 'params_url': 'http://localhost:8844/media/uploads/2021/12/07/my_model_4f9b79fc-f33d-406f-96d3-a6eedeaa91d6.pt', 'training_args': {'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training_data': {'node_44f64619-6a88-4b60-9888-5dcdcca85005': ['dataset_bc32a9f9-74d3-4457-bdf1-611c76792980']}, 'model_args': {}, 'model_url': 'http://localhost:8844/media/uploads/2021/12/07/my_model_9480b7f8-f482-4bdf-88e3-59f0797335d5.py', 'model_class': 'MyTrainingPlan', 'command': 'train'}\n",
      "2021-12-07 10:43:26,486 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / INFO - {'monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x7ff0beecdc70>, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\n",
      "2021-12-07 10:43:26,488 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / DEBUG - Dataset_path../../data\n",
      "2021-12-07 10:43:26,740 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / INFO - Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.276141\n",
      "2021-12-07 10:43:27,517 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / INFO - Train Epoch: 1 [480/60000 (1%)]\tLoss: 1.332526\n",
      "2021-12-07 10:43:28,466 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / INFO - Train Epoch: 1 [960/60000 (2%)]\tLoss: 0.800497\n",
      "2021-12-07 10:43:29,648 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / INFO - Train Epoch: 1 [1440/60000 (2%)]\tLoss: 0.525048\n",
      "2021-12-07 10:43:30,926 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / INFO - Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.532181\n",
      "2021-12-07 10:43:31,064 fedbiomed INFO - log from: node_44f64619-6a88-4b60-9888-5dcdcca85005 / CRITICAL - Node stopped in signal_handler, probably by user decision (Ctrl C)\n",
      "2021-12-07 10:43:36,135 fedbiomed DEBUG - Error message received during training:301 - FB301: Node killed/stopped by a human - Node stopped in SIGTERM signal handler\n",
      "2021-12-07 10:43:36,139 fedbiomed ERROR - FB408: a node did not answer during training (node = node_44f64619-6a88-4b60-9888-5dcdcca85005)\n",
      "2021-12-07 10:43:36,142 fedbiomed ERROR - FB407: list of nodes became empty then training\n"
     ]
    },
    {
     "ename": "DefaultStrategyException",
     "evalue": "FB402: strategy method creashes or sending an error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultStrategyException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105024/2112911450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Inria/development/MR/fedbiomed/fedbiomed/researcher/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sync)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# refining/normalizing model weigths received from nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_selection_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_replies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mround_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# aggregate model from nodes to a global model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Inria/development/MR/fedbiomed/fedbiomed/researcher/strategies/default_strategy.py\u001b[0m in \u001b[0;36mrefine\u001b[0;34m(self, training_replies, round_i)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErrorNumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFB407\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDefaultStrategyException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrorNumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFB402\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# check that all nodes that answer could successfully train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDefaultStrategyException\u001b[0m: FB402: strategy method creashes or sending an error"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available in `exp.training_replies` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies.keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies[rounds - 1].data\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies[rounds - 1].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available in `exp.aggregated_params` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params.keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params[rounds - 1]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional : searching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "\n",
    "r = Requests()\n",
    "data = r.search(tags)\n",
    "\n",
    "import pandas as pd\n",
    "for node_id in data.keys():\n",
    "    print('\\n','Data for ', node_id, '\\n\\n', pd.DataFrame(data[node_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optional : clean file repository (do not run unless necessary)\n",
    "Clean all the files in the repo via the rest API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from fedbiomed.researcher.environ import environ\n",
    "\n",
    "# uploaded_models = requests.get(environ['UPLOADS_URL']).json()\n",
    "# for m in uploaded_models:\n",
    "#   requests.delete(m['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Feel free to try your own models :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
