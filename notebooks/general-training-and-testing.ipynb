{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Testing at Each Round of Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due torch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing Pytorch Model Using Predefiend Evalution Metrics at each Round of Federeated Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlan, self).__init__(model_args)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Declare and run the experiment\n",
    "The model is trained on the **MNIST dataset** for classification. For testing, we will be using the **F1-Score**  as a metric. Testing will be performed on both **local updates and global updates**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 17:02:18,878 fedbiomed INFO - Component environment:\n",
      "2022-04-05 17:02:18,880 fedbiomed INFO - type = ComponentType.RESEARCHER\n",
      "2022-04-05 17:02:19,371 fedbiomed INFO - Messaging researcher_00aba3da-4c77-4047-832c-ee956d08535c successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x138197160>\n",
      "2022-04-05 17:02:19,413 fedbiomed INFO - Searching dataset with data tags: ['#MNIST', '#dataset'] for all nodes\n",
      "2022-04-05 17:02:29,449 fedbiomed INFO - Node selected for training -> node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "2022-04-05 17:02:29,493 fedbiomed DEBUG - Model file has been saved: /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/my_model_e6b0ed0a-f068-4bb6-82bb-f7dd683adc6c.py\n",
      "2022-04-05 17:02:29,820 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/my_model_e6b0ed0a-f068-4bb6-82bb-f7dd683adc6c.py successful, with status code 201\n",
      "2022-04-05 17:02:30,756 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/aggregated_params_init_f651eff4-b835-408c-9c7a-d8ffd342990b.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "\n",
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "  \n",
    "}\n",
    "\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None,\n",
    "                tensorboard=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring Testing Arguments \n",
    "\n",
    "- **test_ratio:** The ratio for testing partition \n",
    "- **test_metric:** The metric that is going to be used for evaluation\n",
    "- **Testing on local updates:** Means that testing is going to be perform after training is performed over aggreated paramaters  \n",
    "- **Testing on global updates**: Means that testing will be perform on aggregated parameters before performing the training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display all the default metrics that are supported in Fed-BioMed. They are all based on sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCURACY',\n",
       " 'F1_SCORE',\n",
       " 'PRECISION',\n",
       " 'RECALL',\n",
       " 'MEAN_SQUARE_ERROR',\n",
       " 'MEAN_ABSOLUTE_ERROR',\n",
       " 'EXPLAINED_VARIANCE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.common.metrics import MetricTypes\n",
    "MetricTypes.get_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 17:02:39,489 fedbiomed DEBUG - Experimentation training_args updated for `job`\n",
      "2022-04-05 17:02:39,489 fedbiomed DEBUG - Experimentation training_args updated for `job`\n",
      "2022-04-05 17:02:39,490 fedbiomed DEBUG - Experimentation training_args updated for `job`\n",
      "2022-04-05 17:02:39,492 fedbiomed DEBUG - Experimentation training_args updated for `job`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<MetricTypes.F1_SCORE: (1, <_MetricCategory.CLASSIFICATION_LABELS: 0>)>, {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.set_test_ratio(0.1)\n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_on_global_updates(True)\n",
    "exp.set_test_metric(MetricTypes.F1_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b42ceb2ff02e8956\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b42ceb2ff02e8956\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 17:04:29,751 fedbiomed INFO - Sampled nodes in round 0 ['node_cebf1f87-fc00-42ca-9142-ec9226084a94']\n",
      "2022-04-05 17:04:29,752 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t\u001b[1m Reqeust: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_00aba3da-4c77-4047-832c-ee956d08535c', 'job_id': 'a2a6ad3b-2895-43a4-9642-71563d0bcdb0', 'training_args': {'test_ratio': 0.1, 'test_on_local_updates': True, 'test_on_global_updates': True, 'test_metric': <MetricTypes.F1_SCORE: (1, <_MetricCategory.CLASSIFICATION_LABELS: 0>)>, 'test_metric_args': {}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training': True, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/04/05/my_model_e6b0ed0a-f068-4bb6-82bb-f7dd683adc6c.py', 'params_url': 'http://localhost:8844/media/uploads/2022/04/05/aggregated_params_init_f651eff4-b835-408c-9c7a-d8ffd342990b.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_cebf1f87-fc00-42ca-9142-ec9226084a94': ['dataset_43767c3b-23bc-4b55-b7c6-6082519b2a31']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-04-05 17:04:29,753 fedbiomed DEBUG - researcher_00aba3da-4c77-4047-832c-ee956d08535c\n",
      "2022-04-05 17:04:31,305 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x126819d90>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:04:32,299 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m No `testing_step` method found in TrainingPlan: using defined metric F1_SCORE for model evaluation.\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:04:40,804 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Actual/True values (y_true) has more than two levels, using multiclass `weighted` calculation for the metric F1_SCORE\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:04:40,842 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Completed: 6000/6000 (100%) \n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.028613\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:41,876 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 480/54000 (1%) \n",
      " \t\t\t\t\t Loss: \u001b[1m1.686003\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:43,295 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 960/54000 (2%) \n",
      " \t\t\t\t\t Loss: \u001b[1m1.114182\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:44,649 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1440/54000 (3%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.577932\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:45,753 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1920/54000 (4%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.674934\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:46,687 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2400/54000 (4%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.529942\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:47,640 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2880/54000 (5%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.494226\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:48,813 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3360/54000 (6%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.435512\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:50,301 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3840/54000 (7%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.163826\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:51,861 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 4320/54000 (8%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.759652\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:04:54,607 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m No `testing_step` method found in TrainingPlan: using defined metric F1_SCORE for model evaluation.\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:01,973 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Actual/True values (y_true) has more than two levels, using multiclass `weighted` calculation for the metric F1_SCORE\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:02,001 fedbiomed INFO - \u001b[1mTESTING ON LOCAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Completed: 6000/6000 (100%) \n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.942801\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:02,742 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:09,804 fedbiomed INFO - Downloading model params after training on node_cebf1f87-fc00-42ca-9142-ec9226084a94 - from http://localhost:8844/media/uploads/2022/04/05/node_params_564ed109-289c-431c-b60f-a4b918b78f82.pt\n",
      "2022-04-05 17:05:10,100 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_13ceee26-bf5e-4249-bbb8-69e1cadd48ce.pt successful, with status code 200\n",
      "2022-04-05 17:05:10,127 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_cebf1f87-fc00-42ca-9142-ec9226084a94']\n",
      "2022-04-05 17:05:11,024 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/aggregated_params_973f0680-acdc-4a60-8761-c85c1710a758.pt successful, with status code 201\n",
      "2022-04-05 17:05:11,026 fedbiomed INFO - Saved aggregated params for round 0 in /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/aggregated_params_973f0680-acdc-4a60-8761-c85c1710a758.pt\n",
      "2022-04-05 17:05:11,028 fedbiomed INFO - Sampled nodes in round 1 ['node_cebf1f87-fc00-42ca-9142-ec9226084a94']\n",
      "2022-04-05 17:05:11,040 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t\u001b[1m Reqeust: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_00aba3da-4c77-4047-832c-ee956d08535c', 'job_id': 'a2a6ad3b-2895-43a4-9642-71563d0bcdb0', 'training_args': {'test_ratio': 0.1, 'test_on_local_updates': True, 'test_on_global_updates': True, 'test_metric': 'F1_SCORE', 'test_metric_args': {}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}, 'training': True, 'model_args': {}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/04/05/my_model_e6b0ed0a-f068-4bb6-82bb-f7dd683adc6c.py', 'params_url': 'http://localhost:8844/media/uploads/2022/04/05/aggregated_params_973f0680-acdc-4a60-8761-c85c1710a758.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'node_cebf1f87-fc00-42ca-9142-ec9226084a94': ['dataset_43767c3b-23bc-4b55-b7c6-6082519b2a31']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-04-05 17:05:11,042 fedbiomed DEBUG - researcher_00aba3da-4c77-4047-832c-ee956d08535c\n",
      "2022-04-05 17:05:12,075 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x1268bedc0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 17:05:13,114 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m No `testing_step` method found in TrainingPlan: using defined metric F1_SCORE for model evaluation.\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:18,360 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Actual/True values (y_true) has more than two levels, using multiclass `weighted` calculation for the metric F1_SCORE\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:18,386 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Completed: 6000/6000 (100%) \n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.937988\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:19,321 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 480/54000 (1%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.472177\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:20,205 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 960/54000 (2%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.223436\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:21,103 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1440/54000 (3%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.134577\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:22,020 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 1920/54000 (4%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.140179\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:22,918 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2400/54000 (4%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.190448\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:23,937 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 2880/54000 (5%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.217308\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:25,432 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3360/54000 (6%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.174758\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:26,941 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 3840/54000 (7%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.114562\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:27,889 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 4320/54000 (8%) \n",
      " \t\t\t\t\t Loss: \u001b[1m0.173597\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:29,705 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m No `testing_step` method found in TrainingPlan: using defined metric F1_SCORE for model evaluation.\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:35,735 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Actual/True values (y_true) has more than two levels, using multiclass `weighted` calculation for the metric F1_SCORE\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:35,802 fedbiomed INFO - \u001b[1mTESTING ON LOCAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Completed: 6000/6000 (100%) \n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.957502\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-04-05 17:05:36,568 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:46,075 fedbiomed INFO - Downloading model params after training on node_cebf1f87-fc00-42ca-9142-ec9226084a94 - from http://localhost:8844/media/uploads/2022/04/05/node_params_e90ed8c1-23f1-4084-8cee-33ee0285f8b2.pt\n",
      "2022-04-05 17:05:46,310 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_10f36e39-07b4-4753-88d5-f637a6d158c9.pt successful, with status code 200\n",
      "2022-04-05 17:05:46,327 fedbiomed INFO - Nodes that successfully reply in round 1 ['node_cebf1f87-fc00-42ca-9142-ec9226084a94']\n",
      "2022-04-05 17:05:47,011 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/aggregated_params_98cf6af2-0933-4046-843e-117baf5783a3.pt successful, with status code 201\n",
      "2022-04-05 17:05:47,013 fedbiomed INFO - Saved aggregated params for round 1 in /Users/jls/Development/fedbiomed/fedbiomed/var/experiments/Experiment_0050/aggregated_params_98cf6af2-0933-4046-843e-117baf5783a3.pt\n",
      "2022-04-05 17:05:47,014 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t\u001b[1m Reqeust: \u001b[0m:Perform final testing on aggregated parameters \n",
      " -----------------------------------------------------------------\n",
      "2022-04-05 17:05:47,017 fedbiomed DEBUG - researcher_00aba3da-4c77-4047-832c-ee956d08535c\n",
      "2022-04-05 17:05:47,350 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x126819f70>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'batch_size': 48, 'lr': 0.001, 'epochs': 1, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:48,173 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m No `testing_step` method found in TrainingPlan: using defined metric F1_SCORE for model evaluation.\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:53,927 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cebf1f87-fc00-42ca-9142-ec9226084a94\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Actual/True values (y_true) has more than two levels, using multiclass `weighted` calculation for the metric F1_SCORE\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-04-05 17:05:53,945 fedbiomed INFO - \u001b[1mTESTING ON GLOBAL UPDATES\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cebf1f87-fc00-42ca-9142-ec9226084a94 \n",
      "\t\t\t\t\t Completed: 6000/6000 (100%) \n",
      " \t\t\t\t\t F1_SCORE: \u001b[1m0.962429\u001b[0m \n",
      "\t\t\t\t\t ---------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Training and Testing with sklearn Perceptron model\n",
    "\n",
    "\n",
    "Now we will use the testing facility on Skelearn training plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import SGDSkLearnModel\n",
    "from fedbiomed.common.data import DataManager\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SkLearnClassifierTrainingPlan(SGDSkLearnModel):\n",
    "    def __init__(self, model_args):\n",
    "        super(SkLearnClassifierTrainingPlan,self).__init__(model_args)\n",
    "        self.add_dependency(['import torch',\n",
    "                            \"from sklearn.linear_model import Perceptron\",\n",
    "                            \"from torchvision import datasets, transforms\",\n",
    "                           \"from torch.utils.data import DataLoader\"])\n",
    "    \n",
    "    \n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data: np.ndarray\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        \n",
    "        train_kwargs = {'batch_size': 500, 'shuffle': True}  # number of data passed to classifier\n",
    "        X_train = dataset.data.numpy()\n",
    "        X_train = X_train.reshape(-1, 28*28)\n",
    "        Y_train = dataset.targets.numpy()\n",
    "        \n",
    "        return DataManager(dataset=X_train,target=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to define testing option in the training arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = { 'max_iter':1000,\n",
    "              'tol': 1e-4 ,\n",
    "              'model': 'Perceptron' ,\n",
    "              'n_features': 28*28,\n",
    "              'n_classes' : 10,\n",
    "              'eta0':1e-6,\n",
    "              'random_state':1234,\n",
    "              'alpha':0.1 }\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 5, \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 10\n",
    "\n",
    "# select nodes participing to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=SkLearnClassifierTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None, \n",
    "                 tensorboard=True)\n",
    "\n",
    "\n",
    "exp.set_test_ratio(.2)\n",
    "#exp.set_test_metric(MetricTypes.PRECISION, average='macro')\n",
    "exp.set_test_on_global_updates(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feel free to run other sample notebooks or try your own models :D\n",
    "\n",
    "# 3. Testing facility using your own testing metric\n",
    "\n",
    "If the user wants to define its own testing metric, he can do so by defining the `testing_step` method in the Training plan. \n",
    "\n",
    "`testing_step` is defined the same way as `training_step`:\n",
    "\n",
    "When defining a `testing_step` method in the TrainingPlan, user has to:\n",
    "- predict classes or probabilities from model\n",
    "- compute a scalar or a list of scalars\n",
    "\n",
    "Method `testing_step` can return either a scalar or a list of scalars: in Tensorboard, list of scalars will be seen as the output of several metrics\n",
    "\n",
    "\n",
    "## 3.1 PyTorch Training Plan\n",
    "\n",
    "Below we showcase an example of a TorchTrainingPlan with a `testing_step` computing 3 metrics: log likelihood loss, a cross entropy loss, and a custom accuracy metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlanCM(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlanCM, self).__init__(model_args)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n",
    "\n",
    "    def testing_step(self, data, target):        \n",
    "        output = self.forward(data)\n",
    "        \n",
    "        #negative log likelihood loss\n",
    "        loss1   = torch.nn.functional.nll_loss(output, target)\n",
    "        \n",
    "        #cross entropy\n",
    "        loss2 = torch.nn.functional.cross_entropy(output,target)\n",
    "        \n",
    "        # accuracy\n",
    "        _,predicted = torch.max(output.data,1)\n",
    "        acc = torch.sum(predicted==target)\n",
    "        loss3 = acc/len(target)\n",
    "        \n",
    "        # Returning results as list\n",
    "        return [loss1,loss2,loss3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "    'test_ratio': .3,\n",
    "    'test_on_local_updates': True, \n",
    "    'test_on_global_updates': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlanCM,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None, \n",
    "                tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sklearn Training Plan\n",
    "\n",
    "Below we showcase an example of a SklearnTrainingPlan with a `testing_step` computing several metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import SGDSkLearnModel\n",
    "from fedbiomed.common.data import DataManager\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SkLearnClassifierTrainingPlan(SGDSkLearnModel):\n",
    "    def __init__(self, model_args):\n",
    "        super(SkLearnClassifierTrainingPlan,self).__init__(model_args)\n",
    "        self.add_dependency(['import torch',\n",
    "                            \"from sklearn.linear_model import Perceptron\",\n",
    "                            \"from torchvision import datasets, transforms\",\n",
    "                           \"from torch.utils.data import DataLoader\",\n",
    "                            \"from sklearn.metrics import hinge_loss\"])\n",
    "    \n",
    "    \n",
    "    def compute_accuracy_for_specific_digit(self, data, target, digit: int):\n",
    "        idx_data_equal_to_digit = target == digit\n",
    "        \n",
    "        predicted = self.model.predict(data[idx_data_equal_to_digit])\n",
    "        well_predicted_label = np.sum(predicted == digit) / np.sum(idx_data_equal_to_digit)\n",
    "        return well_predicted_label\n",
    "    \n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        \n",
    "        train_kwargs = {'batch_size': 500, 'shuffle': True}  # number of data passed to classifier\n",
    "        X_train = dataset.data.numpy()\n",
    "        X_train = X_train.reshape(-1, 28*28)\n",
    "        Y_train = dataset.targets.numpy()\n",
    "        \n",
    "        return DataManager(dataset=X_train, target=Y_train)\n",
    "    \n",
    "    def testing_step(self, data, target):\n",
    "        #test_data = data.reshape(-1, 28 * 28)\n",
    "        # hinge loss\n",
    "        distance_from_hyperplan = self.model.decision_function(data)\n",
    "        loss = hinge_loss(target, distance_from_hyperplan)\n",
    "        \n",
    "        # get the accuracy only on images representing digit 1\n",
    "        well_predicted_label_1 = self.compute_accuracy_for_specific_digit(data, target, 1)\n",
    "        \n",
    "        # Returning results as dict\n",
    "        return {'Hinge Loss': loss, 'Well Predcited Label 1' : well_predicted_label_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = { 'max_iter':1000,\n",
    "              'tol': 1e-4 ,\n",
    "              'model': 'Perceptron' ,\n",
    "              'n_features': 28*28,\n",
    "              'n_classes' : 10,\n",
    "              'eta0':1e-6,\n",
    "              'random_state':1234,\n",
    "              'alpha':0.1 }\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 5, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 10\n",
    "\n",
    "# select nodes participing to this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=SkLearnClassifierTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None, \n",
    "                 tensorboard=True)\n",
    "\n",
    "\n",
    "exp.set_test_ratio(.2)\n",
    "#exp.set_test_metric(MetricTypes.PRECISION, average='macro')\n",
    "exp.set_test_on_global_updates(True)\n",
    "exp.set_test_on_local_updates(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
