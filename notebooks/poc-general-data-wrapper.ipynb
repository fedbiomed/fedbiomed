{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee99bdb4",
   "metadata": {},
   "source": [
    "Related to user story: [SP11-Item04: General Data Wrapper PoC](https://gitlab.inria.fr/fedbiomed/fedbiomed/-/issues/164)\n",
    "\n",
    "## Tabular dataset\n",
    "\n",
    "Workflow of data pre processing:\n",
    "\n",
    "1. Columns name should be shared with the researcher\n",
    "2. Data format file to be filled by clinicians.\n",
    "3. Specify if missing data are allowed for a given columns (Exception). The file will be used for data verification during FL pre-processing,\n",
    "4. Outlier verification for quantitative data, continuous and discrete, and for dates (Critical warning),\n",
    "5. Missing data imputation by local mean (or optional NN), or majority voting for discrete labels. Give warnings when missing data are found (for verification a posteriori).\n",
    "6. Give critical warning when too many missing are found (>50%),\n",
    "7. Verify that number of available data is greater then minimum required (Error)\n",
    "\n",
    "Critical warnings have different levels of disclosure to the researcher (1) only the warning, 2) type of warning, 3) type of warning and column affected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ae4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. load  a single view dataset\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Union, Dict\n",
    "import os\n",
    "\n",
    "path_file = '/user/ybouilla/home/Documents/data/pseudo_adni_mod/pseudo_adni_mod.csv'\n",
    "file_name = os.path.basename(path_file)\n",
    "single_view_dataset = pd.read_csv(path_file, delimiter=';', header=0)\n",
    "single_view_dataset = {file_name: single_view_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41302983",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pseudo_adni_mod.csv':      CDRSB.bl  ADAS11.bl  MMSE.bl  RAVLT.immediate.bl  RAVLT.learning.bl  \\\n",
       " 0           1          8     27.0           23.739439                4.0   \n",
       " 1           0          0     30.0           64.933800                9.0   \n",
       " 2           0          8     24.0           36.987722                3.0   \n",
       " 3           0          3     29.0           50.314425                5.0   \n",
       " 4           0          0     30.0           57.217830                9.0   \n",
       " ..        ...        ...      ...                 ...                ...   \n",
       " 995         1          2     29.0           61.896022                8.0   \n",
       " 996         0          1     29.0           62.083170                8.0   \n",
       " 997         3         14     24.0           22.289059                2.0   \n",
       " 998         0         13     26.0           31.650504                2.0   \n",
       " 999         0         15     28.0           29.089863                3.0   \n",
       " \n",
       "      RAVLT.forgetting.bl  FAQ.bl  WholeBrain.bl  Ventricles.bl  \\\n",
       " 0               5.821573       3       0.684331       0.012699   \n",
       " 1               4.001653       0       0.735892       0.012803   \n",
       " 2               6.876316       0       0.738731       0.030492   \n",
       " 3               4.733481       3       0.696179       0.032797   \n",
       " 4               7.225401       0       0.841806       0.004030   \n",
       " ..                   ...     ...            ...            ...   \n",
       " 995             1.663102       0       0.767153       0.011417   \n",
       " 996             5.241477       1       0.695168       0.011908   \n",
       " 997             5.437600       7       0.628691       0.041537   \n",
       " 998             1.669603       4       0.714763       0.020461   \n",
       " 999             7.703384       4       0.691858       0.030349   \n",
       " \n",
       "      Hippocampus.bl  MidTemp.bl  Entorhinal.bl  ABETA.MEDIAN.bl  \\\n",
       " 0          0.003786    0.012678       0.002214       154.016065   \n",
       " 1          0.004866    0.015071       0.003041       211.573206   \n",
       " 2          0.004300    0.012419       0.002316       163.637668   \n",
       " 3          0.004720    0.012312       0.002593       182.256297   \n",
       " 4          0.006820    0.016948       0.002896       247.997479   \n",
       " ..              ...         ...            ...              ...   \n",
       " 995        0.005209    0.012879       0.002208       231.706787   \n",
       " 996        0.004641    0.012534       0.002197       146.949187   \n",
       " 997        0.003478    0.010870       0.001939       181.805672   \n",
       " 998        0.004713    0.013989       0.001981       178.824412   \n",
       " 999        0.004237    0.011439       0.002419       180.781989   \n",
       " \n",
       "      PTAU.MEDIAN.bl  TAU.MEDIAN.bl   AGE  \n",
       " 0         67.970509     132.571916  75.0  \n",
       " 1          5.451168      33.787719  67.0  \n",
       " 2         66.704378     110.049924  63.0  \n",
       " 3         47.091893     138.690457  75.0  \n",
       " 4         -5.997140     -61.573234  65.0  \n",
       " ..              ...            ...   ...  \n",
       " 995       24.632786      87.065806  76.0  \n",
       " 996       57.588115     121.985248  77.0  \n",
       " 997       55.052669     157.229102  74.0  \n",
       " 998       69.412821     103.238647  64.0  \n",
       " 999       32.978001      54.780563  65.0  \n",
       " \n",
       " [1000 rows x 16 columns]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_view_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2460bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for multi view dataframe\n",
    "\n",
    "def create_multi_view_dataframe(datasets: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    _header_labels = ['views', 'feature_name']\n",
    "    # 1. create multiindex header\n",
    "\n",
    "    _feature_name_array = np.array([])  # store all feature names\n",
    "    _view_name_array = []  # store all views (ie modalities) names\n",
    "\n",
    "    _concatenated_datasets = np.array([])  # store dataframe values\n",
    "\n",
    "    for key in datasets.keys():\n",
    "        _feature_name_array = np.concatenate([_feature_name_array,\n",
    "                                              datasets[key].columns.values])\n",
    "        if len(_concatenated_datasets) <= 0:\n",
    "            # first pass \n",
    "            _concatenated_datasets = datasets[key].values\n",
    "        else:\n",
    "            # next passes\n",
    "            try:\n",
    "                _concatenated_datasets = np.concatenate(\n",
    "                                        [_concatenated_datasets,\n",
    "                                         datasets[key].to_numpy()\n",
    "                                         ], axis=1)\n",
    "            except ValueError as val_err:\n",
    "                # catching case where nb_samples are differents\n",
    "                raise ValueError(\n",
    "                    'Cannot create multi view dataset: different number of samples for each modality have been detected'\\\n",
    "                        + 'Details: ' + str(val_err)\n",
    "                    )\n",
    "        for _ in datasets[key].columns.values:\n",
    "            _view_name_array.append(key)\n",
    "\n",
    "    _header = pd.MultiIndex.from_arrays([_view_name_array,\n",
    "                                         _feature_name_array],\n",
    "                                        names=_header_labels)\n",
    "\n",
    "\n",
    "    # 2. create multi index dataframe\n",
    "\n",
    "    multi_view_df = pd.DataFrame(_concatenated_datasets,\n",
    "                                  columns = _header)\n",
    "    return multi_view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a9c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_variables_before_joining(multi_view_datasets: Dict[str, pd.DataFrame],\n",
    "                                    views_name: List[Union[str, int]],\n",
    "                                    primary_key:Union[str, int]=None) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Renames variables that have same name but different views using the following naming convention:\n",
    "    if `a` is the name of a feature of `view1` and `a` is the name of a feature of `view2`,\n",
    "    features names will be updated into `view1.a` and `view2.a`\n",
    "    \"\"\"\n",
    "    _features_names = {}\n",
    "    _views_length = len(views_name)\n",
    "    \n",
    "    for i_left in range(0, _views_length-1):\n",
    "        _left_view = views_name[i_left]\n",
    "        _left_features_name = multi_view_datasets[_left_view].columns.tolist()\n",
    "        for i_right in range(i_left+1, _views_length):\n",
    "        \n",
    "            _right_view = views_name[i_right]\n",
    "            _right_features_name = multi_view_datasets[_right_view].columns.tolist()\n",
    "            \n",
    "            for _f in _left_features_name:\n",
    "                if primary_key and _f == primary_key:\n",
    "                    # do not affect primary key (if any)\n",
    "                    continue\n",
    "                if _f  in _right_features_name:\n",
    "                    \n",
    "                    if _left_view  not in _features_names:\n",
    "                        _features_names[_left_view] = {}\n",
    "                        \n",
    "                    if _right_view not in _features_names:\n",
    "                        _features_names[_right_view] = {}\n",
    "                        \n",
    "                    _features_names[_left_view].update({_f: _left_view + '.' + str(_f)})\n",
    "                    _features_names[_right_view].update({_f: _right_view + '.' + str(_f)})\n",
    "    \n",
    "    for i in range(_views_length):\n",
    "        _view = views_name[i]\n",
    "        _new_features = _features_names.get(_view)\n",
    "        if _new_features:\n",
    "            multi_view_datasets[_view] = multi_view_datasets[_view].rename(columns=_new_features)\n",
    "        \n",
    "    \n",
    "    return multi_view_datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85714c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_muti_view_dataset(multi_view_dataset: pd.DataFrame, primary_key: str) -> pd.DataFrame:\n",
    "    _views_name = sorted(set(multi_view_dataset.columns.get_level_values(0)))  # get views name\n",
    "    \n",
    "    joined_dataframe = multi_view_dataset[_views_name[0]]  # retrieve the first view\n",
    "    # (as a result of join operation)\n",
    "    for x in range(1, len(_views_name)):\n",
    "        joined_dataframe = joined_dataframe.merge(multi_view_dataset[_views_name[x]],\n",
    "                                                    on=primary_key,\n",
    "                                                    suffixes=('', '.'+_views_name[x]))\n",
    "        \n",
    "        #df['file1'].join(df['file2'].set_index('pkey'), on='pkey', rsuffix='.file2')\n",
    "        \n",
    "    return joined_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0edec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1672a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory found\n"
     ]
    }
   ],
   "source": [
    "# load multi view dataset\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "folder_csv_path = 'test7'\n",
    "if os.path.isdir(folder_csv_path):\n",
    "    print('directory found')\n",
    "    \n",
    "else:\n",
    "    pass\n",
    "    # it is a file \n",
    "\n",
    "tabular_data_files = os.listdir(folder_csv_path)\n",
    "multi_view_dataframe = {}\n",
    "for tabular_data_file in tabular_data_files:\n",
    "    # check if `tabular_data` is a csv file\n",
    "    path_file = os.path.join(folder_csv_path, tabular_data_file)\n",
    "    with open(path_file, 'r') as csvfile:\n",
    "        try:\n",
    "            # do some operation on file using sniffer to make sure considered file\n",
    "            # is a CSV file\n",
    "            dialect = csv.Sniffer().sniff(csvfile.readline())\n",
    "            delimiter = dialect.delimiter\n",
    "            dialect.lineterminator\n",
    "            has_header = csv.Sniffer().has_header(csvfile.readline())\n",
    "            if has_header:\n",
    "                header = 0\n",
    "            else:\n",
    "                header = None\n",
    "            multi_view_dataframe[tabular_data_file] = pd.read_csv(path_file, delimiter=delimiter,)\n",
    "        except csv.Error as err:\n",
    "            print('err', err, 'in file', tabular_data_file)\n",
    "            #tabular_data_files.remove(tabular_data_file)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "636e47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = 'pkey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "56d3dd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['discrete', 'city', 'pkey', 'a', 'e', 'i', 'o', 'file1.0', 'file1.1',\n",
       "       'file1.2', 'file1.3', 'file1.time', 'pressure', 'sp02', 'a.1', 'e.1',\n",
       "       'i.1', 'o.1', 'gender', 'blood type', 'file2.0', 'file2.1', 'file2.2',\n",
       "       'file2.3', 'file2.time', 'pH'],\n",
       "      dtype='object', name='feature_name')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_view_dataframe = rename_variables_before_joining(multi_view_dataframe,\n",
    "                                                      list(multi_view_dataframe.keys()),\n",
    "                                                       primary_key=primary_key)\n",
    "\n",
    "mdf = create_multi_view_dataframe(multi_view_dataframe)\n",
    "mdf = join_muti_view_dataset(mdf, primary_key=primary_key)\n",
    "mdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bea3b6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>feature_name</th>\n",
       "      <th>discrete</th>\n",
       "      <th>city</th>\n",
       "      <th>pkey</th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>o</th>\n",
       "      <th>file1.0</th>\n",
       "      <th>file1.1</th>\n",
       "      <th>file1.2</th>\n",
       "      <th>...</th>\n",
       "      <th>i.1</th>\n",
       "      <th>o.1</th>\n",
       "      <th>gender</th>\n",
       "      <th>blood type</th>\n",
       "      <th>file2.0</th>\n",
       "      <th>file2.1</th>\n",
       "      <th>file2.2</th>\n",
       "      <th>file2.3</th>\n",
       "      <th>file2.time</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>Lille</td>\n",
       "      <td>qpqorfhylu gmfjy bdj</td>\n",
       "      <td>67</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-01-02 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Lille</td>\n",
       "      <td>kkmjozalfyirgsire ui</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>MAN</td>\n",
       "      <td>AB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0.023107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>ezfasuuycdda foisjte</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>89</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>MAN</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-01-02 10:00:00</td>\n",
       "      <td>0.587685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>faxiqkt xggzmwzoidbg</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>MAN</td>\n",
       "      <td>AB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-01-03 12:00:00</td>\n",
       "      <td>0.894073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.0</td>\n",
       "      <td>Lille</td>\n",
       "      <td>znwhlj rwzdutnagwasy</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>O</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-01 10:00:00</td>\n",
       "      <td>0.026831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>zeqhcikzdodus jn qjf</td>\n",
       "      <td>81</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>MAN</td>\n",
       "      <td>AB</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-02 05:00:00</td>\n",
       "      <td>0.78856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>98.0</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>iicthcvfmkajbvr gzir</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>MAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-01-05 02:00:00</td>\n",
       "      <td>0.402979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Lille</td>\n",
       "      <td>ztjakcsk bhjoksdz lm</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "      <td>MAN</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>42.0</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>sabunaa opt vpulnxj</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>MAN</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-01-02 09:00:00</td>\n",
       "      <td>0.651801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Paris</td>\n",
       "      <td>qmbexyexvgromrm admu</td>\n",
       "      <td>22</td>\n",
       "      <td>89</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>MAN</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-03 02:00:00</td>\n",
       "      <td>0.751969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature_name discrete       city                  pkey   a   e   i   o  \\\n",
       "0                64.0      Lille  qpqorfhylu gmfjy bdj  67  16  54  25   \n",
       "1                26.0      Lille  kkmjozalfyirgsire ui  42  96  69  61   \n",
       "2                61.0      Paris  ezfasuuycdda foisjte  46   8  89  21   \n",
       "3                29.0      Paris  faxiqkt xggzmwzoidbg  29   6  77  14   \n",
       "4                99.0      Lille  znwhlj rwzdutnagwasy  96  79  19  33   \n",
       "..                ...        ...                   ...  ..  ..  ..  ..   \n",
       "95                9.0      Paris  zeqhcikzdodus jn qjf  81  62  52  68   \n",
       "96               98.0  Marseille  iicthcvfmkajbvr gzir  16  49  30   7   \n",
       "97               21.0      Lille  ztjakcsk bhjoksdz lm  90  14  36  24   \n",
       "98               42.0  Marseille   sabunaa opt vpulnxj  91  10  69  58   \n",
       "99                3.0      Paris  qmbexyexvgromrm admu  22  89  36  15   \n",
       "\n",
       "feature_name file1.0 file1.1 file1.2  ... i.1 o.1 gender blood type file2.0  \\\n",
       "0               True   False   False  ...  55  27  WOMAN          A    True   \n",
       "1               True    True    True  ...   8  82    MAN         AB   False   \n",
       "2              False    True    True  ...  15  30    MAN          A    True   \n",
       "3              False    True   False  ...  37  55    MAN         AB   False   \n",
       "4              False    True    True  ...  79   6  WOMAN          O    True   \n",
       "..               ...     ...     ...  ...  ..  ..    ...        ...     ...   \n",
       "95              True    True    True  ...  39  35    MAN         AB    True   \n",
       "96             False   False    True  ...  27  23    MAN        NaN    True   \n",
       "97             False   False   False  ...  76   7    MAN          B    True   \n",
       "98              True    True   False  ...  72  53    MAN          B   False   \n",
       "99             False    True    True  ...  18  74    MAN          B   False   \n",
       "\n",
       "feature_name file2.1 file2.2 file2.3           file2.time        pH  \n",
       "0              False   False   False  2018-01-02 06:00:00       NaN  \n",
       "1               True   False    True  2018-01-01 00:00:00  0.023107  \n",
       "2              False    True   False  2018-01-02 10:00:00  0.587685  \n",
       "3               True   False   False  2018-01-03 12:00:00  0.894073  \n",
       "4               True    True    True  2018-01-01 10:00:00  0.026831  \n",
       "..               ...     ...     ...                  ...       ...  \n",
       "95             False   False    True  2018-01-02 05:00:00   0.78856  \n",
       "96              True   False   False  2018-01-05 02:00:00  0.402979  \n",
       "97             False   False    True  2018-01-01 12:00:00       NaN  \n",
       "98              True   False   False  2018-01-02 09:00:00  0.651801  \n",
       "99             False    True    True  2018-01-03 02:00:00  0.751969  \n",
       "\n",
       "[100 rows x 26 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012dc5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca4a18de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect.lineterminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e0739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a178bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add0e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. extract columns name\n",
    "MISSING = 'MISSING'\n",
    "dataset_columns = single_view_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d533e99",
   "metadata": {},
   "source": [
    "Data format file to be filled by clinicians (step 2 int he workflow):\n",
    "\n",
    "Data format file will be a dictionary specifying the type: \n",
    "* for single view datasets:\n",
    "```{<feature_name>: {'data_type': <data_type>, 'type':<values_taken>, 'range': <value_range>}```\n",
    " * for multiview datatset\n",
    "```{{<view_name>: <feature_name>: {'data_type': <data_type>, 'type':<values_taken>, 'range': <value_range>}}```\n",
    "\n",
    "where\n",
    "* `<view_name>` is the name of the view\n",
    "* `<feature_name>` is the name of the feature\n",
    "* `<data_type>` can be categorical or continuous or missing_data or datetime\n",
    "* `<value_taken>` is the type of the value (eg int, char, float, signed, unsigned ...)\n",
    "* `<value_range>` represent either a list of bounds, an upper or a lower bound, or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134b8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create data format file\n",
    "\n",
    "import numpy as np\n",
    "import enum\n",
    "from enum import Enum, auto\n",
    "\n",
    "# the use of Enum classes will prevent incorrect combination of values\n",
    "class QuantitativeDataType(Enum):\n",
    "    CONTINUOUS = [float, np.float64]\n",
    "    DISCRETE = [int, np.int64]\n",
    "\n",
    "class CategoricalDataType(Enum):\n",
    "    BOOLEAN = [bool]\n",
    "    NUMERICAL = [float, int, np.float64, np.int64]\n",
    "    CHARACTER = [str, object]\n",
    "    \n",
    "class KeyDataType(Enum):\n",
    "    NUMERICAL = [int, np.int64]\n",
    "    CHARACTER = [str, object]\n",
    "    DATETIME = \"DATETIME\"\n",
    "    \n",
    "class DataType(Enum):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    KEY = [KeyDataType.NUMERICAL,\n",
    "           KeyDataType.CHARACTER,\n",
    "           KeyDataType.DATETIME]\n",
    "    QUANTITATIVE = [QuantitativeDataType.CONTINUOUS,\n",
    "                   QuantitativeDataType.DISCRETE]\n",
    "    CATEGORICAL = [CategoricalDataType.BOOLEAN,\n",
    "                  CategoricalDataType.NUMERICAL,\n",
    "                  CategoricalDataType.CHARACTER]\n",
    "    #MISSING = 'MISSING'\n",
    "    DATETIME = 'DATETIME'\n",
    "    UNKNOWN = 'UNKNOWN'\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_names():\n",
    "        return tuple(n for n, _ in DataType.__members__.items())\n",
    "\n",
    "class MissingValueAllowedDefault(Enum):\n",
    "    KEY = False\n",
    "    QUANTITATIVE = True\n",
    "    CATEGORICAL = True\n",
    "    DATETIME = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_names():\n",
    "        return tuple(n for n, _ in MissingValueAllowedDefault.__members__.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea518576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('KEY', 'QUANTITATIVE', 'CATEGORICAL', 'DATETIME', 'UNKNOWN')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataType.get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87fb81c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('KEY', 'QUANTITATIVE', 'CATEGORICAL', 'DATETIME')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MissingValueAllowedDefault.get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4f0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_type(avail_data_types: enum.EnumMeta,\n",
    "                  d_format: Enum,\n",
    "                  d_type: type) ->  Tuple[Enum, List[Union[type, str]]]:\n",
    "    present_d_types = []\n",
    "    sub_d_type_format = None\n",
    "    for avail_data_type in avail_data_types:\n",
    "        if d_format is avail_data_type:\n",
    "            sub_dtypes = avail_data_type.value\n",
    "            if not isinstance(sub_dtypes, str) and hasattr(sub_dtypes, '__getitem__') and isinstance(sub_dtypes[0], Enum):\n",
    "                # check if dtype has subtypes\n",
    "                #(eg if datatype is QUANTITATIVE, subtype will be CONTINOUS or DISCRETE)\n",
    "                for sub_dtype in sub_dtypes:\n",
    "                    if any(d_type == t for t in tuple(sub_dtype.value)):\n",
    "                        present_d_types.append(d_type)\n",
    "                        sub_d_type_format = sub_dtype\n",
    "                        print(sub_dtype, d_type)\n",
    "            else:\n",
    "                \n",
    "                present_d_types.append(sub_dtypes)\n",
    "                sub_d_type_format = sub_dtypes\n",
    "    return  sub_d_type_format, present_d_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee00bd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_view_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21528/355699146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmulti_view_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'multi_view_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "multi_view_dataframe['file1']['a'].dtype is np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "691fe901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_missing_data(column: pd.Series)->bool:\n",
    "    is_missing_data = column.isna().any()\n",
    "    return is_missing_data\n",
    "df = pd.DataFrame({'w': [1, 2, 3, 4,  'jj', None]})\n",
    "print(check_missing_data(df['w']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc0f354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = single_view_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c5c258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_format is DataType.KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join multiple csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0560441",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'available_data_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6741/4290574421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavailable_data_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'available_data_type' is not defined"
     ]
    }
   ],
   "source": [
    "available_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "800e755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<DataType.KEY: [<KeyDataType.NUMERICAL: [<class 'int'>, <class 'numpy.int64'>]>, <KeyDataType.CHARACTER: [<class 'str'>, <class 'object'>]>, <KeyDataType.DATETIME: 'DATETIME'>]>, <DataType.QUANTITATIVE: [<QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>, <QuantitativeDataType.DISCRETE: [<class 'int'>, <class 'numpy.int64'>]>]>, <DataType.CATEGORICAL: [<CategoricalDataType.BOOLEAN: [<class 'bool'>]>, <CategoricalDataType.NUMERICAL: [<class 'float'>, <class 'int'>, <class 'numpy.float64'>, <class 'numpy.int64'>]>, <CategoricalDataType.CHARACTER: [<class 'str'>, <class 'object'>]>]>, <DataType.DATETIME: 'DATETIME'>, <DataType.UNKNOWN: 'UNKNOWN'>]\n"
     ]
    }
   ],
   "source": [
    "# CLI for clinicians for setting up data format file\n",
    "\n",
    "import sys, pprint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "available_data_type = [d_type for d_type in DataType]  # get all available data type\n",
    "n_available_data_type = len(available_data_type)\n",
    "print(available_data_type)\n",
    "\n",
    "data_format_files = {}\n",
    "\n",
    "\n",
    "msg = ''\n",
    "msg_yes_or_no_question = '1) YES\\n2) NO\\n'\n",
    "yes_or_no_question_key = {'1': True,\n",
    "                    '2': False}\n",
    "for i, dtype in enumerate(available_data_type):\n",
    "    msg += '%d) %s \\n' %  (i+1, dtype.name)\n",
    "msg += '%d) ignore this column\\n' % (i+2)\n",
    "ignoring_key = i+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "013ffc69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++ Now parsing : file1 ++++++++++++++++\n",
      "displaying first 10 values of feature a (n_feature: 0)\n",
      "0    48\n",
      "1    87\n",
      "2    46\n",
      "3    84\n",
      "4    94\n",
      "5    18\n",
      "6    15\n",
      "7    30\n",
      "8    54\n",
      "9    46\n",
      "Name: a, dtype: int64\n",
      "specify data type for a:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) UNKNOWN \n",
      "6) ignore this column\n",
      "6\n",
      "Ignoring a\n",
      "displaying first 10 values of feature e (n_feature: 1)\n",
      "0    98\n",
      "1    83\n",
      "2    73\n",
      "3    45\n",
      "4    84\n",
      "5     5\n",
      "6    44\n",
      "7    55\n",
      "8    37\n",
      "9     8\n",
      "Name: e, dtype: int64\n",
      "specify data type for e:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) UNKNOWN \n",
      "6) ignore this column\n",
      "6\n",
      "Ignoring e\n",
      "displaying first 10 values of feature i (n_feature: 2)\n",
      "0    65\n",
      "1    13\n",
      "2    81\n",
      "3    81\n",
      "4     0\n",
      "5    57\n",
      "6    14\n",
      "7    98\n",
      "8    13\n",
      "9    89\n",
      "Name: i, dtype: int64\n",
      "specify data type for i:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) UNKNOWN \n",
      "6) ignore this column\n",
      "2\n",
      "<enum 'DataType'> DataType.QUANTITATIVE int64\n",
      "QuantitativeDataType.DISCRETE int64\n",
      "QuantitativeDataType.DISCRETE [dtype('int64')]\n",
      "Allow i to have missing values:\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "displaying first 10 values of feature o (n_feature: 3)\n",
      "0     5\n",
      "1    70\n",
      "2    96\n",
      "3    39\n",
      "4    15\n",
      "5    28\n",
      "6    29\n",
      "7    82\n",
      "8    19\n",
      "9    21\n",
      "Name: o, dtype: int64\n",
      "stopping nowInterrupted by user\n",
      "++++++++ Now parsing : contatct ++++++++++++++++\n",
      "displaying first 10 values of feature discrete (n_feature: 0)\n",
      "0    64.0\n",
      "1    26.0\n",
      "2    61.0\n",
      "3    29.0\n",
      "4    99.0\n",
      "5     5.0\n",
      "6    71.0\n",
      "7    99.0\n",
      "8    90.0\n",
      "9    36.0\n",
      "Name: discrete, dtype: float64\n",
      "stopping nowInterrupted by user\n",
      "++++++++ Now parsing : file2 ++++++++++++++++\n",
      "displaying first 10 values of feature 0 (n_feature: 0)\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: 0, dtype: bool\n",
      "stopping nowInterrupted by user\n"
     ]
    }
   ],
   "source": [
    "## CLI to use when dataset is available\n",
    "for tabular_data_file in datasets.keys():\n",
    "    data_format_file = {}\n",
    "    \n",
    "    print(f'++++++++ Now parsing : {tabular_data_file} ++++++++++++++++')\n",
    "    dataset = datasets[tabular_data_file]\n",
    "    dataset_columns = dataset.columns\n",
    "    for n_feature, feature in enumerate(dataset_columns):\n",
    "        is_column_parsed = False\n",
    "        is_info_given = False\n",
    "        is_missing_values_allowed = False\n",
    "        print(f'displaying first 10 values of feature {feature} (n_feature: {n_feature})')\n",
    "        pprint.pprint(dataset[feature].head(10))  # print first 10 lines of feature value\n",
    "        try:\n",
    "            while not is_column_parsed:\n",
    "                data_format_id = input(f'specify data type for {feature}:\\n' + msg )\n",
    "                if data_format_id.isdigit() and int(data_format_id) <= n_available_data_type+1:\n",
    "                    # check if value passed by user is correct (if it is integer,\n",
    "                    # and whithin range [1, n_available_data_type])\n",
    "                    is_column_parsed = True\n",
    "                \n",
    "                else:\n",
    "                    print(f'error ! {data_format_id} value not understood')\n",
    "                    \n",
    "        except KeyboardInterrupt as e:\n",
    "            print('stopping now' + str(e))\n",
    "        if not is_column_parsed:\n",
    "            break\n",
    "        if int(data_format_id) < ignoring_key:\n",
    "            \n",
    "            data_format = available_data_type[int(data_format_id)-1]\n",
    "        \n",
    "            data_type = dataset[feature].dtype\n",
    "            print(DataType, data_format, data_type)\n",
    "            data_type, types = get_data_type(DataType, data_format, data_type)\n",
    "            print(data_type, types)\n",
    "\n",
    "            is_missing_values = check_missing_data(dataset[feature])\n",
    "            if is_missing_values:\n",
    "                if data_type is DataType.KEY:\n",
    "                    raise ValueError('KEY should not contain any missing points')\n",
    "            if data_format is DataType.KEY or data_format is DataType.DATETIME:  \n",
    "                is_missing_values_allowed = False\n",
    "            else:\n",
    "                while not is_info_given:\n",
    "                    # set info\n",
    "                    missing_values_selection = input(f'Allow {feature} to have missing values:\\n'+msg_yes_or_no_question)\n",
    "                    if missing_values_selection.isdigit() and int(missing_values_selection) < 3:\n",
    "                        is_info_given = True\n",
    "\n",
    "                    else:\n",
    "                        print(f'error ! {missing_values_selection} value not understood')\n",
    "                is_missing_values_allowed = yes_or_no_question_key[missing_values_selection]\n",
    "\n",
    "            data_format_file[feature] = {'data_type': data_type,\n",
    "                                         'values': types,\n",
    "                                         'is_missing_values': is_missing_values_allowed}\n",
    "        else:\n",
    "            print(f'Ignoring {feature}')\n",
    "    data_format_files[tabular_data_file] = data_format_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ff5d5",
   "metadata": {},
   "source": [
    "#### data_format_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca423d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file1': {'a': {'data_type': <QuantitativeDataType.DISCRETE: [<class 'int'>, <class 'numpy.int64'>]>,\n",
       "   'values': [dtype('int64')],\n",
       "   'is_missing_values': True},\n",
       "  'e': {'data_type': <QuantitativeDataType.DISCRETE: [<class 'int'>, <class 'numpy.int64'>]>,\n",
       "   'values': [dtype('int64')],\n",
       "   'is_missing_values': True},\n",
       "  '0': {'data_type': <CategoricalDataType.BOOLEAN: [<class 'bool'>]>,\n",
       "   'values': [dtype('bool')],\n",
       "   'is_missing_values': True},\n",
       "  '1': {'data_type': <CategoricalDataType.BOOLEAN: [<class 'bool'>]>,\n",
       "   'values': [dtype('bool')],\n",
       "   'is_missing_values': False},\n",
       "  'time': {'data_type': 'DATETIME',\n",
       "   'values': ['DATETIME'],\n",
       "   'is_missing_values': False},\n",
       "  'pressure': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "   'values': [dtype('float64')],\n",
       "   'is_missing_values': False},\n",
       "  'sp02': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "   'values': [dtype('float64')],\n",
       "   'is_missing_values': False},\n",
       "  'a.1': {'data_type': <QuantitativeDataType.DISCRETE: [<class 'int'>, <class 'numpy.int64'>]>,\n",
       "   'values': [dtype('int64')],\n",
       "   'is_missing_values': False},\n",
       "  'gender': {'data_type': <CategoricalDataType.CHARACTER: [<class 'str'>, <class 'object'>]>,\n",
       "   'values': [dtype('O')],\n",
       "   'is_missing_values': True},\n",
       "  'blood type': {'data_type': <CategoricalDataType.CHARACTER: [<class 'str'>, <class 'object'>]>,\n",
       "   'values': [dtype('O')],\n",
       "   'is_missing_values': True},\n",
       "  'pkey': {'data_type': <KeyDataType.CHARACTER: [<class 'str'>, <class 'object'>]>,\n",
       "   'values': [dtype('O')],\n",
       "   'is_missing_values': False}},\n",
       " 'contatct': {'discrete': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "   'values': [dtype('float64')],\n",
       "   'is_missing_values': True},\n",
       "  'city': {'data_type': <CategoricalDataType.CHARACTER: [<class 'str'>, <class 'object'>]>,\n",
       "   'values': [dtype('O')],\n",
       "   'is_missing_values': True},\n",
       "  'pkey': {'data_type': <KeyDataType.CHARACTER: [<class 'str'>, <class 'object'>]>,\n",
       "   'values': [dtype('O')],\n",
       "   'is_missing_values': False}},\n",
       " 'file2': {'3': {'data_type': <CategoricalDataType.BOOLEAN: [<class 'bool'>]>,\n",
       "   'values': [dtype('bool')],\n",
       "   'is_missing_values': True},\n",
       "  'time': {'data_type': 'DATETIME',\n",
       "   'values': ['DATETIME'],\n",
       "   'is_missing_values': False},\n",
       "  'pH': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "   'values': [dtype('float64')],\n",
       "   'is_missing_values': True},\n",
       "  'pkey': {'data_type': <KeyDataType.CHARACTER: [<class 'str'>, <class 'object'>]>,\n",
       "   'values': [dtype('O')],\n",
       "   'is_missing_values': False}}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_format_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "887f090e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) YES\\n2) NO\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_yes_or_no_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d161776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you want to add a new view (file)?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "please add new view name:\n",
      "ll\n",
      "please add new feature name:\n",
      "ll\n",
      "specify data type for 0:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) UNKNOWN \n",
      "6) ignore this column\n",
      "4\n",
      "do you want to add a new variable (feature) ?1) YES\n",
      "2) NO\n",
      "2\n",
      "process done\n",
      "do you want to add a new view (file)?\n",
      "1) YES\n",
      "2) NO\n",
      "1\n",
      "please add new view name:\n",
      "kk\n",
      "please add new feature name:\n",
      "vkeof\n",
      "specify data type for 0:\n",
      "1) KEY \n",
      "2) QUANTITATIVE \n",
      "3) CATEGORICAL \n",
      "4) DATETIME \n",
      "5) UNKNOWN \n",
      "6) ignore this column\n",
      "3\n",
      "do you want to add a new variable (feature) ?1) YES\n",
      "2) NO\n",
      "2\n",
      "process done\n",
      "do you want to add a new view (file)?\n",
      "1) YES\n",
      "2) NO\n",
      "2\n",
      "process done\n"
     ]
    }
   ],
   "source": [
    "is_views_finished = False\n",
    "\n",
    "\n",
    "views_format_file = {}\n",
    "\n",
    "while not is_views_finished:\n",
    "    is_features_finished = False\n",
    "    resp = input('do you want to add a new view (file)?\\n' + msg_yes_or_no_question)\n",
    "    resp = yes_or_no_question_key.get(resp)\n",
    "    if not resp:\n",
    "        is_views_finished = True\n",
    "        print('process done')\n",
    "        continue\n",
    "    new_view = input('please add new view name:\\n')\n",
    "    while not is_features_finished:\n",
    "        feature_format_file = {}\n",
    "        new_feature = input('please add new feature name:\\n')\n",
    "        feature_format_file[new_feature] = {}\n",
    "        is_column_parsed = False\n",
    "        try:\n",
    "            while not is_column_parsed:\n",
    "                data_format_id = input(f'specify data type for {feature}:\\n' + msg )\n",
    "                if data_format_id.isdigit() and int(data_format_id) <= n_available_data_type+1:\n",
    "                    # check if value passed by user is correct (if it is integer,\n",
    "                    # and whithin range [1, n_available_data_type])\n",
    "                    is_column_parsed = True\n",
    "                \n",
    "                else:\n",
    "                    print(f'error ! {data_format_id} value not understood')\n",
    "                    \n",
    "        except KeyboardInterrupt as e:\n",
    "            print('stopping now' + str(e))\n",
    "        resp = input('do you want to add a new variable (feature) ?' + msg_yes_or_no_question)\n",
    "        resp = yes_or_no_question_key.get(resp)\n",
    "        if not resp:\n",
    "            is_features_finished = True\n",
    "            print('process done')\n",
    "            continue\n",
    "    views_format_file[new_view] = feature_format_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee0e0cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ll': {'ll': {}}, 'kk': {'vkeof': {}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_format_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42677fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded data format file\n",
    "\n",
    "data_format_file = {\n",
    "    'CDRSB.bl': {\n",
    "                 'data_type': CategoricalDataType.NUMERICAL,\n",
    "                'values': int,\n",
    "                'is_missing_values': False},\n",
    "    'ADAS11.bl':{'data_type': CategoricalDataType.NUMERICAL, \n",
    "                'values': int,\n",
    "                'is_missing_values': False},\n",
    "    \n",
    "    'MMSE.bl': {'data_type': CategoricalDataType.NUMERICAL, \n",
    "                'values': int,\n",
    "                'is_missing_values': False},\n",
    "    'RAVLT.immediate.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'RAVLT.learning.bl': {'data_type': CategoricalDataType.NUMERICAL, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'RAVLT.forgetting.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'FAQ.bl': {'data_type': CategoricalDataType.NUMERICAL, \n",
    "                'values': int,\n",
    "                'is_missing_values': False},\n",
    "    'WholeBrain.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'Ventricles.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'Hippocampus.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'MidTemp.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'Entorhinal.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'ABETA.MEDIAN.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'PTAU.MEDIAN.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'TAU.MEDIAN.bl': {'data_type': QuantitativeDataType.CONTINUOUS, \n",
    "                'values': float,\n",
    "                'is_missing_values': False},\n",
    "    'AGE': {'data_type': QuantitativeDataType.DISCRETE, \n",
    "                'values': int,\n",
    "                'is_missing_values': False}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb165f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDRSB.bl</th>\n",
       "      <th>ADAS11.bl</th>\n",
       "      <th>MMSE.bl</th>\n",
       "      <th>RAVLT.immediate.bl</th>\n",
       "      <th>RAVLT.learning.bl</th>\n",
       "      <th>RAVLT.forgetting.bl</th>\n",
       "      <th>FAQ.bl</th>\n",
       "      <th>WholeBrain.bl</th>\n",
       "      <th>Ventricles.bl</th>\n",
       "      <th>Hippocampus.bl</th>\n",
       "      <th>MidTemp.bl</th>\n",
       "      <th>Entorhinal.bl</th>\n",
       "      <th>ABETA.MEDIAN.bl</th>\n",
       "      <th>PTAU.MEDIAN.bl</th>\n",
       "      <th>TAU.MEDIAN.bl</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.739439</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.821573</td>\n",
       "      <td>3</td>\n",
       "      <td>0.684331</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>154.016065</td>\n",
       "      <td>67.970509</td>\n",
       "      <td>132.571916</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.933800</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.001653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735892</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>211.573206</td>\n",
       "      <td>5.451168</td>\n",
       "      <td>33.787719</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.987722</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.876316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738731</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>163.637668</td>\n",
       "      <td>66.704378</td>\n",
       "      <td>110.049924</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.314425</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.733481</td>\n",
       "      <td>3</td>\n",
       "      <td>0.696179</td>\n",
       "      <td>0.032797</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>182.256297</td>\n",
       "      <td>47.091893</td>\n",
       "      <td>138.690457</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.217830</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.225401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841806</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>247.997479</td>\n",
       "      <td>-5.997140</td>\n",
       "      <td>-61.573234</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>61.896022</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.663102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767153</td>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.012879</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>231.706787</td>\n",
       "      <td>24.632786</td>\n",
       "      <td>87.065806</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.083170</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.241477</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695168</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>146.949187</td>\n",
       "      <td>57.588115</td>\n",
       "      <td>121.985248</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.289059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.437600</td>\n",
       "      <td>7</td>\n",
       "      <td>0.628691</td>\n",
       "      <td>0.041537</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>181.805672</td>\n",
       "      <td>55.052669</td>\n",
       "      <td>157.229102</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.650504</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.669603</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714763</td>\n",
       "      <td>0.020461</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.013989</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>178.824412</td>\n",
       "      <td>69.412821</td>\n",
       "      <td>103.238647</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.089863</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.703384</td>\n",
       "      <td>4</td>\n",
       "      <td>0.691858</td>\n",
       "      <td>0.030349</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>180.781989</td>\n",
       "      <td>32.978001</td>\n",
       "      <td>54.780563</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CDRSB.bl  ADAS11.bl  MMSE.bl  RAVLT.immediate.bl  RAVLT.learning.bl  \\\n",
       "0           1          8     27.0           23.739439                4.0   \n",
       "1           0          0     30.0           64.933800                9.0   \n",
       "2           0          8     24.0           36.987722                3.0   \n",
       "3           0          3     29.0           50.314425                5.0   \n",
       "4           0          0     30.0           57.217830                9.0   \n",
       "..        ...        ...      ...                 ...                ...   \n",
       "995         1          2     29.0           61.896022                8.0   \n",
       "996         0          1     29.0           62.083170                8.0   \n",
       "997         3         14     24.0           22.289059                2.0   \n",
       "998         0         13     26.0           31.650504                2.0   \n",
       "999         0         15     28.0           29.089863                3.0   \n",
       "\n",
       "     RAVLT.forgetting.bl  FAQ.bl  WholeBrain.bl  Ventricles.bl  \\\n",
       "0               5.821573       3       0.684331       0.012699   \n",
       "1               4.001653       0       0.735892       0.012803   \n",
       "2               6.876316       0       0.738731       0.030492   \n",
       "3               4.733481       3       0.696179       0.032797   \n",
       "4               7.225401       0       0.841806       0.004030   \n",
       "..                   ...     ...            ...            ...   \n",
       "995             1.663102       0       0.767153       0.011417   \n",
       "996             5.241477       1       0.695168       0.011908   \n",
       "997             5.437600       7       0.628691       0.041537   \n",
       "998             1.669603       4       0.714763       0.020461   \n",
       "999             7.703384       4       0.691858       0.030349   \n",
       "\n",
       "     Hippocampus.bl  MidTemp.bl  Entorhinal.bl  ABETA.MEDIAN.bl  \\\n",
       "0          0.003786    0.012678       0.002214       154.016065   \n",
       "1          0.004866    0.015071       0.003041       211.573206   \n",
       "2          0.004300    0.012419       0.002316       163.637668   \n",
       "3          0.004720    0.012312       0.002593       182.256297   \n",
       "4          0.006820    0.016948       0.002896       247.997479   \n",
       "..              ...         ...            ...              ...   \n",
       "995        0.005209    0.012879       0.002208       231.706787   \n",
       "996        0.004641    0.012534       0.002197       146.949187   \n",
       "997        0.003478    0.010870       0.001939       181.805672   \n",
       "998        0.004713    0.013989       0.001981       178.824412   \n",
       "999        0.004237    0.011439       0.002419       180.781989   \n",
       "\n",
       "     PTAU.MEDIAN.bl  TAU.MEDIAN.bl   AGE  \n",
       "0         67.970509     132.571916  75.0  \n",
       "1          5.451168      33.787719  67.0  \n",
       "2         66.704378     110.049924  63.0  \n",
       "3         47.091893     138.690457  75.0  \n",
       "4         -5.997140     -61.573234  65.0  \n",
       "..              ...            ...   ...  \n",
       "995       24.632786      87.065806  76.0  \n",
       "996       57.588115     121.985248  77.0  \n",
       "997       55.052669     157.229102  74.0  \n",
       "998       69.412821     103.238647  64.0  \n",
       "999       32.978001      54.780563  65.0  \n",
       "\n",
       "[1000 rows x 16 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9881289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDRSB.bl': {'data_type': <CategoricalDataType.NUMERICAL: [<class 'float'>, <class 'int'>, <class 'numpy.float64'>, <class 'numpy.int64'>]>,\n",
       "  'values': int,\n",
       "  'is_missing_values': False},\n",
       " 'ADAS11.bl': {'data_type': <CategoricalDataType.NUMERICAL: [<class 'float'>, <class 'int'>, <class 'numpy.float64'>, <class 'numpy.int64'>]>,\n",
       "  'values': int,\n",
       "  'is_missing_values': False},\n",
       " 'MMSE.bl': {'data_type': <CategoricalDataType.NUMERICAL: [<class 'float'>, <class 'int'>, <class 'numpy.float64'>, <class 'numpy.int64'>]>,\n",
       "  'values': int,\n",
       "  'is_missing_values': False},\n",
       " 'RAVLT.immediate.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'RAVLT.learning.bl': {'data_type': <CategoricalDataType.NUMERICAL: [<class 'float'>, <class 'int'>, <class 'numpy.float64'>, <class 'numpy.int64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'RAVLT.forgetting.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'FAQ.bl': {'data_type': <CategoricalDataType.NUMERICAL: [<class 'float'>, <class 'int'>, <class 'numpy.float64'>, <class 'numpy.int64'>]>,\n",
       "  'values': int,\n",
       "  'is_missing_values': False},\n",
       " 'WholeBrain.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'Ventricles.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'Hippocampus.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'MidTemp.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'Entorhinal.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'ABETA.MEDIAN.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'PTAU.MEDIAN.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'TAU.MEDIAN.bl': {'data_type': <QuantitativeDataType.CONTINUOUS: [<class 'float'>, <class 'numpy.float64'>]>,\n",
       "  'values': float,\n",
       "  'is_missing_values': False},\n",
       " 'AGE': {'data_type': <QuantitativeDataType.DISCRETE: [<class 'int'>]>,\n",
       "  'values': int,\n",
       "  'is_missing_values': False}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_format_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb7ad297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.dtype[float64]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(dataset[feature].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63dbaad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_add_numeric_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_see_also_doc',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_binop',\n",
       " '_cacher',\n",
       " '_can_hold_na',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_convert',\n",
       " '_convert_dtypes',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_duplicated',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_from_mgr',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_index_resolvers',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_get_values_tuple',\n",
       " '_get_with',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_index',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_init_dict',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_item_cache',\n",
       " '_ixs',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_map_values',\n",
       " '_maybe_update_cacher',\n",
       " '_memory_usage',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_name',\n",
       " '_needs_reindex_multi',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_indexer',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_replace_single',\n",
       " '_repr_data_resource_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_labels',\n",
       " '_set_name',\n",
       " '_set_value',\n",
       " '_set_values',\n",
       " '_set_with',\n",
       " '_set_with_engine',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'array',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'autocorr',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'clip',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'divmod',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'factorize',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'hasnans',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'interpolate',\n",
       " 'is_monotonic',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'map',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'name',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'ravel',\n",
       " 'rdiv',\n",
       " 'rdivmod',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'repeat',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'searchsorted',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_frame',\n",
       " 'to_hdf',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_list',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_sql',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unique',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae52ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
