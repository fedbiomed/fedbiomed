{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Fed-BioMed Researcher base example\n",
            "\n",
            "This example uses MNIST dataset. Please check `README.md` file in `notebooks` directory for the instructions to load MNIST dataset and configure nodes.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Define an experiment model and parameters"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Declare a torch training plan MyTrainingPlan class to send for training on the node"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "from torch.optim import Adam\n",
            "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
            "from fedbiomed.common.datamanager import DataManager\n",
            "from torchvision import transforms\n",
            "from fedbiomed.common.dataset import MnistDataset\n",
            "\n",
            "# Here we define the training plan to be used.\n",
            "# You can use any class name (here 'MyTrainingPlan')\n",
            "class MyTrainingPlan(TorchTrainingPlan):\n",
            "    class Net(nn.Module):\n",
            "        def __init__(self, model_args):\n",
            "            super().__init__()\n",
            "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
            "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
            "            self.dropout1 = nn.Dropout(0.25)\n",
            "            self.dropout2 = nn.Dropout(0.5)\n",
            "            self.fc1 = nn.Linear(9216, 128)\n",
            "            self.fc2 = nn.Linear(128, 10)\n",
            "\n",
            "        def forward(self, x):\n",
            "            x = self.conv1(x)\n",
            "            x = F.relu(x)\n",
            "            x = self.conv2(x)\n",
            "            x = F.relu(x)\n",
            "            x = F.max_pool2d(x, 2)\n",
            "            x = self.dropout1(x)\n",
            "            x = torch.flatten(x, 1)\n",
            "            x = self.fc1(x)\n",
            "            x = F.relu(x)\n",
            "            x = self.dropout2(x)\n",
            "            x = self.fc2(x)\n",
            "            output = F.log_softmax(x, dim=1)\n",
            "            return output\n",
            "\n",
            "    def init_model(self, model_args):\n",
            "        return self.Net(model_args = model_args)\n",
            "\n",
            "    def init_optimizer(self, optimizer_args):\n",
            "        return Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
            "\n",
            "    def init_dependencies(self):\n",
            "        return [\"from fedbiomed.common.dataset import MnistDataset\",\n",
            "                \"from torchvision import transforms\",\n",
            "                \"from torch.optim import Adam\"]\n",
            "\n",
            "    def training_data(self):\n",
            "        transform = transforms.Normalize((0.1307,), (0.3081,))\n",
            "        dataset1 = MnistDataset(transform=transform)\n",
            "        loader_arguments = {'shuffle': True}\n",
            "        return DataManager(dataset1, **loader_arguments)\n",
            "\n",
            "    def training_step(self, data, target):\n",
            "        output = self.model().forward(data)\n",
            "        loss   = torch.nn.functional.nll_loss(output, target)\n",
            "        return loss\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "from torch.optim import Adam\n",
            "from torchvision import  transforms\n",
            "\n",
            "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
            "from fedbiomed.common.datamanager import DataManager\n",
            "from fedbiomed.common.dataset import MnistDataset\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Model arguments and training arguments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "pycharm": {
               "name": "#%%\n"
            }
         },
         "outputs": [],
         "source": [
            "from fedbiomed.common.metrics import MetricTypes\n",
            "model_args = {}\n",
            "\n",
            "training_args = {\n",
            "    'loader_args': { 'batch_size': 1, }, \n",
            "    'optimizer_args': {\n",
            "        \"lr\" : 1e-3\n",
            "    },\n",
            "    # 'test_ratio' : 0.25,\n",
            "    # 'test_batch_size': 64,\n",
            "    # 'test_metric': MetricTypes.F1_SCORE,\n",
            "    # 'test_on_global_updates': True,\n",
            "    # 'test_on_local_updates': True,\n",
            "    # 'test_metric_args': {'average': 'marco'},\n",
            "    # 'use_gpu': True,  # automatically falls back to cpu on nodes that don't support gpu\n",
            "    'epochs': 1, \n",
            "    'dry_run': False,  \n",
            "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Create and run the experiment"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "pycharm": {
               "name": "#%%\n"
            },
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "from fedbiomed.researcher.federated_workflows import Experiment\n",
            "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
            "\n",
            "tags =  ['#MNIST', '#dataset']\n",
            "rounds = 5\n",
            "\n",
            "exp = Experiment(tags=tags,\n",
            "                 model_args=model_args,\n",
            "                 training_plan_class=MyTrainingPlan,\n",
            "                 training_args=training_args,\n",
            "                 round_limit=rounds,\n",
            "                 aggregator=FedAverage(),\n",
            "                 tensorboard=True,\n",
            "                 node_selection_strategy=None)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tensorboard_dir = exp.tensorboard_results_path\n",
            "tensorboard_dir"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Uncomment fr tensorboard \n",
            "# %load_ext tensorboard\n",
            "# %tensorboard --logdir \"$tensorboard_dir\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "pycharm": {
               "name": "#%%\n"
            },
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "exp.run()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "exp.run_once(increase=True)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Save trained model to file"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "try: \n",
            "    exp.training_plan().export_model('./trained_model')\n",
            "except Exception as e:\n",
            "    print(e)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Display results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "pycharm": {
               "name": "#%%\n"
            }
         },
         "outputs": [],
         "source": [
            "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
            "\n",
            "print(\"\\nList the nodes for the last training round and their timings : \")\n",
            "round_data = exp.training_replies()[rounds - 1]\n",
            "for r in round_data.values():\n",
            "    print(\"\\t- {id} :\\\n",
            "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
            "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
            "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
            "        rtraining = r['timing']['rtime_training'],\n",
            "        ptraining = r['timing']['ptime_training'],\n",
            "        rtotal = r['timing']['rtime_total']))\n",
            "print('\\n')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Federated parameters for each round are available via `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
            "\n",
            "For example you can view the federated parameters for the last round of the experiment :"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(\"\\nList the training rounds : \", exp.aggregated_params().keys())\n",
            "\n",
            "print(\"\\nAccess the federated params for the last training round :\")\n",
            "print(\"\\t- parameter data: \", exp.aggregated_params()[rounds - 1]['params'].keys())\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
