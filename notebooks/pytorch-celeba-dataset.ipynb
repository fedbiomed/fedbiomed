{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed-BioMed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates using a convolutional model in PyTorch for recognition of smiling faces, with a CelebA dataset split over 2 nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "\n",
    "Install the CelebA dataset with the help of the [`README.md`](data/Celeba/README.md), inside the [`notebooks/data` folder](./data/Celeba).\n",
    "The script create 3 nodes with each their data. The dataset of the node 3 is used in this notebook as a testing set.  \n",
    "Therefore its not necessary to create a node and run the node 3  \n",
    "\n",
    "Before using script make sure the correct environment is setup, for the node environement, run : `source ./scripts/fedbiomed_environment node`  \n",
    "For the sake of testing the resulting model, this file uses the data from node 1 and 2 for training and the data from node 3 to test.\n",
    "You can create multiple nodes by adding a config parameter to the command controlling nodes, for example :  \n",
    "creating 2 nodes for training :  \n",
    " - `./scripts/fedbiomed_run node config node1.ini start`\n",
    " - `./scripts/fedbiomed_run node config node2.ini start`  \n",
    " \n",
    "adding data for each node :  \n",
    " - `./scripts/fedbiomed_run node config node1.ini add`\n",
    " - `./scripts/fedbiomed_run node config node2.ini add`\n",
    "\n",
    "It is necessary to previously configure at least 1 node:\n",
    "1. `./scripts/fedbiomed_run node config (ini file) add`\n",
    "  * Select option 4 (images) to add an image dataset to the node\n",
    "  * Add a name (eg: 'celeba') and the tag for the dataset (tag should contain `#celeba` as it is the tag used for this training) and finaly add the description\n",
    "  * Pick a data folder from the 3 generated inside `data/Celeba/celeba_preprocessed` (eg: `data_node_1`)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node config (ini file) list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node config (ini file) start`. Wait until you get `Starting task manager`. it means you are online.\n",
    "\n",
    "For the sake of testing the resulting model, only nodes 1 and 2 were started during training, datas from node 3 is used to test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a TorchTrainingPlan Net class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from fedbiomed.common.data import DataManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class CelebaTrainingPlan(TorchTrainingPlan):\n",
    "         \n",
    "    # Defines model \n",
    "    def init_model(self):\n",
    "        model = self.Net()\n",
    "        return model \n",
    "    \n",
    "    # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torch.utils.data import Dataset\",\n",
    "                \"from torchvision import transforms\",\n",
    "                \"import pandas as pd\",\n",
    "                \"from PIL import Image\",\n",
    "                \"import os\",\n",
    "                \"import numpy as np\"]\n",
    "        return deps\n",
    "\n",
    "    # Torch modules class\n",
    "    class Net(nn.Module):\n",
    "        \n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            #convolution layers\n",
    "            self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "            self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "            self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            # classifier\n",
    "            self.fc1 = nn.Linear(3168, 128)\n",
    "            self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.conv4(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "        \n",
    "        # we dont load the full data of the images, we retrieve the image with the get item. \n",
    "        # in our case, each image is 218*178 * 3colors. there is 67533 images. this take at leas 7G of ram\n",
    "        # loading images when needed takes more time during training but it wont impact the ram usage as much as loading everything\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "    # The training_data creates the Dataloader to be used for training in the \n",
    "    # general class Torchnn of fedbiomed\n",
    "    def training_data(self):\n",
    "        dataset = self.CelebaDataset(self.dataset_path + \"/target.csv\", self.dataset_path + \"/data/\")\n",
    "        train_kwargs = {'shuffle': True}\n",
    "        return DataManager(dataset, **train_kwargs)\n",
    "    \n",
    "    # This function must return the loss to backward it \n",
    "    def training_step(self, data, target):\n",
    "        \n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3\n",
    "    }, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the federated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#celeba']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=CelebaTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the federated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model = exp.training_plan().model()\n",
    "fed_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a little testing routine to extract the accuracy metrics on the testing dataset\n",
    "## Important\n",
    "This is done to test the model because it can be accessed in a developpement environment  \n",
    "In production, the data wont be accessible on the nodes, we will need a test dataset on the server or accessible from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    device = \"cpu\"\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    loader_size = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            #only uses 10% of the dataset, results are similar but faster\n",
    "            if idx >= loader_size / 10:\n",
    "                pass\n",
    "                break\n",
    "\n",
    "    \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/(data_loader.batch_size * idx)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset is the data from the third node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset_path = \"./data/Celeba/celeba_preprocessed/data_node_3\"\n",
    "\n",
    "class CelebaDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, txt_path, img_dir, transform=None):\n",
    "        df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_path = txt_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Smiling'].values\n",
    "        self.transform = transform\n",
    "        print(\"celeba dataset finished\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "        img = transforms.ToTensor()(img)\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "\n",
    "dataset = CelebaDataset(test_dataset_path + \"/target.csv\", test_dataset_path + \"/data/\")\n",
    "train_kwargs = { 'shuffle': True}\n",
    "data_loader = DataLoader(dataset, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the testing dataset and computing accuracy metrics for local and federated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_federated = testing_Accuracy(fed_model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc_federated[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e89561e616b27d96972869796636c18d9df047835da4fde0d47d1d63cf19e486"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
