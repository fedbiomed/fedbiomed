{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Depth Experiment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment class provides an interface that you can manage your experiment with backward compatibility. It means that even your Experiment has been built/defined you will be able to configure its parameters. This feature will provide more control over your experiment even after your running your experiment for several rounds. In this tutorial, detailed experiment interface will be explained using MNIST basic example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Environment\n",
    "Before running this notebook, you need to configure your environment by completing following steps:\n",
    "\n",
    "### Starting the Network Component\n",
    "Please run following command to start Network component that provided communication between your notebook and the node;\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run network\n",
    "```\n",
    "<div class=\"note\">\n",
    "<p>This command will launch docker containers. Therefore, please make sure that your Docker engine is up and running.</p>\n",
    "</div>\n",
    "\n",
    "### Deploying MNIST Dataset in the None\n",
    "Please run following command to add MNIST dataset into your Node. This command will deploy MNIST dataset in your default node whose config file is located in `{FEDBIOMED_DIR}/etc` directory as `config_node.ini`\n",
    "\n",
    "After running following command, please select data type `2) default`, use default `tags` and select the folder where MNIST dataset will be saved.\n",
    "\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node add\n",
    "```\n",
    "\n",
    "### Starting the Node\n",
    " After you have successfully completed previous step, please run following command to start your node.\n",
    "\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Training Plan\n",
    "\n",
    "Before declaring an experiment, the training plan that will be used for federated training should be defined. The model that is goÄ±ng to be used is exactly the same training plan that has been created in the Basic MNIST tutorial. We recommend you to follow Basic MNIST tutorial on PyTorch Framework to understand following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Experiment Step by Step  \n",
    "\n",
    "The experiment class can be created without passing any argument. This will just build an empty experiment object. Afterwards, you will be able to define your arguments using setters of the experiment object.\n",
    "\n",
    "\n",
    "<div class=\"note\"><p>It is always possible to create a fully configured experiment by passing all arguments during the initialization. You can also create your experiment with some of the arguments and set the other arguments after.</p></div>\n",
    "\n",
    "### Building an Empty Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building an empty experiment you won't be able to perform federated training, since it is not fully configured. That's why the output of the initialization will always remind you that the experiment is not fully configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "exp = Experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Current Status of Experiment\n",
    "As an addition to output of the initialization, to find out more about the current status of the experiment, you can call the `info()` method of your experiment object. This method will print the information about your experiment and what you should complete to be able to start your federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output, some arguments are defined with default values, while others are not. Model arguments, training arguments, tags, round limit, training data etc. have no default value, and they are required to be set. However, these arguments are related to each other. For example, to be able to define your federated training data you need to define the `tags` first, and then while setting your training data argument, experiment will be able to send search request to the nodes to receive information about the datasets. These relations between the arguments will be explained in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Training Plan for The Experiment\n",
    "\n",
    "The training plan that is going to be used for training can be set in the experiment using the method `set_training_plan_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_training_plan_class(training_plan_class=MyTrainingPlan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting The Training Plan path (Special Case)\n",
    "The `set_training_plan_path` is used in the case where you don't define the training plan directly in the notebook, but rather import it from a python module file. In this case, the `training_plan_file` argument is used to specify the module file's directory. However, the experiment also needs to know your class name. You specify your class name as a **`string`** with `set_training_plan_class` method. Thus the backend knows which class to use in the module file.\n",
    "\n",
    "```python\n",
    "exp.set_training_plan_path(training_plan_path='path/to/your/script.py')\n",
    "exp.set_training_plan_class(training_plan_class='TrainingPlanClassAsString')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Model and Training Arguments\n",
    "In the previous step, the model has been defined for your experiment. Now, you can define your model arguments and training arguments that will be used respectively for building your model class and training your model on the node side. The methods `set_model_args` and `set_training_args` of the experiment class will allow you to set these arguments.\n",
    "\n",
    "<div class=\"\">\n",
    "    <p>There isn't any requirement on the order of defining model class and mode/training arguments. It is also possible to\n",
    "        define model/training arguments first and model class after. \n",
    "    </p>    \n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model arguments should be an empty Dict, since our model does not require \n",
    "# any argument for initialization\n",
    "model_args = {}\n",
    "\n",
    "# Training Arguments\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3, \n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "exp.set_model_args(model_args=model_args)\n",
    "exp.set_training_args(training_args=training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags for the dataset search request can be set using `set_tags` method of experiment object. \n",
    "\n",
    "<br><div class=\"note\"><p>Setting tags does not mean sending dataset search request. Search request is sent while setting training data. `tags` is the argument that is required for the search request.</p></div>\n",
    "\n",
    "The arguments `tags` of `set_tags` method should be an array of tags which are in `string` type or just a tag in `string` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['#MNIST', '#dataset']\n",
    "exp.set_tags(tags = tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the tags that are set, you can run `tags()` method of experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Nodes\n",
    "The `nodes` arguments indicates the nodes that are going to be used for the experiment. By default, it is equal to `None` which means every node up and running will be part of the experiment as long as they have the dataset that is going to be used for training. If the `nodes` has been set in advance, the search request for the dataset search will be sent only the nodes that are indicated. You can set nodes using the method `set_nodes(noes=nodes)`. This method takes `nodes` argument which should be an array of node ids which are in `string` type or just a single node id as `string`.\n",
    "\n",
    "Since the node ids can change randomly, to make this notebook runnable in all environments, we won't be setting nodes for the experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Training Data\n",
    "Training data is a `FederatedDataSet` instance which comes from the module `fedbiomed.researcher.datasets`. There are several ways to define your training data.\n",
    "\n",
    "1. You can run `set_training_data(training_data=None, from_tags=True)`. This will send search request to the nodes to get dataset information by using the `tags` which are defined before.\n",
    "2. You can provide `training_data` argument which is an instance of `FederatedDataSet`. \n",
    "3. You can provide `training_data` argument as python `dict` and setter will create a `FederatedDataSet` object by itself.\n",
    "\n",
    "While using the last option please make sure that your `dict` object is configured as coherent to `FederatedDataSet` schema. Otherwise, you might get error while running your experiment.\n",
    "\n",
    "A `FederatedDataSet` object must have **one unique** dataset per node to ensure training uses only one dataset for each node. This is checked and enforced when creating a `FederatedDataSet`\n",
    "\n",
    "If you run `set_training_data(training_data=None)`. No training data is defined yet for the experiment (`training_data` is set to `None`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = exp.set_training_data(training_data=None, from_tags=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it will send search request to the nodes, the output will inform you about selected nodes for training. It means that those nodes have the dataset and able to train your model.\n",
    "\n",
    "`set_training_data` will return a `FederatedDataSet` object. You can either use the return value of the setter or the getter for training data which is `training_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = exp.training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the result in detail you can call the method `data()` of the `FederatedDataSet` object. This will return a python dictionary that includes information about the datasets that has been found in the nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is mentioned before, setting training data once doesn't mean that you can't change it. You can create a new `FederatedDataSet` with a `dict` that includes the information about the datasets. This will allow you to select the datasets that will be used for federated training.\n",
    "\n",
    "<div class=\"note\"><p>Since the dataset information will be provided, there will be no need to send request to the nodes</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.datasets import FederatedDataSet \n",
    "\n",
    "tr_data = training_data.data()\n",
    "federated_dataset = FederatedDataSet(tr_data)\n",
    "exp.set_training_data(training_data = federated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can directly use `tr_data` in `set_training_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_training_data(training_data = tr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"note\">\n",
    "    <p>\n",
    "        If you change the tags for the dataset by using <code>set_tags</code> and if there is already a defined training data in your experiment object, you have to update your training data by running <code>exp.set_training_data(training_data=None)</code>.  \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting an Aggregator  \n",
    "\n",
    "An aggregator is one of the required arguments for the experiment. It is used for aggregating model parameters that are received from the nodes after every round. By default, when the experiment is initialized without passing any aggregator, it will automatically use the default `FedAverage` aggregator class. However, it is also possible to set a different aggregation algorithm with the method `set_aggregator`. Currently, Fed-BioMed has only `FedAverage` but it is possible to create a custom aggregator classes.\n",
    "\n",
    "You can see the current aggregator by running `exp.aggregator()`. It will return the aggregator object that will be used for aggregation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.aggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we supposed that you have created your own aggregator, you can set it as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "exp.set_aggregator(aggregator=FedAverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your aggregator class needs initialization parameters, you can build your class and pass as an object ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_average = FedAverage()\n",
    "exp.set_aggregator(aggregator=fed_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Node Selection Strategy\n",
    "\n",
    "Node selection Strategy is also one of the required arguments for the experiment. It is used for selecting nodes before each round of training. Since the strategy will be used for selecting nodes, before setting the strategy, training data should be already set. Then, strategy will be able to which nodes are current with their dataset.\n",
    "\n",
    "By default, `set_strategy(node_selection_strategy=None)` will use the default `DefaultStrategy` class. It is default strategy that selects all the nodes available with their datasets at the moment. However, it is also possible to set different strategies. Currently, Fed-BioMed has only `DefaultStrategy` but you can create your custom strategy classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_strategy(node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can directly pass `DefaultStrategy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "exp.set_strategy(node_selection_strategy=DefaultStrategy)\n",
    "\n",
    "# To make the strategy has been set\n",
    "exp.strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Round Limit\n",
    "\n",
    "Round limit is the limit that indicates max number of rounds of the training. By default, it is `None` and it needs to be set before running your experiment. You can set the round limit with the method `set_round_limit`. Round limit can  be changed after running one or several rounds of training. You can always execute `exp.round_limit()` to see current round limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_round_limit(round_limit=2)\n",
    "exp.round_limit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Job to Manage Federated Training Rounds\n",
    "\n",
    "Job is a class that manages federated training rounds. Before setting job, strategy for selecting nodes, model and training data should be set. Therefore, please make sure that they all defined before setting job.  The method `set_job` creates the Job instance and it does not take any argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_job()\n",
    "exp.job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Secure Aggregation\n",
    "\n",
    "Secure aggregation enables nodes to send encrypted updates to the researcher. Thus researcher cannot read cleartext updates from the nodes. Nevertheless, researcher can aggregate updates from the nodes. The aggregated model parameters are then in cleartext, and the researcher can read them.\n",
    "\n",
    "The method `use_secagg` toggles usage of secure aggregation. When `True`, a secure aggregation context (cryptographic material) for the experiment is negotiated between the experiment parties (if not existing yet) or existing secure aggregation context is re-used. Then usage of secure aggregation by the experiment is activated.\n",
    "\n",
    "Secure aggregation needs at least 2 active nodes in the experiment (thus 3 parties including the researcher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_use_secagg(use_secagg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status()}\\n- secagg_id {exp_servkey.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_servkey.context()}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status()}\\n- secagg_id {exp_biprime.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_biprime.context()}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_use_secagg(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlling Experiment Status Before Starting Training Rounds\n",
    "Now, let's see if our experiment is ready for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the experiment is ready, you will see the message that says `Experiment can be run now (fully defined)` at the bottom of the output. So now, we can run the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running The Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as `info()` says that the experiment is fully defined you will be able to run your experiment. Experiment has two methods  as `run()` and `run_once()` for running training rounds.\n",
    "\n",
    " - `run()` runs the experiment rounds from current round to round limit. If the round limit is reached it will indicate that the round limit has been reach. However, the method `run` takes to arguments as `round` and `increase`. \n",
    "    - `round` is an integer that indicates number of rounds that are going to be run. If the experiment is at round `0`, the round limit is `4`, and if you pass `round` as 3, it will run the experiment only for `3` rounds.\n",
    "    - `increase` is a boolean that indicates whether round limit should be increased if the given `round` pass over the round limit. For example, if the current round is `3`, the round limit is `4`, and the `round` argument is `2`, the experiment will increase round limit to `5`\n",
    "    \n",
    " - `run_once()` runs the experiment for single round of training. If the round limit is reached it will indicate that the round limit has been reach. However, if it is executed as `run_once(increase=True)` when the round limit is reach, it increases the round limit for one round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the experiment for once, you can check the current round. It returns `1` which means only one round has been run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.round_current()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the experiment with `run_once()` again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the round limit has been set to `2` the round limit had been reached. If you try to run `run()` or `run_once()` the experiment will indicate that the round limit has been reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this point, if you would like to run the experiment you can increase round limit with `set_round_limit(round)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_round_limit(4)\n",
    "print('Round Limit    : ' , exp.round_limit())\n",
    "print('Current Round  : ' , exp.round_current())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The round limit of the experiment has been set to `4` and the completed number of rounds is `2`. It means if you run the experiment with method `run()` without passing any argument, it will run the experiment for `2` rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the current round status of the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Round Limit    : ' , exp.round_limit())\n",
    "print('Current Round  : ' , exp.round_current())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to run our experiment if the round limit is reached is passing `rounds` to the method `run()`. For example, following cell will run the experiment for `2` more rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(rounds=2, increase=True) # increase is True by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the argument `increase` is `False`, it will not increase the round limit automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(rounds=2, increase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Round Limit    : ' , exp.round_limit())\n",
    "print('Current Round  : ' , exp.round_current())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to increase number of rounds while running the experiment with `run_once()` by passing `increase` argument as `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Round Limit    : ' , exp.round_limit())\n",
    "print('Current Round  : ' , exp.round_current())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Training Arguments for the Next Round\n",
    "\n",
    "The method `set_training_args()` allows you to change the training arguments even you've already run your experiment several times. Thanks to the method `set_training_args()` you will be able to configure your training from one round to another. For example, we can change our `batch_size` to `64` and `batch_maxnum` to `50` for the next round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = {\n",
    "    'batch_size': 64, \n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 50\n",
    "}\n",
    "\n",
    "exp.set_training_args(training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conclusions \n",
    "The experiment class is the interface and the orchestrator of the whole processes behind federated training on the researcher side. It allows you to manage your federated training experiment easily. It has been extended with setter and getter methods to ease its declaration. This also provides more control before, during or after the training rounds. The purpose of the experiment class is to provide a robust interface for end-user to make them able to easily perform their federated training on Fed-BioMed nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
