{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process for Approved Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fed-BioMed offers a feature to run only the pre-approved models on the nodes. The nodes which receive your model might require approved models. Therefore, if the node accepts only the approved model, the model files that are sent by a researcher with the training request should be approved by the node side in advance. In this workflow, the approval process is done by a real user/person who reviews the code contained in the model file. The reviewer makes sure the model doesn't contain any code that might cause privacy issues or harm the node.\n",
    "\n",
    "In this tutorial, we will be creating a node with activated model approval option.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Node\n",
    "\n",
    "\n",
    "Enabling model approval can be done both from config file or Fed-BioMed CLI while starting the node. The process of creating and starting a node with model approval option is not so different from setting up a normal node. By default, if no option is specified in the CLI when the node is launched for the first time, the node disables model approval in the security section of the config file. It then looks like the snippet below :\n",
    "\n",
    "```shell\n",
    "[security]\n",
    "hashing_algorithm = SHA256\n",
    "allow_default_models = True\n",
    "model_approval = False\n",
    "```\n",
    "The Fed-BioMed CLI has two optional extra parameters `--enable-model-approval` and `--allow-default-models` to activate model approval. They choose the config file options, when the node is launched for the first time. They enable one-time override of the config file options at each launch of the node.\n",
    "\n",
    "* `--enable-model-approval` : This parameter enables model approval for the node. If there isn't a config file for the node while running CLI, it creates a new config file with enabled model approval mode `model_approval = True`. \n",
    "* `--allow-default-models`  : This parameter allows default models for train requests. These are the models that come for Fed-BioMed tutorials. For example, the model for MNIST dataset that we will be using for this tutorial. If the default models are enabled, node updates/registers model files which are located in `envs/common/default_models` directory during the starting process of the node. This option has no effect if model approval is not enabled.\n",
    "\n",
    "\n",
    "### Adding MNIST Dataset to The Node. \n",
    "\n",
    "In this section we will add MNIST dataset to the node. While adding the dataset through CLI we'll also specify `--enable-model-approval` and `--allow-default-models` options. This will create new `config-n1.ini` file with following configuration. \n",
    "\n",
    "```\n",
    "[security]\n",
    "hashing_algorithm = SHA256\n",
    "allow_default_models = True\n",
    "model_approval = True\n",
    "\n",
    "```\n",
    "Now, let's run the following command. \n",
    "\n",
    "```shell\n",
    "$ {FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n1.ini --enable-model-approval --allow-default-models add \n",
    "```\n",
    "\n",
    "The CLI will ask you to select the dataset type. Since we will be working on MNIST dataset, please select `2` (default) and continue by typing `y` for the next prompt and select folder that you want to store MNIST dataset. Afterward, if you go to `etc` directory of fedbiomed, you can see `config-n1.ini` file. \n",
    "\n",
    "### Starting the Node\n",
    "\n",
    "Now you can start your node by running following command; \n",
    "\n",
    "```\n",
    "$ {FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n1.ini start\n",
    "```\n",
    "\n",
    "Since config file has been configured to enable model approval mode, you do not need to specify any extra parameter while starting the node. But it is also possible to start node with `--enable-model-approval`, `--allow-default-models` or `--disable-model-approval`, `--disable-default-models`. If you start your node with `--disable-model-approval` it will disable model approval even it is enabled in the config file.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating An Experiment\n",
    "\n",
    "In this section we will be using default MNIST model which has been already registered by the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model is the model that will be sent to the node for training. Since the model files are processed by the Experiment to configure dependencies, import part of the final file might be different from this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlan, self).__init__(model_args)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to get/see the final model file we need to initialize the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Final Model File From Experiment\n",
    "\n",
    "`model_file()` displays the model file that will be sent to the nodes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_file(display = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `exp.check_model_status()` sends request to the nodes to check whether the model is approved or not. The nodes that will receive the requests are the nodes that have been found after searching datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = exp.check_model_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs should indicate that the model is approved. You can also get status object from the result of the `check_model_status()`. It returns a list of status objects each for different node. Since we have only launched a single node, it returns only one status object. \n",
    "\n",
    "* `approval_obligation` : Indicates whether the model approval is enabled in the node.  \n",
    "* `status`         : Indicates model status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Model And Testing Model Approval Status\n",
    "\n",
    "Let's change the model codes and test whether it is approved or not. We will be changing the network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MyTrainingPlan, self).__init__(model_args)\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        \n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}        \n",
    "        return DataManager(dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        loss += 1\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update model path using `set_model_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.set_model_class(MyTrainingPlan)\n",
    "# update job since model_path has been changed\n",
    "exp.set_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we changed the model code, the output of the following method should say that the model is not approved by the node and `is_approved` key of the result object should be equal to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = exp.check_model_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is not approved, you won't be able to train your model in the node and experiment will return an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering/Approving the Model \n",
    "\n",
    "To register/approve the model that has been created in the previous section, we can use Fed-BioMed CLI.\n",
    "In Fed-Biomed, there are two ways of approving a model: \n",
    " 1. By sending an `ApprovalRequest` to the `Node`\n",
    " 2. By adding it directly to the `Node` through model registration facility\n",
    " \n",
    "### 1. Approving a Model through an `ApprovalRequest`\n",
    "\n",
    "Fed-BioMed 's `Experiment` interface provides a method to submit a model to the `Node`, for approval. `Node` can then review the code and approve the model using cli or gui.\n",
    "\n",
    "The method of `Experiment` sending such request is `model_approve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_approve(MyTrainingPlan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been sent, we need to approve it (or reject it) on `Node` side.\n",
    "For that, use the following command on a new terminal:\n",
    "\n",
    "```shell\n",
    "$ {FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n1.ini --approve-model\n",
    "```\n",
    "\n",
    "Models with both `Pending` or `Rejected` status will be displayed. Select the model you have sent to approve it. You might see a message explaining that model has successfully been approved.\n",
    "\n",
    "Let's check it status by running the `check_model_status` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_model_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's status must have changed from `Pending` status to `Approved`, which means model can be trained from now on on the `Node`. `Researcher` can now run an `Experiment` on the `Node`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Registering a Model through Node interface\n",
    "\n",
    "You do not need to stop your node to register new models, you can perfom registration process in a different terminal window. However, first we need to get final model from `exp` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.model_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `exp.model_file()` is a file path that shows where the final model is saved. It also prints the content of the model file. You can either get the content of model from the output cell or the path where it is save. Anyway, you need to create a new `txt` file and copy the model content in it. You can create new directory in Fed-BioMed called `models` and inside it, you can create new `my-model.txt` file and copy the model content into it.\n",
    "\n",
    "\n",
    "```shell\n",
    "$ mkdir {FEDBIOMED_DIR}/my_approved_model\n",
    "$ cp <model_path_file> {FEDBIOMED_DIR}/my_approved_model/my_model.txt\n",
    "```\n",
    "Where `<model_path_file>` is the path of the model that is returned by `exp.model_file(display=False)`\n",
    "\n",
    "Afterward, please run the following command in other terminal to register model file.\n",
    "\n",
    "```shell\n",
    "$ {FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n1.ini --register-model\n",
    "```\n",
    "\n",
    "You should type a unique name for your model e.g. 'MyTestModel-1' and a description. The CLI will ask you select model file you want to register. Select the file that you saved and continue.\n",
    "\n",
    "Now, you should be able to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_model_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejecting model\n",
    "\n",
    "On `Node` side, it is possible to reject a Model using cli or GUI. Every type of model can be `Rejected`, even `Default` models. In Fed-BioMed, `Rejected` means that model cannot be trained on the `Node` (but model is still `Registered` into the database).\n",
    "\n",
    "Using cli, `Node` can run:\n",
    "\n",
    "```shell\n",
    "$ {FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n1.ini --reject-model\n",
    "```\n",
    "\n",
    "and select the model to be `Rejected`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_model_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
