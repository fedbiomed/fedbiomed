{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fedbiomed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 15:27:55,784 fedbiomed INFO - Component environment:\n",
      "2021-12-16 15:27:55,785 fedbiomed INFO - - type = ComponentType.RESEARCHER\n",
      "2021-12-16 15:27:56,801 fedbiomed INFO - Messaging researcher_860a6809-2bc7-47ed-8f94-423486e71805 successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x1067374f0>\n",
      "2021-12-16 15:27:56,864 fedbiomed INFO - Listing available datasets in all nodes... \n",
      "2021-12-16 15:27:57,053 fedbiomed INFO - log from: node_4f0f6a9a-a2d6-4e17-a448-7c853bcf561f / DEBUG - Message received: {'researcher_id': 'researcher_860a6809-2bc7-47ed-8f94-423486e71805', 'command': 'list'}\n",
      "2021-12-16 15:27:57,072 fedbiomed INFO - log from: node_a6c386ed-2df1-40d9-9bdd-89c7606c8581 / DEBUG - Message received: {'researcher_id': 'researcher_860a6809-2bc7-47ed-8f94-423486e71805', 'command': 'list'}\n",
      "2021-12-16 15:28:06,885 fedbiomed INFO - \n",
      " Node: node_4f0f6a9a-a2d6-4e17-a448-7c853bcf561f | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] | mednist       | [14738, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n",
      "2021-12-16 15:28:06,887 fedbiomed INFO - \n",
      " Node: node_a6c386ed-2df1-40d9-9bdd-89c7606c8581 | Number of Datasets: 1 \n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "| name    | data_type   | tags        | description   | shape              |\n",
      "+=========+=============+=============+===============+====================+\n",
      "| mednist | images      | ['mednist'] | mednist       | [14736, 3, 64, 64] |\n",
      "+---------+-------------+-------------+---------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_4f0f6a9a-a2d6-4e17-a448-7c853bcf561f': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': 'mednist',\n",
       "   'shape': [14738, 3, 64, 64]}],\n",
       " 'node_a6c386ed-2df1-40d9-9bdd-89c7606c8581': [{'name': 'mednist',\n",
       "   'data_type': 'images',\n",
       "   'tags': ['mednist'],\n",
       "   'description': 'mednist',\n",
       "   'shape': [14736, 3, 64, 64]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the client up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 3 (images) to add MedNIST to the client\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MedNIST is contained\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Connected with result code 0`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+'/')\n",
    "model_file = tmp_dir_model.name + '/class_export_mednist.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import set_determinism, first\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstD,\n",
    "    Compose,\n",
    "    LoadImageD,\n",
    "    RandRotateD,\n",
    "    RandZoomD,\n",
    "    ScaleIntensityRanged,\n",
    "    EnsureTypeD,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.config import print_config, USE_COMPILED\n",
    "from monai.networks.nets import GlobalNet\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.apps import MedNISTDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : write **only** the code to export in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstD,\n",
    "    Compose,\n",
    "    LoadImageD,\n",
    "    RandRotateD,\n",
    "    RandZoomD,\n",
    "    ScaleIntensityRanged,\n",
    "    EnsureTypeD,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.config import print_config, USE_COMPILED\n",
    "from monai.networks.nets import GlobalNet\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.apps import MedNISTDataset\n",
    "\n",
    "# Here we define the model to be used. \n",
    "class MyMonaiTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, kwargs):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"import numpy as np\",\n",
    "                \"import os\",\n",
    "                \"from torch.nn import MSELoss\",\n",
    "                \"from monai.utils import set_determinism, first\",\n",
    "                \"from monai.transforms import (EnsureChannelFirstD,Compose,LoadImageD,RandRotateD,RandZoomD,ScaleIntensityRanged,EnsureTypeD,)\",\n",
    "                \"from monai.data import DataLoader, Dataset, CacheDataset\",\n",
    "                \"from monai.config import print_config, USE_COMPILED\",\n",
    "                \"from monai.networks.nets import GlobalNet\",\n",
    "                \"from monai.networks.blocks import Warp\",\n",
    "                \"from monai.apps import MedNISTDataset\",]\n",
    "        self.add_dependency(deps)\n",
    "        #self.num_class =  kwargs['num_class']\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        self.model = GlobalNet(\n",
    "            image_size=(64, 64),\n",
    "            spatial_dims=2,\n",
    "            in_channels=2,  # moving and fixed\n",
    "            num_channel_initial=16,\n",
    "            depth=3).to(device)\n",
    "        self.image_loss = MSELoss()\n",
    "        if USE_COMPILED:\n",
    "            self.warp_layer = Warp(3, \"border\").to(device)\n",
    "        else:\n",
    "            self.warp_layer = Warp(\"bilinear\", \"border\").to(device)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "        \n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MedNIST data\n",
    "        # custom MedNISTDataset to be created?\n",
    "        train_data = MedNISTDataset(root_dir=self.dataset_path, section=\"training\", download=False, transform=None)\n",
    "        training_datadict = [\n",
    "            {\"fixed_hand\": item[\"image\"], \"moving_hand\": item[\"image\"]}\n",
    "            for item in train_data.data if item[\"label\"] == 4  # label 4 is for xray hands\n",
    "        ]\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImageD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "                EnsureChannelFirstD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "                ScaleIntensityRanged(keys=[\"fixed_hand\", \"moving_hand\"],\n",
    "                                     a_min=0., a_max=255., b_min=0.0, b_max=1.0, clip=True,),\n",
    "                RandRotateD(keys=[\"moving_hand\"], range_x=np.pi/4, prob=1.0, keep_size=True, mode=\"bicubic\"),\n",
    "                RandZoomD(keys=[\"moving_hand\"], min_zoom=0.9, max_zoom=1.1, prob=1.0, mode=\"bicubic\", align_corners=False),\n",
    "                EnsureTypeD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "            ]\n",
    "        )\n",
    "        train_ds = CacheDataset(data=training_datadict[:1000], transform=train_transforms,\n",
    "                                cache_rate=1.0, num_workers=4)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 2}\n",
    "        train_loader = DataLoader(train_ds, **train_kwargs)\n",
    "        \n",
    "        return train_loader\n",
    "\n",
    "    # to be modified\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, moving, fixed):\n",
    "        output = self.forward(data)\n",
    "        loss   = self.image_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the client side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the client side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {'num_class':6,}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 20, \n",
    "    'lr': 1e-5, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum':250 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of client ID with `clients`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `client_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['mednist']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #clients=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='MyMonaiTrainingPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available in `exp.training_replies` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies.keys())\n",
    "\n",
    "print(\"\\nList the clients for the last training round and their timings : \")\n",
    "round_data = exp.training_replies[rounds - 1].data\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies[rounds - 1].dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available in `exp.aggregated_params` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params.keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params[rounds - 1]['params'].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()\n",
    "\n",
    "data_dir = '/Users/balelli/Downloads/MedNIST_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir)\n",
    "                     if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "test_split = int(0.1 * length)\n",
    "test_indices = indices[:test_split]\n",
    "\n",
    "test_x = [image_files_list[i] for i in test_indices]\n",
    "test_y = [image_class[i] for i in test_indices]\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet121(spatial_dims=2, in_channels=1,\n",
    "                    out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "max_epochs = 4\n",
    "val_interval = 1\n",
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.model_instance\n",
    "model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
