{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed-BioMed secure aggregation tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=+2>\n",
    "    Warning: secure aggregation is a work in progress. In current version it is not fully implement and does not provide any effective security/functionality. This notebook exists only for demonstration purposes.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example experimentation setup\n",
    "\n",
    "This part contains setup of a basic example for Fed-BioMed. At this point, nothing is specific to secure aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting nodes up\n",
    "It is necessary to previously configure ** at least two nodes**:\n",
    "1. `./scripts/fedbiomed_run node config config_node1.ini add` (respectively for the second node: `./scripts/fedbiomed_run node config config_node2.ini add`)\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due to a pytorch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run config config_node1.ini node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run config_node1.ini node run`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an experiment model and parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch training plan MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare and run the experiment\n",
    "\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secure aggregation setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check experiment's secure aggregation status: no context is configured yet, experiment doesn't use secure integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status()}\\n- secagg_id {exp_servkey.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_servkey.context()}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status()}\\n- secagg_id {exp_biprime.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_biprime.context()}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negotiate a secure aggregation cryptographic context among experiment parties (researcher and nodes), providing a sufficient `timeout` for the negotiation.\n",
    "If context negotation is successful, require experiment to use secure aggregation from now on (`use_secagg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.set_use_secagg(use_secagg=True, timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check experiment's secure aggregation status: a context exists and secure aggregation is activated, experiment uses secure integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status()}\\n- secagg_id {exp_servkey.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_servkey.context()}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status()}\\n- secagg_id {exp_biprime.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_biprime.context()}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, using secure aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc secure aggregation commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can toggle off/on whether secure aggregation is used. Note that *same* secure aggregation context is used, it does not need to negotiate a new context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_use_secagg(False)\n",
    "exp.set_use_secagg(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status()}\\n- secagg_id {exp_servkey.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_servkey.context()}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status()}\\n- secagg_id {exp_biprime.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_biprime.context()}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use breakpoints along with secure aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_save_breakpoints(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaded_exp = Experiment.load_breakpoint()\n",
    "loaded_exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", loaded_exp.use_secagg())\n",
    "exp_servkey, exp_biprime = loaded_exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status()}\\n- secagg_id {exp_servkey.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_servkey.context()}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status()}\\n- secagg_id {exp_biprime.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_biprime.context()}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate usage: you can setup secure aggregation from the experiment constructor, instead of using `set_use_secagg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp2 = Experiment(tags=tags,\n",
    "                  model_args=model_args,\n",
    "                  training_plan_class=MyTrainingPlan,\n",
    "                  training_args=training_args,\n",
    "                  round_limit=rounds,\n",
    "                  aggregator=FedAverage(),\n",
    "                  node_selection_strategy=None,\n",
    "                  use_secagg=True,\n",
    "                  secagg_timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check experiment's secure aggregation status: a context exists and secure aggregation is activated, experiment uses secure integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex: direct use of secure aggregation contexts\n",
    "\n",
    "Secure aggregation contexts can be used directly, without using an experiment. This is currently mainly for education and debug usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover online nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "\n",
    "requests = Requests()\n",
    "nodes = requests.ping_nodes()\n",
    "print(f'Online nodes:\\n {nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build parties list for secagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "\n",
    "parties = [environ['RESEARCHER_ID']] + nodes\n",
    "if not len(parties) >= 3:\n",
    "    print(\"Need at least 3 parties for secure aggregation\")\n",
    "print(f'Secure aggregation parties:\\n {parties}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup secagg with all online nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a successful secagg context negotiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecaggServkeyContext\n",
    "\n",
    "secagg_servkey = SecaggServkeyContext(parties, 'DUMMY_JOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "secagg_servkey.setup()\n",
    "print(\"Status: \", secagg_servkey.status())\n",
    "print(\"Context: \", secagg_servkey.context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecaggBiprimeContext\n",
    "\n",
    "secagg_biprime = SecaggBiprimeContext(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "secagg_biprime.setup(timeout=10)\n",
    "print(\"Status: \", secagg_biprime.status())\n",
    "print(\"Context: \", secagg_biprime.context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle timeouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `timeout` is unsufficient for completing context negotiation, it fails with a timeout error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecaggServkeyContext\n",
    "secagg_servkey2 = SecaggServkeyContext(parties, 'DUMMY_JOB')\n",
    "secagg_servkey2.setup(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Status: \", secagg_servkey2.status())\n",
    "print(\"Context: \", secagg_servkey2.context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retry negotiation with a sufficient timeout: secagg context is now successfully established (manages fails/retries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "secagg_servkey2.setup()\n",
    "print(\"Status: \", secagg_servkey2.status())\n",
    "print(\"Context: \", secagg_servkey2.context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it may also succeed with a short timeout (like `secagg_servkey2.setup(1.5)` if you wait long enough before retrying so that the secagg computation completes in the meantime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle `job_id`\n",
    "\n",
    "If another job tries to use the servkey secagg context element, then it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_servkey.set_job_id('ANOTHER_JOB')\n",
    "secagg_servkey.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this does not apply to biprime secagg context element, as they don't use `job_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clean out secagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_servkey2.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Status: \", secagg_servkey2.status())\n",
    "print(\"Context: \", secagg_servkey2.context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_biprime.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Note: `secagg_servkey.delete()` would fail as it lost track of the successfully established context after changing `job_id` and trying to setup another context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_servkey.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
