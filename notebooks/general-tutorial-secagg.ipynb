{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed-BioMed secure aggregation tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=+2>\n",
    "    Warning: secure aggregation is a work in progress. In current version it is not fully implement and does not provide any effective security/functionality. This notebook exists only for demonstration purposes.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example experimentation setup\n",
    "\n",
    "This part contains setup of a basic example for Fed-BioMed. At this point, nothing is specific to secure aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting nodes up\n",
    "It is necessary to previously configure ** at least two nodes**:\n",
    "1. `./scripts/fedbiomed_run node config config_node1.ini add` (respectively for the second node: `./scripts/fedbiomed_run node config config_node2.ini add`)\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is downloaded (this is due to a pytorch issue https://github.com/pytorch/vision/issues/3549)\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run config config_node1.ini node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run config_node1.ini node run`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an experiment model and parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch training plan MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare and run the experiment\n",
    "\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secure aggregation setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check experiment's secure aggregation status: no context is configured yet, experiment doesn't use secure integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status()}\\n- secagg_id {exp_servkey.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_servkey.context()}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status()}\\n- secagg_id {exp_biprime.secagg_id ()}\" \\\n",
    "        f\"\\n- context {exp_biprime.context()}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negotiate a secure aggregation cryptographic context among experiment parties (researcher and nodes).\n",
    "If context negotation is successful, require experiment to use secure aggregation from now on (`use_secagg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.set_use_secagg(use_secagg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check experiment's secure aggregation status: a context exists and secure aggregation is activated, experiment uses secure integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status}\\n- secagg_id {exp_servkey.secagg_id}\" \\\n",
    "        f\"\\n- context {exp_servkey.context}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status}\\n- secagg_id {exp_biprime.secagg_id}\" \\\n",
    "        f\"\\n- context {exp_biprime.context}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, using secure aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc secure aggregation commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can toggle off/on whether secure aggregation is used. Note that *same* secure aggregation context is used, it does not need to negotiate a new context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_use_secagg(False)\n",
    "exp.set_use_secagg(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", exp.use_secagg())\n",
    "exp_servkey, exp_biprime = exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status}\\n- secagg_id {exp_servkey.secagg_id}\" \\\n",
    "        f\"\\n- context {exp_servkey.context}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status}\\n- secagg_id {exp_biprime.secagg_id}\" \\\n",
    "        f\"\\n- context {exp_biprime.context}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use breakpoints along with secure aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_save_breakpoints(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaded_exp = Experiment.load_breakpoint()\n",
    "loaded_exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using secagg: \", loaded_exp.use_secagg())\n",
    "exp_servkey, exp_biprime = loaded_exp.secagg_context()\n",
    "if exp_servkey:\n",
    "    print(f\"Secagg servkey:\\n- status {exp_servkey.status}\\n- secagg_id {exp_servkey.secagg_id}\" \\\n",
    "        f\"\\n- context {exp_servkey.context}\")\n",
    "else:\n",
    "    print(\"No secagg servkey\")\n",
    "if exp_biprime:\n",
    "    print(f\"Secagg biprime:\\n- status {exp_biprime.status}\\n- secagg_id {exp_biprime.secagg_id}\" \\\n",
    "        f\"\\n- context {exp_biprime.context}\")\n",
    "else:\n",
    "    print(\"No secagg biprime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate usage: you can setup secure aggregation from the experiment constructor, instead of using `set_use_secagg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp2 = Experiment(tags=tags,\n",
    "                  model_args=model_args,\n",
    "                  training_plan_class=MyTrainingPlan,\n",
    "                  training_args=training_args,\n",
    "                  round_limit=rounds,\n",
    "                  aggregator=FedAverage(),\n",
    "                  node_selection_strategy=None,\n",
    "                  use_secagg=True,\n",
    "                  secagg_timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check experiment's secure aggregation status: a context exists and secure aggregation is activated, experiment uses secure integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annex: direct use of secure aggregation contexts\n",
    "\n",
    "Secure aggregation contexts can be used directly, without using an experiment. This is currently mainly for education and debug usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover online nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "\n",
    "requests = Requests()\n",
    "nodes = requests.ping_nodes()\n",
    "print(f'Online nodes:\\n {nodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build parties list for secagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "\n",
    "parties = [environ['RESEARCHER_ID']] + nodes\n",
    "if not len(parties) >= 3:\n",
    "    print(\"Need at least 3 parties for secure aggregation\")\n",
    "print(f'Secure aggregation parties:\\n {parties}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup secagg with all online nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a successful secagg context negotiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecaggServkeyContext\n",
    "\n",
    "secagg_servkey = SecaggServkeyContext(parties, 'DUMMY_JOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "secagg_servkey.setup()\n",
    "print(\"Status: \", secagg_servkey.status)\n",
    "print(\"Context: \", secagg_servkey.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecaggBiprimeContext\n",
    "\n",
    "secagg_biprime = SecaggBiprimeContext(parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "secagg_biprime.setup()\n",
    "print(\"Status: \", secagg_biprime.status)\n",
    "print(\"Context: \", secagg_biprime.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option for biprime is to use a default biprime number (eg `default_biprime0`) added in the database during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_biprime2 = SecaggBiprimeContext(parties, 'default_biprime0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_biprime2.setup()\n",
    "print(\"Status: \", secagg_biprime2.status)\n",
    "print(\"Context: \", secagg_biprime2.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle timeouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `timeout` is unsufficient for receiving nodes answers after context negotation, it fails with a timeout error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecaggServkeyContext\n",
    "secagg_servkey2 = SecaggServkeyContext(parties, 'DUMMY_JOB')\n",
    "\n",
    "try:\n",
    "    secagg_servkey2.setup(0.01)\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\")\n",
    "    print(\"Timeout might not be enough to receive nodes answers\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, nevertheless, negotiation successfully completes (after the timeout). This may not be the case for more complex failure scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Status: \", secagg_servkey2.status)\n",
    "print(\"Context: \", secagg_servkey2.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before retrying negotiation, we need to clean context for this `secagg_id` on all parties: negotiation may have succeeded on some parties, so they would not re-negotiate as they already have a context for this `secagg_id`.\n",
    "\n",
    "A simpler option is to create a new `SecaggServkeyContext()` object, so no cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_value = secagg_servkey2.delete()\n",
    "print(\"Return value: \", return_value)\n",
    "print(\"Status: \", secagg_servkey2.status)\n",
    "print(\"Context: \", secagg_servkey2.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retry negotiation with a sufficient timeout: secagg context is now successfully established (manages fails/retries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "secagg_servkey2.setup()\n",
    "print(\"Status: \", secagg_servkey2.status)\n",
    "print(\"Context: \", secagg_servkey2.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it may also succeed with a short timeout (like `secagg_servkey2.setup(1.5)` if you wait long enough before retrying so that the secagg computation completes in the meantime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle `job_id`\n",
    "\n",
    "If another job tries to use the servkey secagg context element, then it fails, either immediatly (all the parties have the wrong context element in their database) or at most after the underlying MP-SPDZ timeout (60 seconds) if some parties don't have the element in their database (and thus try to negotiate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secagg_servkey.set_job_id('ANOTHER_JOB')\n",
    "try:\n",
    "    secagg_servkey.setup()\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\")\n",
    "    print(\"Secagg context element negotiation failed\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this does not apply to biprime secagg context element, as they don't use `job_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clean out secagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Status: \", secagg_servkey.status)\n",
    "print(\"Context: \", secagg_servkey.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "secagg_servkey.set_job_id('DUMMY_JOB')\n",
    "return_value = secagg_servkey.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Return value: \", return_value)\n",
    "print(\"Status: \", secagg_servkey.status)\n",
    "print(\"Context: \", secagg_servkey.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Status: \", secagg_biprime.status)\n",
    "print(\"Context: \", secagg_biprime.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "return_value = secagg_biprime.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Return value: \", return_value)\n",
    "print(\"Status: \", secagg_biprime.status)\n",
    "print(\"Context: \", secagg_biprime.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": false
   },
   "source": [
    "Note: `secagg_servkey.delete()` would fail as it lost track of the successfully established context after changing `job_id` and trying to setup another context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default biprime cannot be deleted from database. If you try to delete one, you'll receive an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    secagg_biprime2.delete()\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\")\n",
    "    print(\"Cannot delete a default biprime\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
