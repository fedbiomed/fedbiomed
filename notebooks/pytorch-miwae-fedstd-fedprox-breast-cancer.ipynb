{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data imputation with Fedbiomed using MIWAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show:\n",
    "* how to obtain mean and std in a federated manner, to perform afterwards local dataset standardization with respect to the global dataset\n",
    "* how to impute missing not at random (MAR) data in a federated setting using MIWAE (https://arxiv.org/abs/2006.12871). \n",
    "\n",
    "We will compare results of federated training using FedAvg, FedProx (with both local standardization and federated standardization), with local results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment we will use the breast cancer data from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_train:  404\n",
      "mean_train:  [3.60912463e+00 1.15693069e+01 1.09850495e+01 7.17821782e-02\n",
      " 5.56484158e-01 6.31589109e+00 6.85564356e+01 3.80819505e+00\n",
      " 9.35643564e+00 4.04032178e+02 1.83183168e+01 3.56278342e+02\n",
      " 1.24573515e+01]\n",
      "std_train:  [8.86406744e+00 2.31238090e+01 6.88607935e+00 2.58126901e-01\n",
      " 1.17558710e-01 7.08573178e-01 2.79602535e+01 2.12858714e+00\n",
      " 8.57908366e+00 1.65966869e+02 2.22594093e+00 9.14531376e+01\n",
      " 7.10157559e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train test split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data, target, test_size=0.20, random_state=42)\n",
    "df_data_train = pd.DataFrame(data_train)\n",
    "N_train = len(df_data_train)\n",
    "mean_train = np.mean(data_train,0)\n",
    "std_train = np.std(data_train,0)\n",
    "\n",
    "print(\"N_train: \",N_train)\n",
    "print(\"mean_train: \",mean_train)\n",
    "print(\"std_train: \",std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_train_post 404\n",
      "mean_train_post [3.60912463e+00 1.15693069e+01 1.09850495e+01 7.17821782e-02\n",
      " 5.56484158e-01 6.31589109e+00 6.85564356e+01 3.80819505e+00\n",
      " 9.35643564e+00 4.04032178e+02 1.83183168e+01 3.56278342e+02\n",
      " 1.24573515e+01]\n",
      "std_train_post [8.86436413e+00 2.31246317e+01 6.88614271e+00 2.58134386e-01\n",
      " 1.17559296e-01 7.08579110e-01 2.79608726e+01 2.12859150e+00\n",
      " 8.57923305e+00 1.65969122e+02 2.22596627e+00 9.14558358e+01\n",
      " 7.10158461e+00]\n"
     ]
    }
   ],
   "source": [
    "# split train across datasets\n",
    "client_1, client_2, client_3 = np.split(df_data_train.sample(frac=1,random_state=42), \\\n",
    "                                        [int(.33*N_train), int(.66*len(df_data_train))])\n",
    "\n",
    "Clients_data=[client_1, client_2, client_3]\n",
    "\n",
    "N_cl = [len(i) for i in Clients_data]\n",
    "mean_cl = [np.nanmean(i,0) for i in Clients_data]\n",
    "std_cl = [np.nanstd(i,0) for i in Clients_data]\n",
    "cl = len(Clients_data)\n",
    "\n",
    "N_train_post = sum(N_cl)\n",
    "mean_train_post = sum([N_cl[i]*np.array(mean_cl[i])/N_train_post for i in range(cl)])\n",
    "std_train_post = np.sqrt(sum([((N_cl[i]-1)*np.array(std_cl[i])**2+N_cl[i]*np.array(mean_cl[i])**2)/(N_train_post-cl) for i in range(cl)])-(N_train_post/(N_train_post-cl))*mean_train_post**2)\n",
    "\n",
    "#std_train_post_0=std_cl[0]\n",
    "#mean_train_post_0=mean_cl[0]\n",
    "#N_cl_0=N_cl[0]\n",
    "\n",
    "#for c in range(1,cl):\n",
    "#    std_train_post_1=np.sqrt(((N_cl_0-1)*np.array(std_train_post_0)**2+\\\n",
    "#                          (N_cl[c]-1)*np.array(std_cl[c])**2+\\\n",
    "#                          N_cl_0*N_cl[c]*np.power(mean_train_post_0-mean_cl[c],2)\\\n",
    "#                          /(N_cl_0+N_cl[c]))/(N_cl_0+N_cl[c]-1))\n",
    "#    mean_train_post_1=sum([N_cl[i]*np.array(mean_cl[i])/N_train_post for i in range(c+1)])\n",
    "#    std_train_post_0 = np.copy(std_train_post_1)\n",
    "#    mean_train_post_0 = np.copy(mean_train_post_1)\n",
    "#    N_cl_0+=N_cl[c]\n",
    "\n",
    "#while n_cl_0<=cl:\n",
    "#    mean_train_post_0=sum([N_cl[i]*np.array(mean_cl[i])/N_train_post for i in range(n_cl_0+1)])\n",
    "\n",
    "print(\"N_train_post\", N_train_post)\n",
    "print(\"mean_train_post\", mean_train_post)\n",
    "print(\"std_train_post\",std_train_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from each dataset we will remove randomly 50% of data\n",
    "np.random.seed(1234)\n",
    "\n",
    "# 50% of missing data for client 1, 30% for client 2, 60% for client 3\n",
    "perc_miss_list = [0.5,0.3,0.6] \n",
    "\n",
    "Clients_missing = []\n",
    "for perc,c in enumerate(Clients_data):\n",
    "    perc_miss=perc_miss_list[perc]\n",
    "    n = c.shape[0] # number of observations\n",
    "    p = c.shape[1] # number of features\n",
    "    xmiss = np.copy(c)\n",
    "    #xmiss = (xmiss - np.mean(xmiss,0))/np.std(xmiss,0)\n",
    "    xmiss_flat = xmiss.flatten()\n",
    "    miss_pattern = np.random.choice(n*p, np.floor(n*p*perc_miss).astype(np.int_),\\\n",
    "                                    replace=False)\n",
    "    xmiss_flat[miss_pattern] = np.nan \n",
    "    xmiss = xmiss_flat.reshape([n,p]) # in xmiss, the missing values are represented by nans\n",
    "    mask = np.isfinite(xmiss) # binary mask that indicates which values are missing\n",
    "    Clients_missing.append(xmiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([65, 70, 62, 72, 64, 65, 73, 62, 63, 70, 72, 63, 64]), array([ 89,  87,  96,  91,  89,  92,  91,  88,  97, 102,  98,  96,  95]), array([61, 50, 48, 57, 51, 54, 58, 58, 59, 58, 63, 50, 51])]\n",
      "[215 207 206 220 204 211 222 208 219 230 233 209 210]\n",
      "N_train_post after missing [215 207 206 220 204 211 222 208 219 230 233 209 210]\n",
      "mean_train_post after missing [3.07500809e+00 1.11014493e+01 1.12669903e+01 7.72727273e-02\n",
      " 5.58312745e-01 6.34579147e+00 7.05545045e+01 3.82085865e+00\n",
      " 9.24657534e+00 4.15421739e+02 1.83309013e+01 3.51897033e+02\n",
      " 1.23715238e+01]\n",
      "std_train_post after missing [8.04864157e+00 2.30081521e+01 6.92799094e+00 2.67054724e-01\n",
      " 1.10852174e-01 7.53521123e-01 2.74137196e+01 2.09178388e+00\n",
      " 8.56198414e+00 1.67620328e+02 2.22012681e+00 9.87384587e+01\n",
      " 6.58858144e+00]\n"
     ]
    }
   ],
   "source": [
    "p = Clients_missing[0].shape[1]\n",
    "N_cl = [np.array([Clients_missing[c][:,dim].size - np.count_nonzero(np.isnan(Clients_missing[c][:,dim])) for dim in range(p)]) for c in range(cl)]\n",
    "print(N_cl)\n",
    "mean_cl = [np.nanmean(i,0) for i in Clients_missing]\n",
    "std_cl = [np.nanstd(i,0) for i in Clients_missing]\n",
    "cl = len(Clients_missing)\n",
    "\n",
    "N_train_post = np.array(sum([N_cl[c] for c in range(cl)]))\n",
    "print(N_train_post)\n",
    "mean_train_post = np.array(sum([N_cl[i]*mean_cl[i]/N_train_post for i in range(cl)]))\n",
    "std_train_post = np.sqrt(sum([((N_cl[i]-1)*(std_cl[i]**2)+N_cl[i]*(mean_cl[i]**2))/(N_train_post-cl) for i in range(cl)])-(N_train_post/(N_train_post-cl))*mean_train_post**2)\n",
    "\n",
    "print(\"N_train_post after missing\", N_train_post)\n",
    "print(\"mean_train_post after missing\", mean_train_post)\n",
    "print(\"std_train_post after missing\",std_train_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clients_missing_norm = []\n",
    "for data in Clients_missing:\n",
    "    data_norm = np.copy(data)\n",
    "    data_norm = (data_norm - mean_train_post)/std_train_post\n",
    "    Clients_missing_norm.append(data_norm)\n",
    "\n",
    "import os \n",
    "os.makedirs('data/clients_data', exist_ok=True) \n",
    "for i in range(len(Clients_missing)):\n",
    "    pd.DataFrame(Clients_missing[i]).to_csv('data/clients_data/client_'+str(i+1)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean centralized after missing [3.07500809e+00 1.11014493e+01 1.12669903e+01 7.72727273e-02\n",
      " 5.58312745e-01 6.34579147e+00 7.05545045e+01 3.82085865e+00\n",
      " 9.24657534e+00 4.15421739e+02 1.83309013e+01 3.51897033e+02\n",
      " 1.23715238e+01]\n",
      "std centralized after missing [8.05344570e+00 2.30072840e+01 6.92754048e+00 2.67023694e-01\n",
      " 1.10866213e-01 7.53666761e-01 2.74117840e+01 2.09158817e+00\n",
      " 8.56207122e+00 1.67622662e+02 2.21998097e+00 9.88107497e+01\n",
      " 6.58763897e+00]\n"
     ]
    }
   ],
   "source": [
    "### We centralize all data to evaluate mean and std with missing\n",
    "#print([i.shape for i in Clients_missing])\n",
    "Clients_missing_tot = np.concatenate(Clients_missing,axis=0)\n",
    "#print(Clients_missing_tot.shape)\n",
    "mean_clients_missing = np.nanmean(Clients_missing_tot,0)\n",
    "std_clients_missing = np.nanstd(Clients_missing_tot,0)\n",
    "\n",
    "print(\"mean centralized after missing\", mean_clients_missing)\n",
    "print(\"std centralized after missing\", std_clients_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.std_mean(torch.from_numpy(df_data_train.values).float(), dim=0, unbiased=False)\n",
    "\n",
    "#import torch\n",
    "#from torch import nn\n",
    "\n",
    "#n_features = df_data_train.shape[1]\n",
    "\n",
    "#class Std_mean(nn.Module):\n",
    "#    def __init__(self,n_features):\n",
    "#        super().__init__()\n",
    "#        self.mean = nn.Parameter(torch.zeros(n_features),requires_grad=False)\n",
    "#        self.std = nn.Parameter(torch.zeros(n_features),requires_grad=False)\n",
    "#        self.fake = nn.Parameter(torch.randn(n_features),requires_grad=True)\n",
    "\n",
    "#    def forward(self, input):\n",
    "#        #torch.sum(batch, dim=0)\n",
    "#        self.mean += torch.mean(input,dim=0)\n",
    "#        self.std += torch.std(input,dim=0, unbiased=False)\n",
    "#        return (self.mean,self.std)\n",
    "    \n",
    "#m = Std_mean(n_features)\n",
    "#m(torch.from_numpy(df_data_train.values).float())\n",
    "#print(m.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the nodes up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 1 (csv) to add client_1 dataset to the first node\n",
    "  * Provide the correct tag by entering:  breast_cancer\n",
    "  * Pick the folder where client_1 dataset has been saved\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node start`. Wait until you get `Starting task manager`. it means you are online.\n",
    "4. Following the same procedure, you can create additional nodes for clients 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check available clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:38:51,144 fedbiomed INFO - Component environment:\n",
      "2022-08-04 13:38:51,145 fedbiomed INFO - type = ComponentType.RESEARCHER\n",
      "2022-08-04 13:38:51,186 fedbiomed INFO - Messaging researcher_70860f7a-cf92-4e48-89d2-43faab63e063 successfully connected to the message broker, object = <fedbiomed.common.messaging.Messaging object at 0x15042b790>\n",
      "2022-08-04 13:38:51,225 fedbiomed INFO - Listing available datasets in all nodes... \n",
      "2022-08-04 13:39:01,280 fedbiomed INFO - \n",
      " Node: node_cad61f30-5e43-4275-823f-4663210cfcbb | Number of Datasets: 1 \n",
      "+---------------+-------------+-------------------+---------------+-----------+----------------------+\n",
      "| name          | data_type   | tags              | description   | shape     | dataset_parameters   |\n",
      "+===============+=============+===================+===============+===========+======================+\n",
      "| breast_cancer | csv         | ['breast_cancer'] | breast_cancer | [139, 13] |                      |\n",
      "+---------------+-------------+-------------------+---------------+-----------+----------------------+\n",
      "\n",
      "2022-08-04 13:39:01,284 fedbiomed INFO - \n",
      " Node: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 | Number of Datasets: 1 \n",
      "+---------------+-------------+-------------------+---------------+-----------+----------------------+\n",
      "| name          | data_type   | tags              | description   | shape     | dataset_parameters   |\n",
      "+===============+=============+===================+===============+===========+======================+\n",
      "| breast_cancer | csv         | ['breast_cancer'] | breast_cancer | [134, 13] |                      |\n",
      "+---------------+-------------+-------------------+---------------+-----------+----------------------+\n",
      "\n",
      "2022-08-04 13:39:01,286 fedbiomed INFO - \n",
      " Node: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 | Number of Datasets: 1 \n",
      "+---------------+-------------+-------------------+---------------+-----------+----------------------+\n",
      "| name          | data_type   | tags              | description   | shape     | dataset_parameters   |\n",
      "+===============+=============+===================+===============+===========+======================+\n",
      "| breast_cancer | csv         | ['breast_cancer'] | breast_cancer | [134, 13] |                      |\n",
      "+---------------+-------------+-------------------+---------------+-----------+----------------------+\n",
      "\n",
      "2022-08-04 13:39:01,288 fedbiomed INFO - Listing available datasets in all nodes... \n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)\n",
    "xx = req.list()\n",
    "dataset_size = [xx[i][0]['shape'][1] for i in xx]\n",
    "assert min(dataset_size)==max(dataset_size)\n",
    "data_size = dataset_size[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover global mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from fedbiomed.common.constants import ProcessTypes\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class FedMeanStdTrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(FedMeanStdTrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        deps = [\"import pandas as pd\",\n",
    "               \"import numpy as np\",\n",
    "               \"from copy import deepcopy\"]\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.n_features=model_args['n_features']\n",
    "        \n",
    "        self.mean = nn.Parameter(torch.zeros(self.n_features),requires_grad=False)\n",
    "        self.std = nn.Parameter(torch.zeros(self.n_features),requires_grad=False)\n",
    "        self.size = nn.Parameter(torch.zeros(self.n_features),requires_grad=False)\n",
    "        self.fake = nn.Parameter(torch.randn(1),requires_grad=True)\n",
    "        \n",
    "    def training_data(self):\n",
    "        \n",
    "        df = pd.read_csv(self.dataset_path, sep=',', index_col=False)\n",
    "        \n",
    "        ### NOTE: batch_size should be == dataset size ###\n",
    "        batch_size = df.shape[0]\n",
    "        x_train = df.values\n",
    "        x_mask = np.isfinite(x_train)\n",
    "        xhat_0 = np.copy(x_train)\n",
    "        ### NOTE: for standardization purposes, we keep nan when data is missing\n",
    "        #xhat_0[np.isnan(x_train)] = 0\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        \n",
    "        data_manager = DataManager(dataset=xhat_0 , target=x_mask , **train_kwargs)\n",
    "        \n",
    "        return data_manager\n",
    "    \n",
    "    def training_step(self, data, mask):\n",
    "        #self.size += data.shape[0]\n",
    "        data_np = data.numpy()\n",
    "        self.size += torch.Tensor([data_np[:,dim].size - np.count_nonzero(np.isnan(data_np[:,dim]))\\\n",
    "                                   for dim in range(self.n_features)])\n",
    "        #print(data[0,:])\n",
    "        #fed_mean = torch.zeros(self.n_features)\n",
    "        #fed_std = torch.zeros(self.n_features)\n",
    "        #print(\"data shape\",data.shape)\n",
    "        #for dim in range(self.n_features):\n",
    "        #    data_i = deepcopy(data[:,dim][mask[:,dim].bool()])\n",
    "        #    mean_i = torch.mean(data_i, dim=0)\n",
    "        #    std_i = torch.std(data_i, unbiased=False, dim=0)\n",
    "        #    fed_mean[dim] = mean_i\n",
    "        #    fed_std[dim] = std_i\n",
    "        #    print(dim, data_i.shape,mean_i,std_i)\n",
    "        #self.mean += fed_mean\n",
    "        #self.std += fed_std\n",
    "#        self.mean += torch.mean(data[mask.bool()], dim=0)\n",
    "#        self.std += torch.std(data[mask.bool()], dim=0, unbiased=False)\n",
    "        self.mean += torch.from_numpy(np.nanmean(data_np,0))\n",
    "        self.std += torch.from_numpy(np.nanstd(data_np,0))\n",
    "        return self.fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {'n_features':data_size}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'log_interval' : 1,\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    #'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "tags =  ['breast_cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:40:13,910 fedbiomed INFO - Searching dataset with data tags: ['breast_cancer'] for all nodes\n",
      "2022-08-04 13:40:23,956 fedbiomed INFO - Node selected for training -> node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "2022-08-04 13:40:23,958 fedbiomed INFO - Node selected for training -> node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "2022-08-04 13:40:23,963 fedbiomed INFO - Node selected for training -> node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "2022-08-04 13:40:23,980 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "2022-08-04 13:40:24,001 fedbiomed DEBUG - Model file has been saved: /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0000/my_model_ff6ee0e9-0089-4d09-8686-530036d2ff30.py\n",
      "2022-08-04 13:40:24,157 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0000/my_model_ff6ee0e9-0089-4d09-8686-530036d2ff30.py successful, with status code 201\n",
      "2022-08-04 13:40:24,220 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0000/aggregated_params_init_794ce34c-060d-4092-b5fd-fa929b4a037e.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedstandard import FedStandard\n",
    "\n",
    "fed_mean_std = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=FedMeanStdTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=1,\n",
    "                 aggregator=FedStandard(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:40:24,281 fedbiomed INFO - Sampled nodes in round 0 ['node_0b7c1887-216e-49c4-ac10-2ba325ca4d24', 'node_cad61f30-5e43-4275-823f-4663210cfcbb', 'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8']\n",
      "2022-08-04 13:40:24,282 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': 'b72fa0fd-ffe2-40b3-bb97-6fd135ba7ff1', 'training_args': scheme:\n",
      "{'lr': {'rules': [<class 'float'>, <function TrainingArgs._lr_hook at 0x150062310>], 'required': False}, 'batch_size': {'rules': [<class 'int'>], 'required': False}, 'epochs': {'rules': [<class 'int'>], 'required': False}, 'dry_run': {'rules': [<class 'bool'>], 'required': False}, 'batch_maxnum': {'rules': [<class 'int'>], 'required': False}, 'test_ratio': {'rules': [<class 'float'>, <function TrainingArgs._test_ratio_hook at 0x1500621f0>], 'required': False, 'default': 0.0}, 'test_on_local_updates': {'rules': [<class 'bool'>], 'required': False, 'default': False}, 'test_on_global_updates': {'rules': [<class 'bool'>], 'required': False, 'default': False}, 'test_metric': {'rules': [<function TrainingArgs._metric_validation_hook at 0x1500620d0>], 'required': False, 'default': None}, 'test_metric_args': {'rules': [<class 'dict'>], 'required': False, 'default': {}}, 'log_interval': {'rules': [<class 'int'>], 'required': False}, 'fedprox_mu': {'rules': [<class 'float'>], 'required': False}}\n",
      "value:\n",
      "{'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 1, 'dry_run': False, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_ff6ee0e9-0089-4d09-8686-530036d2ff30.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_794ce34c-060d-4092-b5fd-fa929b4a037e.pt', 'model_class': 'FedMeanStdTrainingPlan', 'training_data': {'node_0b7c1887-216e-49c4-ac10-2ba325ca4d24': ['dataset_73d93ba1-c8c8-41da-abbc-8ea6cac2d2a9']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 13:40:24,282 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 13:40:24,283 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': 'b72fa0fd-ffe2-40b3-bb97-6fd135ba7ff1', 'training_args': {'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 1, 'dry_run': False, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_ff6ee0e9-0089-4d09-8686-530036d2ff30.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_794ce34c-060d-4092-b5fd-fa929b4a037e.pt', 'model_class': 'FedMeanStdTrainingPlan', 'training_data': {'node_cad61f30-5e43-4275-823f-4663210cfcbb': ['dataset_5032df1b-a636-42c8-9013-ccf988bd4829']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 13:40:24,283 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 13:40:24,284 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': 'b72fa0fd-ffe2-40b3-bb97-6fd135ba7ff1', 'training_args': {'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 1, 'dry_run': False, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_ff6ee0e9-0089-4d09-8686-530036d2ff30.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_794ce34c-060d-4092-b5fd-fa929b4a037e.pt', 'model_class': 'FedMeanStdTrainingPlan', 'training_data': {'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8': ['dataset_ade68612-7fa7-4ef2-923d-6ebc94b7547e']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 13:40:24,285 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 13:40:25,065 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,065 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,066 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,093 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x17693fa00>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 1, 'dry_run': False}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,094 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x178e2b970>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 1, 'dry_run': False}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,095 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m-0.036037\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:40:25,095 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m-0.036037\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:40:25,099 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x178334970>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 1, 'dry_run': False}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,106 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m-0.036037\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:40:25,236 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:25,375 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:40:25,465 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:40:34,349 fedbiomed INFO - Downloading model params after training on node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 - from http://localhost:8844/media/uploads/2022/08/04/node_params_2fa1bfdf-3b14-4ea6-a668-77c5e80faec2.pt\n",
      "2022-08-04 13:40:34,394 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_8dd296b2-1818-4a93-a4f0-0b9c886459b8.pt successful, with status code 200\n",
      "2022-08-04 13:40:34,406 fedbiomed INFO - Downloading model params after training on node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 - from http://localhost:8844/media/uploads/2022/08/04/node_params_74fd12af-472b-4641-a4ee-8485790e7f87.pt\n",
      "2022-08-04 13:40:34,424 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_0d01b3f5-2183-43cf-a2f7-8a67beceafef.pt successful, with status code 200\n",
      "2022-08-04 13:40:34,429 fedbiomed INFO - Downloading model params after training on node_cad61f30-5e43-4275-823f-4663210cfcbb - from http://localhost:8844/media/uploads/2022/08/04/node_params_13a1f15d-2cde-431e-896c-4d9a9d1743df.pt\n",
      "2022-08-04 13:40:34,445 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_373ecf10-dabc-474f-94cc-e5fabd506cc8.pt successful, with status code 200\n",
      "2022-08-04 13:40:34,454 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8', 'node_0b7c1887-216e-49c4-ac10-2ba325ca4d24', 'node_cad61f30-5e43-4275-823f-4663210cfcbb']\n",
      "2022-08-04 13:40:34,526 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0000/aggregated_params_471b3523-c906-4f93-b414-bf054c820ea5.pt successful, with status code 201\n",
      "2022-08-04 13:40:34,527 fedbiomed INFO - Saved aggregated params for round 0 in /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0000/aggregated_params_471b3523-c906-4f93-b414-bf054c820ea5.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fed_mean_std.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fed_mean': tensor([3.0750e+00, 1.1101e+01, 1.1267e+01, 7.7273e-02, 5.5831e-01, 6.3458e+00,\n",
      "        7.0555e+01, 3.8209e+00, 9.2466e+00, 4.1542e+02, 1.8331e+01, 3.5190e+02,\n",
      "        1.2372e+01]), 'fed_std': tensor([8.0486e+00, 2.3008e+01, 6.9280e+00, 2.6705e-01, 1.1085e-01, 7.5352e-01,\n",
      "        2.7414e+01, 2.0918e+00, 8.5620e+00, 1.6762e+02, 2.2201e+00, 9.8739e+01,\n",
      "        6.5886e+00]), 'N_tot': tensor([215., 207., 206., 220., 204., 211., 222., 208., 219., 230., 233., 209.,\n",
      "        210.])}\n"
     ]
    }
   ],
   "source": [
    "fed_mean = fed_mean_std.aggregated_params()[0]['params']['fed_mean']\n",
    "fed_std = fed_mean_std.aggregated_params()[0]['params']['fed_std']\n",
    "print(fed_mean_std.aggregated_params()[0]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.07500809e+00 1.11014493e+01 1.12669903e+01 7.72727273e-02\n",
      " 5.58312745e-01 6.34579147e+00 7.05545045e+01 3.82085865e+00\n",
      " 9.24657534e+00 4.15421739e+02 1.83309013e+01 3.51897033e+02\n",
      " 1.23715238e+01]\n",
      "[8.05344570e+00 2.30072840e+01 6.92754048e+00 2.67023694e-01\n",
      " 1.10866213e-01 7.53666761e-01 2.74117840e+01 2.09158817e+00\n",
      " 8.56207122e+00 1.67622662e+02 2.21998097e+00 9.88107497e+01\n",
      " 6.58763897e+00]\n",
      "tensor([-1.7753e-07, -2.6261e-07, -5.8332e-07,  8.1279e-10,  2.8606e-08,\n",
      "        -1.2932e-07, -1.0997e-07, -6.5214e-07,  1.3064e-08,  1.3799e-05,\n",
      "        -4.9100e-06,  1.9858e-07,  1.0013e-06], dtype=torch.float64)\n",
      "tensor([-4.8045e-03,  8.7369e-04,  4.5043e-04,  3.1013e-05, -1.4001e-05,\n",
      "        -1.4264e-04,  1.9561e-03,  1.9631e-04, -8.7160e-05, -2.3773e-03,\n",
      "         1.4399e-04, -7.2140e-02,  9.4259e-04], dtype=torch.float64)\n",
      "1.4712755509100255e-05 0.07237912242096359\n"
     ]
    }
   ],
   "source": [
    "pdist = torch.nn.PairwiseDistance(p=2)\n",
    "print(mean_clients_missing)\n",
    "print(std_clients_missing)\n",
    "print(fed_mean-mean_clients_missing)\n",
    "print(fed_std-std_clients_missing)\n",
    "mean_dist = np.linalg.norm(fed_mean-mean_clients_missing)\n",
    "std_dist = np.linalg.norm(fed_std-std_clients_missing)\n",
    "print(mean_dist,std_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.075007915496826, 11.101449012756348, 11.266989707946777, 0.07727272808551788, 0.5583127737045288, 6.345791339874268, 70.55450439453125, 3.8208580017089844, 9.246575355529785, 415.4217529296875, 18.330896377563477, 351.89703369140625, 12.371524810791016]\n",
      "[8.048641204833984, 23.00815773010254, 6.927990913391113, 0.2670547068119049, 0.1108522117137909, 0.753524124622345, 27.413740158081055, 2.0917844772338867, 8.561984062194824, 167.6202850341797, 2.2201249599456787, 98.73860931396484, 6.588581562042236]\n"
     ]
    }
   ],
   "source": [
    "print(fed_mean.tolist())\n",
    "print(fed_std.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define experiment model and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch.nn MIWAETrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : we include a function, ``standardize_data``, which allow to standardize data either with respect to a mean and std provided by the user, or locally, considering only local data for each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.distributions as td\n",
    "import pandas as pd\n",
    "\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from fedbiomed.common.constants import ProcessTypes\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MIWAETrainingPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args: dict = {}):\n",
    "        super(MIWAETrainingPlan, self).__init__(model_args)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        deps = [\"from torchvision import datasets, transforms\",\n",
    "               \"import torch.distributions as td\",\n",
    "               \"import pandas as pd\",\n",
    "               \"import numpy as np\"]\n",
    "        \n",
    "        self.n_features=model_args['n_features']\n",
    "        self.n_latent=model_args['n_latent']\n",
    "        self.n_hidden=model_args['n_hidden']\n",
    "        self.n_samples=model_args['n_samples']\n",
    "        \n",
    "        if 'standardization' in model_args:\n",
    "            self.standardization = True\n",
    "            if (('fed_mean' in model_args['standardization']) and ('fed_std' in model_args['standardization'])):\n",
    "                self.fed_mean = np.array(model_args['standardization']['fed_mean'])\n",
    "                self.fed_std = np.array(model_args['standardization']['fed_std'])\n",
    "            else:\n",
    "                self.fed_mean = None\n",
    "                self.fed_std = None\n",
    "        \n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        # the encoder will output both the mean and the diagonal covariance\n",
    "        self.encoder=nn.Sequential(\n",
    "                        torch.nn.Linear(self.n_features, self.n_hidden),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(self.n_hidden, 2*self.n_latent),  \n",
    "                        )\n",
    "        # the decoder will output both the mean, the scale, \n",
    "        # and the number of degrees of freedoms (hence the 3*p)\n",
    "        self.decoder = nn.Sequential(\n",
    "                        torch.nn.Linear(self.n_latent, self.n_hidden),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(self.n_hidden, 3*self.n_features),  \n",
    "                        )\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(list(self.encoder.parameters()) \\\n",
    "                                    + list(self.decoder.parameters()),lr=1e-3)\n",
    "              \n",
    "        self.encoder.apply(self.weights_init)\n",
    "        self.decoder.apply(self.weights_init)\n",
    "    \n",
    "    def weights_init(self,layer):\n",
    "        if type(layer) == nn.Linear: torch.nn.init.orthogonal_(layer.weight)\n",
    "    \n",
    "    def miwae_loss(self,iota_x,mask):\n",
    "        batch_size = iota_x.shape[0]\n",
    "        out_encoder = self.encoder(iota_x)\n",
    "        # prior\n",
    "        p_z = td.Independent(td.Normal(loc=torch.zeros(self.n_latent).to(self.device)\\\n",
    "                                       ,scale=torch.ones(self.n_latent).to(self.device)),1)\n",
    "        \n",
    "        q_zgivenxobs = td.Independent(td.Normal(loc=out_encoder[..., :self.n_latent],\\\n",
    "                                                scale=torch.nn.Softplus()\\\n",
    "                                                (out_encoder[..., self.n_latent:\\\n",
    "                                                             (2*self.n_latent)])),1)\n",
    "\n",
    "        zgivenx = q_zgivenxobs.rsample([self.n_samples])\n",
    "        zgivenx_flat = zgivenx.reshape([self.n_samples*batch_size,self.n_latent])\n",
    "\n",
    "        out_decoder = self.decoder(zgivenx_flat)\n",
    "        all_means_obs_model = out_decoder[..., :self.n_features]\n",
    "        all_scales_obs_model = torch.nn.Softplus()(out_decoder[..., self.n_features:\\\n",
    "                                                               (2*self.n_features)]) + 0.001\n",
    "        all_degfreedom_obs_model = torch.nn.Softplus()\\\n",
    "        (out_decoder[..., (2*self.n_features):(3*self.n_features)]) + 3\n",
    "\n",
    "        data_flat = torch.Tensor.repeat(iota_x,[self.n_samples,1]).reshape([-1,1])\n",
    "        tiledmask = torch.Tensor.repeat(mask,[self.n_samples,1])\n",
    "\n",
    "        all_log_pxgivenz_flat = torch.distributions.StudentT\\\n",
    "        (loc=all_means_obs_model.reshape([-1,1]),\\\n",
    "         scale=all_scales_obs_model.reshape([-1,1]),\\\n",
    "         df=all_degfreedom_obs_model.reshape([-1,1])).log_prob(data_flat)\n",
    "        all_log_pxgivenz = all_log_pxgivenz_flat.reshape([self.n_samples*batch_size,self.n_features])\n",
    "\n",
    "        logpxobsgivenz = torch.sum(all_log_pxgivenz*tiledmask,1).reshape([self.n_samples,batch_size])\n",
    "        logpz = p_z.log_prob(zgivenx)\n",
    "        logq = q_zgivenxobs.log_prob(zgivenx)\n",
    "\n",
    "        neg_bound = -torch.mean(torch.logsumexp(logpxobsgivenz + logpz - logq,0))\n",
    "\n",
    "        return neg_bound\n",
    "\n",
    "    def training_data(self,  batch_size = 48):\n",
    "        \n",
    "        df = pd.read_csv(self.dataset_path, sep=',', index_col=False)\n",
    "        x_train = df.values\n",
    "        x_mask = np.isfinite(x_train)\n",
    "        # xhat_0: missing values are replaced by zeros. \n",
    "        #This x_hat0 is what will be fed to our encoder.\n",
    "        xhat_0 = np.copy(x_train)\n",
    "        \n",
    "        # Data standardization\n",
    "        if self.standardization:\n",
    "            xhat_0 = self.standardize_data(xhat_0)\n",
    "            \n",
    "        xhat_0[np.isnan(x_train)] = 0\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        \n",
    "        data_manager = DataManager(dataset=xhat_0 , target=x_mask , **train_kwargs)\n",
    "        \n",
    "        return data_manager\n",
    "    \n",
    "    def standardize_data(self,data):\n",
    "        data_norm = np.copy(data)\n",
    "        if ((self.fed_mean is not None) and (self.fed_std is not None)):\n",
    "            print('FEDERATED STANDARDIZATION')\n",
    "            data_norm = (data_norm - self.fed_mean)/self.fed_std\n",
    "        else:\n",
    "            print('LOCAL STANDARDIZATION')\n",
    "            data_norm = (data_norm - np.nanmean(data_norm,0))/np.nanstd(data_norm,0)\n",
    "        return data_norm\n",
    "    \n",
    "    def training_step(self, data, mask):\n",
    "        self.encoder.zero_grad()\n",
    "        self.decoder.zero_grad()\n",
    "        loss = self.miwae_loss(iota_x = data,mask = mask)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side. \n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "* data `tags` to search nodes for training.\n",
    "* total number of `rounds`.\n",
    "If FedProx optimisation is requested, `fedprox_mu` parameter must be defined here. It also must be a float between XX and YY.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "h = 128 # number of hidden units in (same for all MLPs)\n",
    "d = 10 # dimension of the latent space, we choose d=1 for visualisation purposes\n",
    "K = 20 # number of IS during training\n",
    "\n",
    "n_epochs=5\n",
    "\n",
    "model_args = {'n_features':data_size, 'n_latent':d,'n_hidden':h,'n_samples':K,'standardization':{'fed_mean':fed_mean.tolist(),'fed_std':fed_std.tolist()}}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 48, \n",
    "    'lr': 1e-3, \n",
    "    'log_interval' : 1,\n",
    "    'epochs': n_epochs, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "tags =  ['breast_cancer']\n",
    "rounds = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and run the experiment\n",
    "\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:44:26,904 fedbiomed INFO - Searching dataset with data tags: ['breast_cancer'] for all nodes\n",
      "2022-08-04 13:44:36,945 fedbiomed INFO - Node selected for training -> node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "2022-08-04 13:44:36,948 fedbiomed INFO - Node selected for training -> node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "2022-08-04 13:44:36,949 fedbiomed INFO - Node selected for training -> node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "2022-08-04 13:44:36,964 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "2022-08-04 13:44:36,980 fedbiomed DEBUG - Model file has been saved: /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0002/my_model_02880f7d-bfce-4e35-bff2-ba91725479a6.py\n",
      "2022-08-04 13:44:37,057 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0002/my_model_02880f7d-bfce-4e35-bff2-ba91725479a6.py successful, with status code 201\n",
      "2022-08-04 13:44:37,131 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0002/aggregated_params_init_b7238400-8f99-45be-9819-22dea1c1a616.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MIWAETrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local training results for each round and each node are available via `exp.training_replies()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List the training rounds :  dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "\n",
      "List the nodes for the last training round and their timings : \n",
      "\t- node_cad61f30-5e43-4275-823f-4663210cfcbb :    \n",
      "\t\trtime_training=0.17 seconds    \n",
      "\t\tptime_training=0.20 seconds    \n",
      "\t\trtime_total=10.05 seconds\n",
      "\t- node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 :    \n",
      "\t\trtime_training=0.17 seconds    \n",
      "\t\tptime_training=0.19 seconds    \n",
      "\t\trtime_total=10.11 seconds\n",
      "\t- node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 :    \n",
      "\t\trtime_training=0.17 seconds    \n",
      "\t\tptime_training=0.19 seconds    \n",
      "\t\trtime_total=10.14 seconds\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>msg</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>params_path</th>\n",
       "      <th>params</th>\n",
       "      <th>timing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>dataset_5032df1b-a636-42c8-9013-ccf988bd4829</td>\n",
       "      <td>node_cad61f30-5e43-4275-823f-4663210cfcbb</td>\n",
       "      <td>/Users/ibalelli/Documents/INRIA_EPIONE/FedBioM...</td>\n",
       "      <td>{'encoder.0.weight': [[tensor(0.0297), tensor(...</td>\n",
       "      <td>{'rtime_training': 0.16832783400002427, 'ptime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>dataset_73d93ba1-c8c8-41da-abbc-8ea6cac2d2a9</td>\n",
       "      <td>node_0b7c1887-216e-49c4-ac10-2ba325ca4d24</td>\n",
       "      <td>/Users/ibalelli/Documents/INRIA_EPIONE/FedBioM...</td>\n",
       "      <td>{'encoder.0.weight': [[tensor(0.0362), tensor(...</td>\n",
       "      <td>{'rtime_training': 0.1669240420000051, 'ptime_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>dataset_ade68612-7fa7-4ef2-923d-6ebc94b7547e</td>\n",
       "      <td>node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8</td>\n",
       "      <td>/Users/ibalelli/Documents/INRIA_EPIONE/FedBioM...</td>\n",
       "      <td>{'encoder.0.weight': [[tensor(0.0380), tensor(...</td>\n",
       "      <td>{'rtime_training': 0.16873950000001514, 'ptime...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   success msg                                    dataset_id  \\\n",
       "0     True      dataset_5032df1b-a636-42c8-9013-ccf988bd4829   \n",
       "1     True      dataset_73d93ba1-c8c8-41da-abbc-8ea6cac2d2a9   \n",
       "2     True      dataset_ade68612-7fa7-4ef2-923d-6ebc94b7547e   \n",
       "\n",
       "                                     node_id  \\\n",
       "0  node_cad61f30-5e43-4275-823f-4663210cfcbb   \n",
       "1  node_0b7c1887-216e-49c4-ac10-2ba325ca4d24   \n",
       "2  node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8   \n",
       "\n",
       "                                         params_path  \\\n",
       "0  /Users/ibalelli/Documents/INRIA_EPIONE/FedBioM...   \n",
       "1  /Users/ibalelli/Documents/INRIA_EPIONE/FedBioM...   \n",
       "2  /Users/ibalelli/Documents/INRIA_EPIONE/FedBioM...   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'encoder.0.weight': [[tensor(0.0297), tensor(...   \n",
       "1  {'encoder.0.weight': [[tensor(0.0362), tensor(...   \n",
       "2  {'encoder.0.weight': [[tensor(0.0380), tensor(...   \n",
       "\n",
       "                                              timing  \n",
       "0  {'rtime_training': 0.16832783400002427, 'ptime...  \n",
       "1  {'rtime_training': 0.1669240420000051, 'ptime_...  \n",
       "2  {'rtime_training': 0.16873950000001514, 'ptime...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1].data()\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies()[rounds - 1].dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federated parameters for each round are available via `exp.aggregated_params()` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List the training rounds :  dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "\n",
      "Access the federated params for the last training round :\n",
      "\t- params_path:  /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0002/aggregated_params_9025aafc-0951-4c0e-b91c-42e1cbb98ecb.pt\n",
      "\t- parameter data:  odict_keys(['encoder.0.weight', 'encoder.0.bias', 'encoder.2.weight', 'encoder.2.bias', 'encoder.4.weight', 'encoder.4.bias', 'decoder.0.weight', 'decoder.0.bias', 'decoder.2.weight', 'decoder.2.bias', 'decoder.4.weight', 'decoder.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params().keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params()[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params()[rounds - 1]['params'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the experiment with FedProx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the federated training but using FedProx as aggregation scheme (starting from the second iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:50:59,493 fedbiomed INFO - Searching dataset with data tags: ['breast_cancer'] for all nodes\n",
      "2022-08-04 13:51:09,529 fedbiomed INFO - Node selected for training -> node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "2022-08-04 13:51:09,532 fedbiomed INFO - Node selected for training -> node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "2022-08-04 13:51:09,535 fedbiomed INFO - Node selected for training -> node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "2022-08-04 13:51:09,554 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "2022-08-04 13:51:09,578 fedbiomed DEBUG - Model file has been saved: /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0003/my_model_b763f58d-e5c9-49ac-88c1-ea0e6935917b.py\n",
      "2022-08-04 13:51:09,673 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0003/my_model_b763f58d-e5c9-49ac-88c1-ea0e6935917b.py successful, with status code 201\n",
      "2022-08-04 13:51:09,748 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0003/aggregated_params_init_68a06593-19a5-4c63-8f21-9e4bfdc41c68.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "# To make the method fairly comparable with FedCos, during the first round\n",
    "# we will simply use FedAvg with standard optimization scheme: the FedProx penalization\n",
    "# term will be introduced exclusively from the second round.\n",
    "# training_args.update(fedprox_mu = 0.)\n",
    "\n",
    "exp_fedprox = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MIWAETrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:51:09,815 fedbiomed INFO - Sampled nodes in round 0 ['node_0b7c1887-216e-49c4-ac10-2ba325ca4d24', 'node_cad61f30-5e43-4275-823f-4663210cfcbb', 'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8']\n",
      "2022-08-04 13:51:09,815 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': '4a15ad68-0cfc-4d8e-81fe-dce33bad8d5f', 'training_args': scheme:\n",
      "{'lr': {'rules': [<class 'float'>, <function TrainingArgs._lr_hook at 0x150062310>], 'required': False}, 'batch_size': {'rules': [<class 'int'>], 'required': False}, 'epochs': {'rules': [<class 'int'>], 'required': False}, 'dry_run': {'rules': [<class 'bool'>], 'required': False}, 'batch_maxnum': {'rules': [<class 'int'>], 'required': False}, 'test_ratio': {'rules': [<class 'float'>, <function TrainingArgs._test_ratio_hook at 0x1500621f0>], 'required': False, 'default': 0.0}, 'test_on_local_updates': {'rules': [<class 'bool'>], 'required': False, 'default': False}, 'test_on_global_updates': {'rules': [<class 'bool'>], 'required': False, 'default': False}, 'test_metric': {'rules': [<function TrainingArgs._metric_validation_hook at 0x1500620d0>], 'required': False, 'default': None}, 'test_metric_args': {'rules': [<class 'dict'>], 'required': False, 'default': {}}, 'log_interval': {'rules': [<class 'int'>], 'required': False}, 'fedprox_mu': {'rules': [<class 'float'>], 'required': False}}\n",
      "value:\n",
      "{'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13, 'n_latent': 10, 'n_hidden': 128, 'n_samples': 20, 'standardization': {'fed_mean': [3.075007915496826, 11.101449012756348, 11.266989707946777, 0.07727272808551788, 0.5583127737045288, 6.345791339874268, 70.55450439453125, 3.8208580017089844, 9.246575355529785, 415.4217529296875, 18.330896377563477, 351.89703369140625, 12.371524810791016], 'fed_std': [8.048641204833984, 23.00815773010254, 6.927990913391113, 0.2670547068119049, 0.1108522117137909, 0.753524124622345, 27.413740158081055, 2.0917844772338867, 8.561984062194824, 167.6202850341797, 2.2201249599456787, 98.73860931396484, 6.588581562042236]}}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_b763f58d-e5c9-49ac-88c1-ea0e6935917b.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_68a06593-19a5-4c63-8f21-9e4bfdc41c68.pt', 'model_class': 'MIWAETrainingPlan', 'training_data': {'node_0b7c1887-216e-49c4-ac10-2ba325ca4d24': ['dataset_73d93ba1-c8c8-41da-abbc-8ea6cac2d2a9']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,816 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 13:51:09,816 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': '4a15ad68-0cfc-4d8e-81fe-dce33bad8d5f', 'training_args': {'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13, 'n_latent': 10, 'n_hidden': 128, 'n_samples': 20, 'standardization': {'fed_mean': [3.075007915496826, 11.101449012756348, 11.266989707946777, 0.07727272808551788, 0.5583127737045288, 6.345791339874268, 70.55450439453125, 3.8208580017089844, 9.246575355529785, 415.4217529296875, 18.330896377563477, 351.89703369140625, 12.371524810791016], 'fed_std': [8.048641204833984, 23.00815773010254, 6.927990913391113, 0.2670547068119049, 0.1108522117137909, 0.753524124622345, 27.413740158081055, 2.0917844772338867, 8.561984062194824, 167.6202850341797, 2.2201249599456787, 98.73860931396484, 6.588581562042236]}}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_b763f58d-e5c9-49ac-88c1-ea0e6935917b.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_68a06593-19a5-4c63-8f21-9e4bfdc41c68.pt', 'model_class': 'MIWAETrainingPlan', 'training_data': {'node_cad61f30-5e43-4275-823f-4663210cfcbb': ['dataset_5032df1b-a636-42c8-9013-ccf988bd4829']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,817 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 13:51:09,818 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': '4a15ad68-0cfc-4d8e-81fe-dce33bad8d5f', 'training_args': {'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13, 'n_latent': 10, 'n_hidden': 128, 'n_samples': 20, 'standardization': {'fed_mean': [3.075007915496826, 11.101449012756348, 11.266989707946777, 0.07727272808551788, 0.5583127737045288, 6.345791339874268, 70.55450439453125, 3.8208580017089844, 9.246575355529785, 415.4217529296875, 18.330896377563477, 351.89703369140625, 12.371524810791016], 'fed_std': [8.048641204833984, 23.00815773010254, 6.927990913391113, 0.2670547068119049, 0.1108522117137909, 0.753524124622345, 27.413740158081055, 2.0917844772338867, 8.561984062194824, 167.6202850341797, 2.2201249599456787, 98.73860931396484, 6.588581562042236]}}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_b763f58d-e5c9-49ac-88c1-ea0e6935917b.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_68a06593-19a5-4c63-8f21-9e4bfdc41c68.pt', 'model_class': 'MIWAETrainingPlan', 'training_data': {'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8': ['dataset_ade68612-7fa7-4ef2-923d-6ebc94b7547e']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,818 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 13:51:09,903 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,904 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,905 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,941 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x1798c1f40>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:51:09,942 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x17697fc10>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,943 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x17a3bbe20>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:09,956 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.941436\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,957 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m7.068967\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,958 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.304906\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,967 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.074785\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,968 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.771885\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,969 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m7.241017\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,977 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.323287\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,978 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.537636\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,979 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.487830\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,990 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.467965\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,991 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.711312\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:09,992 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.687287\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,001 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.041646\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,001 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.902481\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,002 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.545815\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,011 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.180983\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,012 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.227006\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,012 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.323081\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,022 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.183284\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,023 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.612190\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,024 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.254674\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,034 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.649909\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,035 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.882004\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,035 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.573913\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,044 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.445234\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,045 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.441035\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,046 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.683125\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,066 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.256932\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,068 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.019443\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,068 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.925947\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,069 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.950418\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,069 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.684875\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,070 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.153069\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,076 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m7.989266\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,077 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.372692\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,079 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.794092\u001b[0m \n",
      "\t\t\t\t\t ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 13:51:10,088 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.491025\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,089 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.562397\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,090 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.555610\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,100 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.062581\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,100 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.819637\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,101 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.788453\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,109 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.430572\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,110 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.396572\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,110 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.914848\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 13:51:10,213 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:10,248 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:10,286 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 13:51:19,868 fedbiomed INFO - Downloading model params after training on node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 - from http://localhost:8844/media/uploads/2022/08/04/node_params_a1cdebbd-ef07-4611-8f2d-4dfedd9750f4.pt\n",
      "2022-08-04 13:51:19,923 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_74e0e401-6033-4e7b-9834-1f6da4b51a99.pt successful, with status code 200\n",
      "2022-08-04 13:51:19,934 fedbiomed INFO - Downloading model params after training on node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 - from http://localhost:8844/media/uploads/2022/08/04/node_params_211d0895-6f5f-4a0b-8713-cc2440e57874.pt\n",
      "2022-08-04 13:51:19,956 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_b1213670-f221-44d6-90aa-9d32854c2a27.pt successful, with status code 200\n",
      "2022-08-04 13:51:19,962 fedbiomed INFO - Downloading model params after training on node_cad61f30-5e43-4275-823f-4663210cfcbb - from http://localhost:8844/media/uploads/2022/08/04/node_params_3a1701b0-ad42-4542-bd14-e63184027352.pt\n",
      "2022-08-04 13:51:19,982 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_a8479cbc-822e-48c0-98c4-22b6f3438076.pt successful, with status code 200\n",
      "2022-08-04 13:51:19,989 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_0b7c1887-216e-49c4-ac10-2ba325ca4d24', 'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8', 'node_cad61f30-5e43-4275-823f-4663210cfcbb']\n",
      "2022-08-04 13:51:20,061 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0003/aggregated_params_db852ad9-9aee-4376-991c-6ae82bdaf39c.pt successful, with status code 201\n",
      "2022-08-04 13:51:20,063 fedbiomed INFO - Saved aggregated params for round 0 in /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0003/aggregated_params_db852ad9-9aee-4376-991c-6ae82bdaf39c.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_fedprox.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from the second round, FedProx is used with mu=0.1\n",
    "# We first update the training args\n",
    "training_args.update(fedprox_mu = 0.1)\n",
    "# Then update training args in the experiment\n",
    "exp_fedprox.set_training_args(training_args)\n",
    "exp_fedprox.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the experiment with FedProx and performing the standardization locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we propose to use FedCos as well, which introduce an alternative penalization term with cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 14:23:44,653 fedbiomed INFO - Searching dataset with data tags: ['breast_cancer'] for all nodes\n",
      "2022-08-04 14:23:54,698 fedbiomed INFO - Node selected for training -> node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "2022-08-04 14:23:54,701 fedbiomed INFO - Node selected for training -> node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "2022-08-04 14:23:54,702 fedbiomed INFO - Node selected for training -> node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "2022-08-04 14:23:54,712 fedbiomed INFO - Checking data quality of federated datasets...\n",
      "2022-08-04 14:23:54,726 fedbiomed DEBUG - Model file has been saved: /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0004/my_model_ca99afbf-11da-49a5-9edc-aef5431dd595.py\n",
      "2022-08-04 14:23:54,849 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0004/my_model_ca99afbf-11da-49a5-9edc-aef5431dd595.py successful, with status code 201\n",
      "2022-08-04 14:23:54,958 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0004/aggregated_params_init_c854136d-6b55-43db-9998-dfd0c7af3164.pt successful, with status code 201\n"
     ]
    }
   ],
   "source": [
    "del training_args['fedprox_mu'] \n",
    "\n",
    "model_args.update(standardization = {})\n",
    "\n",
    "exp_fedprox_std_local = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 model_class=MIWAETrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 14:24:00,173 fedbiomed INFO - Sampled nodes in round 0 ['node_cad61f30-5e43-4275-823f-4663210cfcbb', 'node_0b7c1887-216e-49c4-ac10-2ba325ca4d24', 'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8']\n",
      "2022-08-04 14:24:00,174 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': '10b886ad-9724-429c-b1d7-5491da102ef9', 'training_args': scheme:\n",
      "{'lr': {'rules': [<class 'float'>, <function TrainingArgs._lr_hook at 0x150062310>], 'required': False}, 'batch_size': {'rules': [<class 'int'>], 'required': False}, 'epochs': {'rules': [<class 'int'>], 'required': False}, 'dry_run': {'rules': [<class 'bool'>], 'required': False}, 'batch_maxnum': {'rules': [<class 'int'>], 'required': False}, 'test_ratio': {'rules': [<class 'float'>, <function TrainingArgs._test_ratio_hook at 0x1500621f0>], 'required': False, 'default': 0.0}, 'test_on_local_updates': {'rules': [<class 'bool'>], 'required': False, 'default': False}, 'test_on_global_updates': {'rules': [<class 'bool'>], 'required': False, 'default': False}, 'test_metric': {'rules': [<function TrainingArgs._metric_validation_hook at 0x1500620d0>], 'required': False, 'default': None}, 'test_metric_args': {'rules': [<class 'dict'>], 'required': False, 'default': {}}, 'log_interval': {'rules': [<class 'int'>], 'required': False}, 'fedprox_mu': {'rules': [<class 'float'>], 'required': False}}\n",
      "value:\n",
      "{'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13, 'n_latent': 10, 'n_hidden': 128, 'n_samples': 20, 'standardization': {}}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_ca99afbf-11da-49a5-9edc-aef5431dd595.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_c854136d-6b55-43db-9998-dfd0c7af3164.pt', 'model_class': 'MIWAETrainingPlan', 'training_data': {'node_cad61f30-5e43-4275-823f-4663210cfcbb': ['dataset_5032df1b-a636-42c8-9013-ccf988bd4829']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,174 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 14:24:00,175 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': '10b886ad-9724-429c-b1d7-5491da102ef9', 'training_args': {'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13, 'n_latent': 10, 'n_hidden': 128, 'n_samples': 20, 'standardization': {}}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_ca99afbf-11da-49a5-9edc-aef5431dd595.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_c854136d-6b55-43db-9998-dfd0c7af3164.pt', 'model_class': 'MIWAETrainingPlan', 'training_data': {'node_0b7c1887-216e-49c4-ac10-2ba325ca4d24': ['dataset_73d93ba1-c8c8-41da-abbc-8ea6cac2d2a9']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,175 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 14:24:00,176 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
      "\t\t\t\t\t\u001b[1m To\u001b[0m: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t\u001b[1m Request: \u001b[0m: Perform training with the arguments: {'researcher_id': 'researcher_70860f7a-cf92-4e48-89d2-43faab63e063', 'job_id': '10b886ad-9724-429c-b1d7-5491da102ef9', 'training_args': {'batch_size': 48, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100, 'test_ratio': 0.0, 'test_on_local_updates': False, 'test_on_global_updates': False, 'test_metric': None, 'test_metric_args': {}}, 'training': True, 'model_args': {'n_features': 13, 'n_latent': 10, 'n_hidden': 128, 'n_samples': 20, 'standardization': {}}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2022/08/04/my_model_ca99afbf-11da-49a5-9edc-aef5431dd595.py', 'params_url': 'http://localhost:8844/media/uploads/2022/08/04/aggregated_params_init_c854136d-6b55-43db-9998-dfd0c7af3164.pt', 'model_class': 'MIWAETrainingPlan', 'training_data': {'node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8': ['dataset_ade68612-7fa7-4ef2-923d-6ebc94b7547e']}} \n",
      " -----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,176 fedbiomed DEBUG - researcher_70860f7a-cf92-4e48-89d2-43faab63e063\n",
      "2022-08-04 14:24:00,321 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,364 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x178374a60>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,379 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.720678\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,398 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.848170\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,409 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.908340\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,414 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,415 fedbiomed INFO - \u001b[1mWARNING\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m There is no validation activated for the round. Please set flag for `test_on_global_updates`, `test_on_local_updates`, or both. Splitting dataset for validation will be ignored\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,423 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.462533\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,426 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x1782c8100>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,427 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m training with arguments {'history_monitor': <fedbiomed.node.history_monitor.HistoryMonitor object at 0x17a4dd4f0>, 'node_args': {'gpu': False, 'gpu_num': None, 'gpu_only': False}, 'lr': 0.001, 'log_interval': 1, 'epochs': 5, 'dry_run': False, 'batch_maxnum': 100}\u001b[0m\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 14:24:00,438 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.985334\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,447 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.983921\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,448 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.858846\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,449 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.211574\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,461 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.764750\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,462 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.856921\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,463 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.819034\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,471 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.909765\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,472 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.820196\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,473 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 1 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.506299\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,482 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.300194\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,483 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.560756\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,484 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.257369\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,495 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.589664\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,496 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.141989\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,497 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.505290\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,506 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.795135\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,507 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 2 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.256756\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,508 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.690357\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,518 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.517415\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,519 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.808389\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,520 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.846454\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,530 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m5.028674\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,531 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.718330\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,532 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.744795\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,541 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.987054\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,542 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 3 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.662223\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,543 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m6.191742\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,552 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.612133\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,553 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.070934\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,554 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.895230\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,565 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.655535\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,566 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m9.363015\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,576 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.293911\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,579 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 4 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.747529\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,590 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 48/138 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.583696\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,591 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 48/133 (33%) \n",
      " \t\t\t\t\t Loss: \u001b[1m8.544411\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,605 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 96/138 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m4.369554\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,606 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 96/133 (67%) \n",
      " \t\t\t\t\t Loss: \u001b[1m10.099533\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,616 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_cad61f30-5e43-4275-823f-4663210cfcbb \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 138/138 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m3.619930\u001b[0m \n",
      "\t\t\t\t\t ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 14:24:00,617 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
      "\t\t\t\t\t NODE_ID: node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 \n",
      "\t\t\t\t\t Epoch: 5 | Completed: 133/133 (100%) \n",
      " \t\t\t\t\t Loss: \u001b[1m7.782302\u001b[0m \n",
      "\t\t\t\t\t ---------\n",
      "2022-08-04 14:24:00,676 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,718 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:00,803 fedbiomed INFO - \u001b[1mINFO\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m results uploaded successfully \u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:24:10,210 fedbiomed INFO - Downloading model params after training on node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8 - from http://localhost:8844/media/uploads/2022/08/04/node_params_dc3ebe6c-d925-4d5d-bb00-feeedd2e3821.pt\n",
      "2022-08-04 14:24:10,262 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_aa9127aa-5c1b-4a5d-bc16-fb6303f7342e.pt successful, with status code 200\n",
      "2022-08-04 14:24:10,272 fedbiomed INFO - Downloading model params after training on node_0b7c1887-216e-49c4-ac10-2ba325ca4d24 - from http://localhost:8844/media/uploads/2022/08/04/node_params_096c81da-bd0f-4c86-b5d7-1e94ca11ebfe.pt\n",
      "2022-08-04 14:24:10,295 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_7e23539a-dcdc-44ea-8fd7-f3656cd57999.pt successful, with status code 200\n",
      "2022-08-04 14:24:10,307 fedbiomed INFO - Downloading model params after training on node_cad61f30-5e43-4275-823f-4663210cfcbb - from http://localhost:8844/media/uploads/2022/08/04/node_params_4201f509-e057-4d76-bf63-7b36038ae3af.pt\n",
      "2022-08-04 14:24:10,323 fedbiomed DEBUG - upload (HTTP GET request) of file node_params_6e78ce3c-cd79-4b4d-8d4d-14fcd55835b1.pt successful, with status code 200\n",
      "2022-08-04 14:24:10,328 fedbiomed INFO - Nodes that successfully reply in round 0 ['node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8', 'node_0b7c1887-216e-49c4-ac10-2ba325ca4d24', 'node_cad61f30-5e43-4275-823f-4663210cfcbb']\n",
      "2022-08-04 14:24:10,403 fedbiomed DEBUG - upload (HTTP POST request) of file /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0004/aggregated_params_2ee2a9d3-0b65-4ff3-852c-efb0dcd87534.pt successful, with status code 201\n",
      "2022-08-04 14:24:10,404 fedbiomed INFO - Saved aggregated params for round 0 in /Users/ibalelli/Documents/INRIA_EPIONE/FedBioMed/fedbiomed/var/experiments/Experiment_0004/aggregated_params_2ee2a9d3-0b65-4ff3-852c-efb0dcd87534.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_fedprox_std_local.run_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.update(fedprox_mu = 0.1)\n",
    "# Then update training args in the experiment\n",
    "exp_fedprox_std_local.set_training_args(training_args)\n",
    "exp_fedprox_std_local.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and comparison to local training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing on an external dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we are going to test the performance of the final federated model to impute missing data on a test dataset. To this extent we are going to remove randomly 50% of samples from the test dataset, `data_test`, defined at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the test dataset, we will remove randomly 50% of data\n",
    "np.random.seed(1234)\n",
    "\n",
    "perc_miss = 0.5 # 50% of missing data\n",
    "\n",
    "n = data_test.shape[0] # number of observations\n",
    "p = data_test.shape[1] # number of features\n",
    "xfull = np.copy(data_test)\n",
    "xfull = (xfull - fed_mean.numpy())/fed_std.numpy()\n",
    "xmiss = np.copy(xfull)\n",
    "xmiss_flat = xmiss.flatten()\n",
    "miss_pattern = np.random.choice(n*p, np.floor(n*p*perc_miss).astype(np.int_),\\\n",
    "                                replace=False)\n",
    "xmiss_flat[miss_pattern] = np.nan \n",
    "xmiss = xmiss_flat.reshape([n,p]) # in xmiss, the missing values are represented by nans\n",
    "mask = np.isfinite(xmiss) # binary mask that indicates which values are missing\n",
    "xhat_0 = np.copy(xmiss)\n",
    "xhat_0[np.isnan(xmiss)] = 0\n",
    "xhat = np.copy(xhat_0) # This will be out imputed data matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the MIWAE imputation routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miwae_impute(encoder,decoder,iota_x,mask,d,L):\n",
    "    \n",
    "    p_z = td.Independent(td.Normal(loc=torch.zeros(d),scale=torch.ones(d)),1)\n",
    "    \n",
    "    batch_size = iota_x.shape[0]\n",
    "    out_encoder = encoder(iota_x)\n",
    "    q_zgivenxobs = td.Independent(td.Normal(loc=out_encoder[..., :d],scale=torch.nn.Softplus()(out_encoder[..., d:(2*d)])),1)\n",
    "\n",
    "    zgivenx = q_zgivenxobs.rsample([L])\n",
    "    zgivenx_flat = zgivenx.reshape([L*batch_size,d])\n",
    "\n",
    "    out_decoder = decoder(zgivenx_flat)\n",
    "    all_means_obs_model = out_decoder[..., :p]\n",
    "    all_scales_obs_model = torch.nn.Softplus()(out_decoder[..., p:(2*p)]) + 0.001\n",
    "    all_degfreedom_obs_model = torch.nn.Softplus()(out_decoder[..., (2*p):(3*p)]) + 3\n",
    "\n",
    "    data_flat = torch.Tensor.repeat(iota_x,[L,1]).reshape([-1,1])\n",
    "    tiledmask = torch.Tensor.repeat(mask,[L,1])\n",
    "\n",
    "    all_log_pxgivenz_flat = torch.distributions.StudentT(loc=all_means_obs_model.reshape([-1,1]),scale=all_scales_obs_model.reshape([-1,1]),df=all_degfreedom_obs_model.reshape([-1,1])).log_prob(data_flat)\n",
    "    all_log_pxgivenz = all_log_pxgivenz_flat.reshape([L*batch_size,p])\n",
    "\n",
    "    logpxobsgivenz = torch.sum(all_log_pxgivenz*tiledmask,1).reshape([L,batch_size])\n",
    "    logpz = p_z.log_prob(zgivenx)\n",
    "    logq = q_zgivenxobs.log_prob(zgivenx)\n",
    "\n",
    "    xgivenz = td.Independent(td.StudentT(loc=all_means_obs_model, scale=all_scales_obs_model, df=all_degfreedom_obs_model),1)\n",
    "\n",
    "    imp_weights = torch.nn.functional.softmax(logpxobsgivenz + logpz - logq,0) # these are w_1,....,w_L for all observations in the batch\n",
    "    xms = xgivenz.mean.reshape([L,batch_size,p])  # that's the only line that changed!\n",
    "    xm=torch.einsum('ki,kij->ij', imp_weights, xms) \n",
    "\n",
    "    return xm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the MSE function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(xhat,xtrue,mask): # MSE function for imputations\n",
    "    xhat = np.array(xhat)\n",
    "    xtrue = np.array(xtrue)\n",
    "    return np.mean(np.power(xhat-xtrue,2)[~mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the model using last updated federated parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract federated model into PyTorch framework\n",
    "model = exp.model_instance()\n",
    "model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])\n",
    "\n",
    "encoder = model.encoder\n",
    "decoder = model.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the models trained with FedProx and FedCos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fedprox = exp_fedprox.model_instance()\n",
    "model_fedprox.load_state_dict(exp_fedprox.aggregated_params()[rounds - 1]['params'])\n",
    "\n",
    "encoder_fedprox = model_fedprox.encoder\n",
    "decoder_fedprox = model_fedprox.decoder\n",
    "\n",
    "#model_fedcos = exp_fedcos.model_instance()\n",
    "# We should remove the 'disp_global' key from the aggregated paramters since this\n",
    "# is not needed to instantiate the model (just needed for training)\n",
    "#aggregated_params_fedcos = exp_fedcos.aggregated_params()[rounds - 1]['params']\n",
    "#del aggregated_params_fedcos['disp_global']\n",
    "#model_fedcos.load_state_dict(aggregated_params_fedcos)\n",
    "\n",
    "#encoder_fedcos = model_fedcos.encoder\n",
    "#decoder_fedcos = model_fedcos.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we finally do the imputation and evaluate the corresponding imputation error through MSE for each federated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MSE of fed model on testing data 0.530358\n",
      "-----\n",
      "Imputation MSE of fed model (with fedprox) on testing data  0.524753\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "L = 100\n",
    "\n",
    "xhat[~mask] = miwae_impute(encoder = encoder,decoder = decoder,iota_x = torch.from_numpy(xhat_0).float(),mask = torch.from_numpy(mask).float(),d = d,L= L).cpu().data.numpy()[~mask]\n",
    "err_test_data = np.array([mse(xhat,xfull,mask)])\n",
    "print('Imputation MSE of fed model on testing data %g' %err_test_data)\n",
    "print('-----')\n",
    "\n",
    "xhat[~mask] = miwae_impute(encoder = encoder_fedprox,decoder = decoder_fedprox,iota_x = torch.from_numpy(xhat_0).float(),mask = torch.from_numpy(mask).float(),d = d,L= L).cpu().data.numpy()[~mask]\n",
    "err_test_data_fedprox = np.array([mse(xhat,xfull,mask)])\n",
    "print('Imputation MSE of fed model (with fedprox) on testing data  %g' %err_test_data_fedprox)\n",
    "print('-----')\n",
    "#\n",
    "#xhat[~mask] = miwae_impute(encoder = encoder_fedcos,decoder = decoder_fedcos,iota_x = torch.from_numpy(xhat_0).float(),mask = torch.from_numpy(mask).float(),d = d,L= L).cpu().data.numpy()[~mask]\n",
    "#err_test_data_fedcos = np.array([mse(xhat,xfull,mask)])\n",
    "#print('Imputation MSE of fed model (with fedcos) on testing data  %g' %err_test_data_fedcos)\n",
    "#print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing on a client's dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use the final federated model to impute missing data of client 1, which have been used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MSE of fed model on data from client 1  0.576993\n",
      "-----\n",
      "Imputation MSE of fed model (with fedprox) on data from client 1  0.568694\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# We first recover data (full and with missing entries) from client 1\n",
    "data_client_1 = np.copy(Clients_data[0])\n",
    "n = data_client_1.shape[0] # number of observations\n",
    "p = data_client_1.shape[1] # number of features\n",
    "\n",
    "xfull_cl1 = np.copy(data_client_1)\n",
    "xfull_cl1 = (xfull_cl1 - fed_mean.numpy())/fed_std.numpy()\n",
    "\n",
    "xmiss_cl1 = np.copy(Clients_missing[0])\n",
    "xmiss_cl1 = (xmiss_cl1 - fed_mean.numpy())/fed_std.numpy()\n",
    "mask_cl1 = np.isfinite(xmiss_cl1) # binary mask that indicates which values are missing\n",
    "xhat_0_cl1 = np.copy(xmiss_cl1)\n",
    "xhat_0_cl1[np.isnan(xmiss_cl1)] = 0\n",
    "xhat_cl1 = np.copy(xhat_0_cl1) # This will be out imputed data matrix\n",
    "\n",
    "### Now we do the imputation\n",
    "\n",
    "xhat_cl1[~mask_cl1] = miwae_impute(encoder = encoder,decoder = decoder, iota_x = torch.from_numpy(xhat_0_cl1).float(),mask = torch.from_numpy(mask_cl1).float(),d = d,L= L).cpu().data.numpy()[~mask_cl1]\n",
    "err_cl1_data = np.array([mse(xhat_cl1,xfull_cl1,mask_cl1)])\n",
    "print('Imputation MSE of fed model on data from client 1  %g' %err_cl1_data)\n",
    "print('-----')\n",
    "\n",
    "xhat_cl1[~mask_cl1] = miwae_impute(encoder = encoder_fedprox,decoder = decoder_fedprox, iota_x = torch.from_numpy(xhat_0_cl1).float(),mask = torch.from_numpy(mask_cl1).float(),d = d,L= L).cpu().data.numpy()[~mask_cl1]\n",
    "err_cl1_data_fedprox = np.array([mse(xhat_cl1,xfull_cl1,mask_cl1)])\n",
    "print('Imputation MSE of fed model (with fedprox) on data from client 1  %g' %err_cl1_data_fedprox)\n",
    "print('-----')\n",
    "\n",
    "#xhat_cl1[~mask_cl1] = miwae_impute(encoder = encoder_fedcos,decoder = decoder_fedcos, iota_x = torch.from_numpy(xhat_0_cl1).float(),mask = torch.from_numpy(mask_cl1).float(),d = d,L= L).cpu().data.numpy()[~mask_cl1]\n",
    "#err_cl1_data_fedcos = np.array([mse(xhat_cl1,xfull_cl1,mask_cl1)])\n",
    "#print('Imputation MSE of fed model (with fedcos) on data from client 1  %g' %err_cl1_data_fedcos)\n",
    "#print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing of FedProx model with local standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test the federated model with FedProx, where data standardization is performed locally. In order to be as much coherent as possible, each time the standardization will be realized locally as well in the testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MSE of fed model (with fedprox) on testing data  0.566713\n",
      "-----\n",
      "Imputation MSE of fed model (with fedprox) on data from client 1  0.597889\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# We recover the model\n",
    "model_fedprox_std_local = exp_fedprox_std_local.model_instance()\n",
    "model_fedprox_std_local.load_state_dict(exp_fedprox_std_local.aggregated_params()[rounds - 1]['params'])\n",
    "\n",
    "encoder_fedprox_std_local = model_fedprox_std_local.encoder\n",
    "decoder_fedprox_std_local = model_fedprox_std_local.decoder\n",
    "\n",
    "# We re-create the testing dataset, and standardize with respect to his own data\n",
    "np.random.seed(1234)\n",
    "\n",
    "perc_miss = 0.5 # 50% of missing data\n",
    "\n",
    "n = data_test.shape[0] # number of observations\n",
    "p = data_test.shape[1] # number of features\n",
    "xfull = np.copy(data_test)\n",
    "xfull = (xfull - np.mean(xfull,0))/np.std(xfull,0)\n",
    "xmiss = np.copy(xfull)\n",
    "xmiss_flat = xmiss.flatten()\n",
    "miss_pattern = np.random.choice(n*p, np.floor(n*p*perc_miss).astype(np.int_),\\\n",
    "                                replace=False)\n",
    "xmiss_flat[miss_pattern] = np.nan \n",
    "xmiss = xmiss_flat.reshape([n,p]) # in xmiss, the missing values are represented by nans\n",
    "mask = np.isfinite(xmiss) # binary mask that indicates which values are missing\n",
    "xhat_0 = np.copy(xmiss)\n",
    "xhat_0[np.isnan(xmiss)] = 0\n",
    "xhat = np.copy(xhat_0) # This will be out imputed data matrix\n",
    "\n",
    "# We do the imputation\n",
    "xhat[~mask] = miwae_impute(encoder = encoder_fedprox_std_local,decoder = decoder_fedprox_std_local,iota_x = torch.from_numpy(xhat_0).float(),mask = torch.from_numpy(mask).float(),d = d,L= L).cpu().data.numpy()[~mask]\n",
    "err_test_data_fedprox_std_local = np.array([mse(xhat,xfull,mask)])\n",
    "print('Imputation MSE of fed model (with fedprox and local standardization) on testing data  %g' %err_test_data_fedprox_std_local)\n",
    "print('-----')\n",
    "\n",
    "# Same for the dataset from client 1\n",
    "data_client_1 = np.copy(Clients_data[0])\n",
    "n = data_client_1.shape[0] # number of observations\n",
    "p = data_client_1.shape[1] # number of features\n",
    "\n",
    "xfull_cl1 = np.copy(data_client_1)\n",
    "xfull_cl1 = (xfull_cl1 - np.mean(xfull_cl1,0))/np.std(xfull_cl1,0)\n",
    "\n",
    "xmiss_cl1 = np.copy(Clients_missing[0])\n",
    "xmiss_cl1 = (xmiss_cl1 - fed_mean.numpy())/fed_std.numpy()\n",
    "mask_cl1 = np.isfinite(xmiss_cl1) # binary mask that indicates which values are missing\n",
    "xhat_0_cl1 = np.copy(xmiss_cl1)\n",
    "xhat_0_cl1[np.isnan(xmiss_cl1)] = 0\n",
    "xhat_cl1 = np.copy(xhat_0_cl1) # This will be out imputed data matrix\n",
    "\n",
    "xhat_cl1[~mask_cl1] = miwae_impute(encoder = encoder_fedprox_std_local,decoder = decoder_fedprox_std_local, iota_x = torch.from_numpy(xhat_0_cl1).float(),mask = torch.from_numpy(mask_cl1).float(),d = d,L= L).cpu().data.numpy()[~mask_cl1]\n",
    "err_cl1_data_fedprox_std_local = np.array([mse(xhat_cl1,xfull_cl1,mask_cl1)])\n",
    "print('Imputation MSE of fed model (with fedprox and local standardization) on data from client 1  %g' %err_cl1_data_fedprox_std_local)\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Local training and testing on a client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test the performance of the same model trained locally and tested on the dataset from client 1. We will use a total of `epochs`x`rounds` local epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miwae_loss(iota_x,mask,d):\n",
    "    \n",
    "    p_z = td.Independent(td.Normal(loc=torch.zeros(d),scale=torch.ones(d)),1)\n",
    "    \n",
    "    batch_size = iota_x.shape[0]\n",
    "    out_encoder = encoder(iota_x)\n",
    "    q_zgivenxobs = td.Independent(td.Normal(loc=out_encoder[..., :d],scale=torch.nn.Softplus()(out_encoder[..., d:(2*d)])),1)\n",
    "\n",
    "    zgivenx = q_zgivenxobs.rsample([K])\n",
    "    zgivenx_flat = zgivenx.reshape([K*batch_size,d])\n",
    "\n",
    "    out_decoder = decoder(zgivenx_flat)\n",
    "    all_means_obs_model = out_decoder[..., :p]\n",
    "    all_scales_obs_model = torch.nn.Softplus()(out_decoder[..., p:(2*p)]) + 0.001\n",
    "    all_degfreedom_obs_model = torch.nn.Softplus()(out_decoder[..., (2*p):(3*p)]) + 3\n",
    "\n",
    "    data_flat = torch.Tensor.repeat(iota_x,[K,1]).reshape([-1,1])\n",
    "    tiledmask = torch.Tensor.repeat(mask,[K,1])\n",
    "\n",
    "    all_log_pxgivenz_flat = torch.distributions.StudentT(loc=all_means_obs_model.reshape([-1,1]),scale=all_scales_obs_model.reshape([-1,1]),df=all_degfreedom_obs_model.reshape([-1,1])).log_prob(data_flat)\n",
    "    all_log_pxgivenz = all_log_pxgivenz_flat.reshape([K*batch_size,p])\n",
    "\n",
    "    logpxobsgivenz = torch.sum(all_log_pxgivenz*tiledmask,1).reshape([K,batch_size])\n",
    "    logpz = p_z.log_prob(zgivenx)\n",
    "    logq = q_zgivenxobs.log_prob(zgivenx)\n",
    "\n",
    "    neg_bound = -torch.mean(torch.logsumexp(logpxobsgivenz + logpz - logq,0))\n",
    "\n",
    "    return neg_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the local training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "MIWAE likelihood bound  -2.2844\n",
      "Epoch 31\n",
      "MIWAE likelihood bound  -2.193\n",
      "Epoch 61\n",
      "MIWAE likelihood bound  -2.15775\n",
      "Epoch 91\n",
      "MIWAE likelihood bound  -2.20038\n",
      "Epoch 121\n",
      "MIWAE likelihood bound  -2.19855\n"
     ]
    }
   ],
   "source": [
    "# We recover again data (full and with missing entries) from client 1\n",
    "data_client_1 = np.copy(Clients_data[0])\n",
    "xfull_cl1 = np.copy(data_client_1)\n",
    "xfull_cl1 = (xfull_cl1 - fed_mean.numpy())/fed_std.numpy()\n",
    "\n",
    "xmiss_cl1 = np.copy(Clients_missing[0])\n",
    "xmiss_cl1 = (xmiss_cl1 - fed_mean.numpy())/fed_std.numpy()\n",
    "mask_cl1 = np.isfinite(xmiss_cl1) # binary mask that indicates which values are missing\n",
    "xhat_0_cl1 = np.copy(xmiss_cl1)\n",
    "xhat_0_cl1[np.isnan(xmiss_cl1)] = 0\n",
    "xhat_cl1 = np.copy(xhat_0_cl1) # This will be out imputed data matrix\n",
    "\n",
    "n_epochs_local = n_epochs*rounds\n",
    "bs = 48 # batch size\n",
    "\n",
    "encoder_cl1 = nn.Sequential(\n",
    "    torch.nn.Linear(p, h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h, h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h, 2*d),  # the encoder will output both the mean and the diagonal covariance\n",
    ")\n",
    "\n",
    "decoder_cl1 = nn.Sequential(\n",
    "    torch.nn.Linear(d, h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h, h),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h, 3*p),  # the decoder will output both the mean, the scale, and the number of degrees of freedoms (hence the 3*p)\n",
    ")\n",
    "\n",
    "optimizer_cl1 = torch.optim.Adam(list(encoder_cl1.parameters()) + list(decoder_cl1.parameters()),lr=1e-3)\n",
    "\n",
    "def weights_init(layer):\n",
    "    if type(layer) == nn.Linear: torch.nn.init.orthogonal_(layer.weight)\n",
    "        \n",
    "encoder_cl1.apply(weights_init)\n",
    "decoder_cl1.apply(weights_init)\n",
    "\n",
    "for ep in range(1,n_epochs_local):\n",
    "    perm = np.random.permutation(n) # We use the \"random reshuffling\" version of SGD\n",
    "    batches_data = np.array_split(xhat_0_cl1[perm,], n/bs)\n",
    "    batches_mask = np.array_split(mask_cl1[perm,], n/bs)\n",
    "    for it in range(len(batches_data)):\n",
    "        optimizer_cl1.zero_grad()\n",
    "        encoder_cl1.zero_grad()\n",
    "        decoder_cl1.zero_grad()\n",
    "        b_data = torch.from_numpy(batches_data[it]).float()\n",
    "        b_mask = torch.from_numpy(batches_mask[it]).float()\n",
    "        loss = miwae_loss(iota_x = b_data,mask = b_mask, d = d)\n",
    "        loss.backward()\n",
    "        optimizer_cl1.step()\n",
    "    if ep % rounds == 1:\n",
    "        print('Epoch %g' %ep)\n",
    "        print('MIWAE likelihood bound  %g' %(-np.log(K)-miwae_loss(iota_x = torch.from_numpy(xhat_0_cl1).float(),mask = torch.from_numpy(mask_cl1).float(), d = d).cpu().data.numpy())) # Gradient step      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do the imputation on the same dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MSE of local model on data from same client (cl 1)  1.06176\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "xhat_cl1[~mask_cl1] = miwae_impute(encoder = encoder_cl1, decoder = decoder_cl1, iota_x = torch.from_numpy(xhat_0_cl1).float(),mask = torch.from_numpy(mask_cl1).float(),d = d,L= L).cpu().data.numpy()[~mask_cl1]\n",
    "err_local_cl1_data = np.array([mse(xhat_cl1,xfull_cl1,mask_cl1)])\n",
    "print('Imputation MSE of local model on data from same client (cl 1)  %g' %err_local_cl1_data)\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the imputation on the external test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MSE of local model on testing data 0.990027\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "xhat[~mask] = miwae_impute(encoder = encoder_cl1,decoder = decoder_cl1,iota_x = torch.from_numpy(xhat_0).float(),mask = torch.from_numpy(mask).float(),d = d,L= L).cpu().data.numpy()[~mask]\n",
    "err_local_cl1_test_data = np.array([mse(xhat,xfull,mask)])\n",
    "print('Imputation MSE of local model on testing data %g' %err_local_cl1_test_data)\n",
    "print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary of obtained results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation MSE on testing data\n",
      "-----\n",
      "Model          Mean Squared Error (â†“)\n",
      "-----------  ------------------------\n",
      "FedAvg                       0.530358\n",
      "FedProx                      0.524753\n",
      "FedLocStd                    0.566713\n",
      "Local (cl1)                  0.990027\n",
      "-----\n",
      "-----\n",
      "Imputation MSE on local data from client 1\n",
      "-----\n",
      "Model          Mean Squared Error (â†“)\n",
      "-----------  ------------------------\n",
      "FedAvg                       0.576993\n",
      "FedProx                      0.568694\n",
      "FedLocStd                    0.597889\n",
      "Local (cl1)                  1.06176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 14:47:10,546 fedbiomed INFO - \u001b[1mCRITICAL\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_cad61f30-5e43-4275-823f-4663210cfcbb\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Node stopped in signal_handler, probably by user decision (Ctrl C)\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:47:12,686 fedbiomed INFO - \u001b[1mCRITICAL\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_0b7c1887-216e-49c4-ac10-2ba325ca4d24\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Node stopped in signal_handler, probably by user decision (Ctrl C)\u001b[0m\n",
      "-----------------------------------------------------------------\n",
      "2022-08-04 14:47:14,488 fedbiomed INFO - \u001b[1mCRITICAL\u001b[0m\n",
      "\t\t\t\t\t\u001b[1m NODE\u001b[0m node_16ce90b0-e8d1-4327-ae43-e7632d93c6e8\n",
      "\t\t\t\t\t\u001b[1m MESSAGE:\u001b[0m Node stopped in signal_handler, probably by user decision (Ctrl C)\u001b[0m\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print('Imputation MSE on testing data')\n",
    "print('-----')\n",
    "data = [['FedAvg', err_test_data],\n",
    "['FedProx', err_test_data_fedprox],\n",
    "['FedLocStd', err_test_data_fedprox_std_local],\n",
    "['Local (cl1)', err_local_cl1_test_data]]\n",
    "print (tabulate(data, headers=[\"Model\", \"Mean Squared Error (\\u2193)\"]))\n",
    "print('-----')\n",
    "print('-----')\n",
    "print('Imputation MSE on local data from client 1')\n",
    "print('-----')\n",
    "data = [['FedAvg', err_cl1_data],\n",
    "['FedProx', err_cl1_data_fedprox],\n",
    "['FedLocStd', err_cl1_data_fedprox_std_local],\n",
    "['Local (cl1)', err_local_cl1_data]]\n",
    "print (tabulate(data, headers=[\"Model\", \"Mean Squared Error (\\u2193)\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the federated model performs better than the local one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
