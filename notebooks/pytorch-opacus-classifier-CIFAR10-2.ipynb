{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fedbiomed Image Classifier with Differential Privacy with CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how an Image classifier with Opacus (https://opacus.ai/) differential privacy engine can be trained with Fed-BioMed. We refer to the Opacus tutorial available here:\n",
    "https://opacus.ai/tutorials/building_image_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req = Requests()\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the node up\n",
    "It is necessary to previously configure a node:\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 2 (default), and write CIFAR10 to add CIFAR to the node through `torchvision.datasets.CIFAR10`\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where CIFAR is downloaded\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node run`. Wait until you get `Starting task manager`. it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a TorchTrainingPlan Net class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=environ['TMP_DIR']+'/')\n",
    "model_file = tmp_dir_model.name + '/Cifar_opacus.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we are going to define the model using opacus for differential privacy. For this example, we are going to use the `ModuleValidator` function to validate and/or correct models to be compatible with the `opacus` engine, and the function `make_private_with_epsilon` from `opacus.privacy_engine`. \n",
    "\n",
    "To train a model with `make_private_with_epsilon` from Opacus library, there are three privacy-specific hyper-parameters that must be tuned for better performance:\n",
    "\n",
    "* `max_grad_norm`: The maximum L2 norm of per-sample gradients before they are aggregated by the averaging step.\n",
    "* `noise_multiplier`: The amount of noise sampled and added to the average of the gradients in a batch.\n",
    "* `target_epsilon` and `target_delta`: The target Ïµ and Î´ of the (Ïµ,Î´)-differential privacy guarantee. \n",
    "\n",
    "It is worth noting that in order to use the opacus `PrivacyEngine` class we need to properly define as training plan attributes a `model`, a `dataloader` and an `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnnDP import TorchTrainingDPPlan\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from opacus.validators import ModuleValidator\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class CIFAR10DPPlan(TorchTrainingPlan):\n",
    "    def __init__(self, model_args):\n",
    "        super(CIFAR10DPPlan, self).__init__()\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch DataLoader classes\n",
    "        # Since we will train on MNIST, we need datasets and transform from torchvision\n",
    "        deps = [\"from torchvision import datasets, transforms, models\",\n",
    "                \"from torch.utils.data import DataLoader\",\n",
    "                \"import torch.optim as optim\",\n",
    "                \"from opacus.validators import ModuleValidator\",\n",
    "                \"from opacus.utils.batch_memory_manager import BatchMemoryManager\",]\n",
    "        self.add_dependency(deps)\n",
    "        \n",
    "        self.diff_privacy = model_args['diff_privacy']\n",
    "        self.privacy_func = model_args['privacy_func']\n",
    "        self.max_grad_norm = model_args['max_grad_norm']\n",
    "        self.epsilon = model_args['target_epsilon']\n",
    "        self.delta = model_args['target_delta']\n",
    "        self.max_physical_batch_size = model_args['max_physical_batch_size']\n",
    "        \n",
    "        self.num_classes = model_args['num_classes']\n",
    "        self.model = self.make_model()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def make_model(self):\n",
    "        model = models.resnet18(num_classes=self.num_classes)\n",
    "        model = ModuleValidator.fix(model)\n",
    "        ModuleValidator.validate(model, strict=False)      \n",
    "        return model\n",
    "    \n",
    "    def give_optimizer(self,lr):\n",
    "        optimizer = optim.RMSprop(self.model.parameters(), lr=lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_model(self):\n",
    "        self.model.train()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "        CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
    "        # Custom torch Dataloader for CIFAR data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD_DEV),\n",
    "                                       ])\n",
    "        dataset1 = datasets.CIFAR10(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "        return data_loader\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data)\n",
    "        loss   = self.loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side. For instance, the privacy parameters should be passed here.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {'diff_privacy': True, 'privacy_func': 'make_private_with_epsilon',\n",
    "              'num_classes': 10, 'max_grad_norm': 1.2, \n",
    "              'target_epsilon': 50.0, 'target_delta': 1e-5,\n",
    "              'max_physical_batch_size': 100}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 50, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the federated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#CIFAR10', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #nodes=None,\n",
    "                 model_path=model_file,\n",
    "                 model_args=model_args,\n",
    "                 model_class='CIFAR10DPPlan',\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies.keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies[rounds - 1].data\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a little testing routine to extract the accuracy metrics on the testing dataset\n",
    "## Important\n",
    "This is done to test the model because it can be accessed in a developpement environment  \n",
    "In production, the data wont be accessible on the nodes, need a test dataset on the server or accessible from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    device = \"cpu\"\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    loader_size = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            #only uses 10% of the dataset, results are similar but faster\n",
    "            if idx >= loader_size / 10:\n",
    "                pass\n",
    "                break\n",
    "\n",
    "    \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/(data_loader.batch_size * idx)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import os\n",
    "\n",
    "# These values, specific to the CIFAR10 dataset, are assumed to be known.\n",
    "# If necessary, they can be computed with modest privacy budget.\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD_DEV),\n",
    "])\n",
    "\n",
    "base_dir = tmp_dir_model.name \n",
    "if not os.path.isdir(os.path.join(base_dir, \"cifar10\")):\n",
    "    os.makedirs(os.path.join(base_dir, \"cifar10\"))\n",
    "test_data_dir = os.path.join(base_dir, \"cifar10\")\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root=test_data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=48,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a util function to calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model, and we assign to it the model parameters estimated at the last federated optimization round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = models.resnet18(num_classes=10)\n",
    "model = ModuleValidator.fix(model)\n",
    "ModuleValidator.validate(model, strict=False)\n",
    "\n",
    "model = exp.model_instance\n",
    "model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to validate our model on our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we finally test our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc = test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e89561e616b27d96972869796636c18d9df047835da4fde0d47d1d63cf19e486"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
