{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3852a3c8-eeb1-4799-9e5c-6269ced855d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Brain Segmentation\n",
    "\n",
    "This tutorial will show how to use Fed-BioMed to perform image segmentation on 3D medical MRI images of brains, using the publicly available [IXI dataset](https://brain-development.org/ixi-dataset/). \n",
    "It uses a [3D U-Net](https://link.springer.com/chapter/10.1007/978-3-319-46723-8_49) model for the segmentation, trained on data from 3 separate centers. \n",
    "\n",
    "Here we display a very complex case, using advanced Fed-BioMed functionalities such as:\n",
    "- loading a `MedicalFolderDataset`\n",
    "- implementing a custom Node Selection Strategy\n",
    "- setting a non-default Optimizer\n",
    "- monitoring training loss with Tensorboard\n",
    "\n",
    "This tutorial is based on [TorchIO's tutorial](https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/TorchIO_tutorial.ipynb#scrollTo=OoHXr1a4_9Ll)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f52bd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Automatic download and wrangling for the impatient\n",
    "\n",
    "If you're not interested in the details, you may simply execute the [`download_and_split_ixi.py`](./download_and_split_ixi.py) script provided by us, as explained below\n",
    "\n",
    "```shell\n",
    "cd ${FEDBIOMED_DIR}\n",
    "source ./scripts/fedbiomed_environment researcher\n",
    "cd notebooks/medical-image-segmentation\n",
    "python download_and_split_ixi.py -f ../../\n",
    "```\n",
    "\n",
    "After successfully running the command, follow the instructions printed to add the datasets and run the nodes. The tag used for this experiment is `ixi-train`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e4035",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Details about data preparation\n",
    "\n",
    "If you just want to run the notebook, you may skip this section and skip to `Define a new strategy`.\n",
    "\n",
    "First, download the IXI dataset from the [Mendeley archive](https://data.mendeley.com/datasets/7kd5wj7v7p).\n",
    "\n",
    "In this tutorial we are going to use the `MedicalFolderDataset` class provided by the Fed-BioMed library to load medical images in [NIFTI](https://brainder.org/2012/09/23/the-nifti-file-format/) format.\n",
    "Using this dataset class for image segmentation problems guarantees maximum compatibility with the rest of the Fed-BioMed functionalities and features.\n",
    "\n",
    "### Folder structure for MedicalFolderDataset\n",
    "\n",
    "The `MedicalFolderDataset` is heavily inspired by PyTorch's `ImageFolder` Dataset, and requires you to manually prepare the image folders in order to respect a precise structure.\n",
    "The format assumes that you are dealing with imaging data, possibly acquired through multiple modalities, for different study subjects.\n",
    "Hence, you should provide one folder per subject, containing multiple subfolders for each image acquisition modality.\n",
    "Optionally, you may provide a `csv` file containing additional tabular data associated with each subject.\n",
    "This file is typically used for demographics data, and by default is called `participants.csv`.\n",
    "\n",
    "```shell\n",
    "_ root-folder\n",
    " |_ participants.csv\n",
    " |_ subject-1\n",
    " | |_ modality-1\n",
    " | |_ modality-2\n",
    " |_ subject-2\n",
    " | |_ modality-1\n",
    " | |_ modality-2\n",
    " |_ subject-3\n",
    " | |_ modality-1\n",
    " . .\n",
    " . .\n",
    " . .\n",
    "```\n",
    "\n",
    "### Folder structure for this tutorial\n",
    "\n",
    "In the specific case of this tutorial, we encourage you to further divide your images into additional subfolders, according to two criteria: the hospital that generated the data (there are three: Guys, HH and IOP) and a random train/holdout split.\n",
    "Note that each subject's folder will have a name with the following structure: `IXI<SUBJECT_ID>-<HOSPITAL>-<RANDOM_ID>`, for example `IXI002-Guys-0828`.\n",
    "In conclusion, combining the splits above with the structure required by the `MedicalFolderDataset`, your folder tree should look like this:\n",
    "\n",
    "```shell\n",
    "_root-folder\n",
    " |_ Guys\n",
    " | |_ train\n",
    " | | |_ participants.csv\n",
    " | | |_ IXI002-Guys-0828\n",
    " | | | |_ T1                <-- T1 is the first imaging modality\n",
    " | | | |_ T2\n",
    " | | | |_ label\n",
    " | | |_ IXI022-Guys-0701\n",
    " | | | |_ T1\n",
    " | | | |_ T2\n",
    " . . .\n",
    " . . .\n",
    " . . .\n",
    " | |_ holdout\n",
    " | | |_ participants.csv\n",
    " | | |_ IXI004-Guys-0321\n",
    " | | | |_ T1\n",
    " | | | |_ T2\n",
    " | | | |_ label\n",
    " | | | |_ T2\n",
    " . . .\n",
    " . . .\n",
    " . . .\n",
    " |_ HH\n",
    " | |_ train\n",
    " . . .\n",
    " . . .\n",
    " . . .\n",
    " | |_ holdout\n",
    " . . .\n",
    " . . .\n",
    " . . .\n",
    " |_ IOP\n",
    " . . .\n",
    " . . .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a00c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add the IXI dataset to the federated nodes\n",
    "\n",
    "For each of the three hospitals, create a federated node and add the corresponding train dataset by selecting the `medical-folder` data type, and inputting `ixi-train` as the tag.\n",
    "Then start the nodes.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">\n",
    "        Dataset for demograhics of the subjects\n",
    "    </p>\n",
    "    <p>\n",
    "        After selecting the folder that contains the patients for training the CLI will ask for CSV file where demographics of the patient are stored. These CSV files are named as `participants.csv`, and you can find these CSV files in the folder where the subject folders are located e.g `Guys/train/participant.csv`.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "If you don't know how to add datasets to a node, or start a node, please read our [user guide](/user-guide/nodes/deploying-datasets) or follow the [basic tutorial](/tutorials/pytorch/03_PyTorch_MNIST_local_vs_Federated)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb9e4e-0f4c-430d-8887-f98343f652c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a new node sampling Strategy\n",
    "\n",
    "Fed-BioMed's default strategy reads the number of samples per node through the `shape` parameter that is computed when the data is uploaded. \n",
    "For technical reasons, we need to change this to account for the fact that different modalities may have been used during the experiment.\n",
    "Please note node sampling stratgies should inherits from `Strategy` class. Here we are extending `DefaultStrategy` class, which inherits from `Strategy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751760e6-f191-499f-99a6-255df4735c2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "from fedbiomed.common.constants import ErrorNumbers\n",
    "from fedbiomed.common.exceptions import FedbiomedStrategyError\n",
    "\n",
    "class MedicalFolderStrategy(DefaultStrategy):\n",
    "    def __init__(self, data, modalities = ['T1']):\n",
    "        super().__init__(data)\n",
    "        self._modalities = modalities\n",
    "        \n",
    "    def refine(self, training_replies, round_i):\n",
    "        models_params = []\n",
    "        weights = []\n",
    "\n",
    "        # check that all nodes answered\n",
    "        cl_answered = [val['node_id'] for val in training_replies.data()]\n",
    "\n",
    "        answers_count = 0\n",
    "        for cl in self.sample_nodes(round_i):\n",
    "            if cl in cl_answered:\n",
    "                answers_count += 1\n",
    "            else:\n",
    "                # this node did not answer\n",
    "                logger.error(f'{ErrorNumbers.FB408.value} (node = {cl})')\n",
    "\n",
    "        if len(self.sample_nodes(round_i)) != answers_count:\n",
    "            if answers_count == 0:\n",
    "                # none of the nodes answered\n",
    "                msg = ErrorNumbers.FB407.value\n",
    "\n",
    "            else:\n",
    "                msg = ErrorNumbers.FB408.value\n",
    "\n",
    "            logger.critical(msg)\n",
    "            raise FedbiomedStrategyError(msg)\n",
    "\n",
    "        # check that all nodes that answer could successfully train\n",
    "        self._success_node_history[round_i] = []\n",
    "        all_success = True\n",
    "        for tr in training_replies:\n",
    "            if tr['success'] is True:\n",
    "                model_params = {tr['node_id']: tr['params']}\n",
    "                models_params.append(model_params)\n",
    "                self._success_node_history[round_i].append(tr['node_id'])\n",
    "            else:\n",
    "                # node did not succeed\n",
    "                all_success = False\n",
    "                logger.error(f'{ErrorNumbers.FB409.value} (node = {tr[\"node_id\"]})')\n",
    "\n",
    "        if not all_success:\n",
    "            raise FedbiomedStrategyError(ErrorNumbers.FB402.value)\n",
    "\n",
    "        # so far, everything is OK\n",
    "        shapes = [sum(val[0][\"shape\"][modality][0] for modality in self._modalities) for (key, val) in self._fds.data().items()]\n",
    "        totalrows = sum(shapes)\n",
    "        weights = [x / totalrows for x in shapes]\n",
    "        logger.info('Nodes that successfully reply in round ' +\n",
    "                    str(round_i) + ' ' +\n",
    "                    str(self._success_node_history[round_i]))\n",
    "        return models_params, weights\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb49d3-00f7-4c75-b8ac-5588410fb351",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a Training Plan\n",
    "\n",
    "We create a training plan that incorporates the UNet model. We rely on the [unet](https://github.com/fepegar/unet) package for simplicity.\n",
    "Please refer to the original package for more details about UNet:\n",
    "*Pérez-García, Fernando. (2020). fepegar/unet: PyTorch implementation of 2D and 3D U-Net (v0.7.5). Zenodo.* https://doi.org/10.5281/zenodo.3697931\n",
    "\n",
    "### Define the model via the `init_model` function\n",
    "The `init_model` function must return a UNet instance. Please refer to the [TrainingPlan documentation](/user-guide/researcher/training-plan) for more details.\n",
    "\n",
    "### Define the loss function via the `training_step` function\n",
    "Loss function is computed based on the Dice Loss.\n",
    "\n",
    "_Carole H Sudre, Wenqi Li, Tom Vercauteren, Sebastien Ourselin, and M Jorge Cardoso. Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations. In Deep learning in medical image analysis and multimodal learning for clinical decision support, pages 240–248. Springer, 2017._\n",
    "\n",
    "### Define data loading and transformations via the `training_data` function\n",
    "Within the `training_data` function, we create an instance of `MedicalFolderDataset` and pass it to Fed-BioMed's `DataManager` class.\n",
    "\n",
    "To preprocess images, we define the image transformations for the input images and the labels leveraging [MONAI's transforms](https://docs.monai.io/en/stable/transforms.html).\n",
    "Note that we also include the correct dependencies in the `init_dependencies` function.\n",
    "\n",
    "Additionally, we define a transformation for the demographics data contained in the associated `csv` file.\n",
    "In order to be able to use information extracted from the demographics data as inputs to UNet, we must convert it to a `torch.Tensor` object.\n",
    "To achieve this, we exploit the `demographics_transform` argument of the `MedicalFolderDataset`.\n",
    "The transformation defined in this tutorial is just for illustration purposes, it does little more than just extracting some variables from the tabular data and converting them to the appropriate format.\n",
    "\n",
    "### Define training step\n",
    "\n",
    "Here we take as input one batch of (data, target), train the model and compute the loss function. \n",
    "\n",
    "Note that the `MedicalFolderDataset` class returns `data` as a tuple of `(images, demographics)`, where:\n",
    "- `images` is a `dict` of `{modality: image`} (after image transformations)\n",
    "- `demographics` is a `dict` of `{column_name: values}` where the column names are taken from the demographics csv file\n",
    "while the `target` is a `dict` of `{modality: image`} (after target transformations). \n",
    "\n",
    "In our case, the modality used is `T1` for the input images, while the modality used for the target is `label`.\n",
    "In this tutorial, we ignore the values of the demographics data during training because the UNet model only takes images as input.\n",
    "However, the code is provided for illustration purposes as it shows the recommended way to handle the associated tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.logger import logger\n",
    "from fedbiomed.common.data import DataManager, MedicalFolderDataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from unet import UNet\n",
    "\n",
    "class UNetTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "        model = self.Net(model_args)\n",
    "        return model\n",
    "\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        optimizer = AdamW(self.model().parameters())\n",
    "        return optimizer\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        deps = [\"from monai.transforms import (Compose, NormalizeIntensity, AddChannel, Resize, AsDiscrete)\",\n",
    "               \"import torch.nn as nn\",\n",
    "               'import torch.nn.functional as F',\n",
    "               \"from fedbiomed.common.data import MedicalFolderDataset\",\n",
    "               'import numpy as np',\n",
    "               'from torch.optim import AdamW',\n",
    "               'from unet import UNet']\n",
    "        return deps\n",
    "\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        # Init of UNetTrainingPlan\n",
    "        def __init__(self, model_args: dict = {}):\n",
    "            super().__init__()\n",
    "            self.CHANNELS_DIMENSION = 1\n",
    "\n",
    "            self.unet = UNet(\n",
    "                in_channels = model_args.get('in_channels',1),\n",
    "                out_classes = model_args.get('out_classes',2),\n",
    "                dimensions = model_args.get('dimensions',2),\n",
    "                num_encoding_blocks = model_args.get('num_encoding_blocks',5),\n",
    "                out_channels_first_layer = model_args.get('out_channels_first_layer',64),\n",
    "                normalization = model_args.get('normalization', None),\n",
    "                pooling_type = model_args.get('pooling_type', 'max'),\n",
    "                upsampling_type = model_args.get('upsampling_type','conv'),\n",
    "                preactivation = model_args.get('preactivation',False),\n",
    "                residual = model_args.get('residual',False),\n",
    "                padding = model_args.get('padding',0),\n",
    "                padding_mode = model_args.get('padding_mode','zeros'),\n",
    "                activation = model_args.get('activation','ReLU'),\n",
    "                initial_dilation = model_args.get('initial_dilation',None),\n",
    "                dropout = model_args.get('dropout',0),\n",
    "                monte_carlo_dropout = model_args.get('monte_carlo_dropout',0)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.unet.forward(x)\n",
    "            x = F.softmax(x, dim=self.CHANNELS_DIMENSION)\n",
    "            return x\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dice_loss(output, target, epsilon=1e-9):\n",
    "        SPATIAL_DIMENSIONS = 2, 3, 4\n",
    "        p0 = output\n",
    "        g0 = target\n",
    "        p1 = 1 - p0\n",
    "        g1 = 1 - g0\n",
    "        tp = (p0 * g0).sum(dim=SPATIAL_DIMENSIONS)\n",
    "        fp = (p0 * g1).sum(dim=SPATIAL_DIMENSIONS)\n",
    "        fn = (p1 * g0).sum(dim=SPATIAL_DIMENSIONS)\n",
    "        num = 2 * tp\n",
    "        denom = 2 * tp + fp + fn + epsilon\n",
    "        dice_score = num / denom\n",
    "        return 1. - dice_score\n",
    "\n",
    "    @staticmethod\n",
    "    def demographics_transform(demographics):\n",
    "        \"\"\"Transforms dict of demographics into data type for ML.\n",
    "\n",
    "        Must return either a torch Tensor or something Tensor-like\n",
    "        that can be easily converted through the torch.as_tensor()\n",
    "        function.\"\"\"\n",
    "\n",
    "        if isinstance(demographics, dict) and len(demographics) == 0:\n",
    "            # when input is empty dict, we don't want to transform anything\n",
    "            return demographics\n",
    "\n",
    "        # simple example: keep only some keys\n",
    "        keys_to_keep = ['HEIGHT', 'WEIGHT']\n",
    "        out = np.array([float(val) for key, val in demographics.items() if key in keys_to_keep])\n",
    "\n",
    "        # more complex: generate dummy variables for site name\n",
    "        # not ideal as it requires knowing the site names in advance\n",
    "        # could be better implemented with some preprocess\n",
    "        site_names = ['Guys', 'IOP', 'HH']\n",
    "        len_dummy_vars = len(site_names) + 1\n",
    "        dummy_vars = np.zeros(shape=(len_dummy_vars,))\n",
    "        site_name = demographics['SITE_NAME']\n",
    "        if site_name in site_names:\n",
    "            site_idx = site_names.index(site_name)\n",
    "        else:\n",
    "            site_idx = len_dummy_vars - 1\n",
    "        dummy_vars[site_idx] = 1.\n",
    "\n",
    "        return np.concatenate((out, dummy_vars))\n",
    "\n",
    "\n",
    "    def training_data(self,  batch_size = 4):\n",
    "    # The training_data creates the Dataloader to be used for training in the general class Torchnn of fedbiomed\n",
    "        common_shape = (48, 60, 48)\n",
    "        training_transform = Compose([AddChannel(), Resize(common_shape), NormalizeIntensity(),])\n",
    "        target_transform = Compose([AddChannel(), Resize(common_shape), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "        dataset = MedicalFolderDataset(\n",
    "            root=self.dataset_path,\n",
    "            data_modalities='T1',\n",
    "            target_modalities='label',\n",
    "            transform=training_transform,\n",
    "            target_transform=target_transform,\n",
    "            demographics_transform=UNetTrainingPlan.demographics_transform)\n",
    "        loader_arguments = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset, **loader_arguments)\n",
    "\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        #this function must return the loss to backward it\n",
    "        img = data[0]['T1']\n",
    "        demographics = data[1]\n",
    "        output = self.model().forward(img)\n",
    "        loss = UNetTrainingPlan.get_dice_loss(output, target['label'])\n",
    "        avg_loss = loss.mean()\n",
    "        return avg_loss\n",
    "\n",
    "    def testing_step(self, data, target):\n",
    "        img = data[0]['T1']\n",
    "        demographics = data[1]\n",
    "        target = target['label']\n",
    "        prediction = self.model().forward(img)\n",
    "        loss = UNetTrainingPlan.get_dice_loss(prediction, target)\n",
    "        avg_loss = loss.mean()  # average per batch\n",
    "        return avg_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the experiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'in_channels': 1,\n",
    "    'out_classes': 2,\n",
    "    'dimensions': 3,\n",
    "    'num_encoding_blocks': 3,\n",
    "    'out_channels_first_layer': 8,\n",
    "    'normalization': 'batch',\n",
    "    'upsampling_type': 'linear',\n",
    "    'padding': True,\n",
    "    'activation': 'PReLU',\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'batch_size': 16, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,\n",
    "    'log_interval': 2,\n",
    "    'test_ratio' : 0.1,\n",
    "    'test_on_global_updates': True,\n",
    "    'test_on_local_updates': True,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['ixi-train']\n",
    "num_rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=UNetTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 tensorboard=True\n",
    "                )\n",
    "medical_folder_strategy = MedicalFolderStrategy(exp._fds, modalities=['T1'])\n",
    "_ = exp.set_strategy(node_selection_strategy=medical_folder_strategy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.training_plan_file()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorboard setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensorboard --logdir \"$tensorboard_dir\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On a Macbook Pro from 2015 with a 2,5 GHz Quad-Core Intel Core i7 processor and 16GB of DRAM, training for 3 rounds of 2 epochs each took about 30 minutes.\n",
    "The final training curves look like this:\n",
    "\n",
    "![image.png](attachment:2ae42e31-e963-4e55-9ce1-244158988168.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run the experiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89383694-58a2-4c61-bc25-a9b434f48ed0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local_training_plan = UNetTrainingPlan()\n",
    "local_model = local_training_plan.init_model(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8f127-3ca1-4d1d-86f2-95bb4badfe54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dependency_statement in local_training_plan.init_dependencies():\n",
    "    exec(dependency_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5eb090-f216-48da-a8ef-291ed1ed031f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local_model.load_state_dict(exp.aggregated_params()[num_rounds-1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed743b1-38ac-4e7d-bafe-7639fff4beb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define a validation data loader\n",
    "\n",
    "We extract the validation data loader from the training plan as well. This requires some knowledge about the internals of the `MedicalFolderDataset` class. At the end of the process, calling the `split` function with a ratio of 0 will return a data loader that loads all of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339706f-b645-4719-a1d1-3cdf2debb80d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset_parameters = {\n",
    "    'tabular_file': '../data/Hospital-Centers/Guys/holdout/participants.csv',\n",
    "    'index_col': 14\n",
    "}\n",
    "local_training_plan.dataset_path = '../data/Hospital-Centers/Guys/holdout/'\n",
    "val_data_manager = local_training_plan.training_data(batch_size=4)\n",
    "val_data_manager._dataset.set_dataset_parameters(dataset_parameters)\n",
    "val_data_loader = DataLoader(val_data_manager._dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284da20-f0c0-48fa-95c6-fc30ef8e0af7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compute the loss on validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402a6d5-67ea-4505-83b9-239d54b579db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "local_model.eval()\n",
    "\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (images, demographics), targets in val_data_loader:\n",
    "        image = images['T1']\n",
    "        target = targets['label']\n",
    "        prediction = local_model.forward(image)\n",
    "        loss = UNetTrainingPlan.get_dice_loss(prediction, target)\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8345fad-b813-4a83-997e-c17a17731a58",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize the outputs\n",
    "\n",
    "As a bonus, we visualize the outputs of our model on the holdout dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108cfb9-b3aa-4b66-a6f1-82cc183039f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one_batch = next(iter(val_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4e665-6309-495b-879d-31046eef9781",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`one_batch` contains both input features and labels. Both are 3D images, which can be accessed in the following way (`k` represents the _height_ in the stack of images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed855d9-4c23-421f-9bf3-88e4292d8919",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 24\n",
    "one_batch[1]['label'][..., k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd48024-0082-4760-a7da-5c7d60767d43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 24\n",
    "one_batch[0][0]['T1'][..., k].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3a022-2dde-4052-bc7d-35e9724209fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "import torchvision\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ef98c-3f14-4dce-94cf-e1280b6397d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = 24\n",
    "batch_mri = one_batch[0][0]['T1'][..., k]\n",
    "batch_label = one_batch[1]['label'][:, 1:, ..., k]\n",
    "slices = torch.cat((batch_mri, batch_label))\n",
    "image_path = 'batch_whole_images.png'\n",
    "torchvision.utils.save_image(\n",
    "    slices,\n",
    "    image_path,\n",
    "    nrow=max(val_data_loader.batch_size//2,1),\n",
    "    normalize=True,\n",
    "    scale_each=True,\n",
    "    padding=4,\n",
    ")\n",
    "display.Image(image_path, width=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}