{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing : Download Used Cars Dataset \n",
    "https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Details\n",
    "The data consists of used cars listings. 100,000 listings, which have been separated into files corresponding to each car manufacturer. Each file will simulate data for each node.\n",
    "\n",
    "# Goal\n",
    "\n",
    "The goal of this tutorial is to build a federated regression model on Non-IID dataset and generate the best model by performing validation on hold out dataset and tuning hyperparameters.The metric used to decide best model is RMSE."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "audi = pd.read_csv(\"___PATH to audi.csv___\")\n",
    "bmw = pd.read_csv(\"___PATH to bmw.csv___\")\n",
    "# Use Ford for final validation at central researcher\n",
    "ford = pd.read_csv(\"___PATH to ford.csv___\")\n",
    "\n",
    "# Use the following csvs if you want to run more than 2 nodes. Uncomment Corresponding lines in the following cell blocks\n",
    "# cclass = pd.read_csv(\"___PATH to cclass.csv___\")\n",
    "# focus = pd.read_csv(\"___PATH to focus.csv___\")\n",
    "# hyundai = pd.read_csv(\"___PATH to huyndai.csv___\")\n",
    "# merc = pd.read_csv(\"___PATH to merc.csv___\")\n",
    "# skoda = pd.read_csv(\"___PATH to skoda.csv___\")\n",
    "# toyata = pd.read_csv(\"___PATH to toyata.csv___\")\n",
    "# vauxhall = pd.read_csv(\"___PATH to vauxhall.csv___\")\n",
    "# vw = pd.read_csv(\"__PATH to vw.csv___\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop columns model & fuelType as labels are not consistent across files. A better solution could be vertical federated learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "audi.drop(columns = ['model','fuelType'],inplace = True)\n",
    "bmw.drop(columns = ['model','fuelType'],inplace = True)\n",
    "ford.drop(columns = ['model','fuelType'],inplace = True)\n",
    "\n",
    "# cclass.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# focus.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# hyundai.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# merc.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# skoda.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# toyata.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# vauxhall.drop(columns = ['model','fuelType'],inplace = True)\n",
    "# vw.drop(columns = ['model','fuelType'],inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Label encode transmission column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "audi['transmission'] = audi['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "bmw['transmission'] = bmw['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "ford['transmission'] = ford['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "\n",
    "# cclass['transmission'] = cclass['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# focus['transmission'] = focus['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# hyundai['transmission'] = hyundai['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# merc['transmission'] = merc['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# skoda['transmission'] = skoda['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# toyata['transmission'] = toyata['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# vauxhall['transmission'] = vauxhall['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})\n",
    "# vw['transmission'] = vw['transmission'].map({'Automatic':0,'Manual':1,'Semi-Auto':2,'Other':3})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "audi.to_csv('audi_transformed.csv',header = True,index= False)\n",
    "bmw.to_csv('bmw_transformed.csv',header = True,index= False)\n",
    "ford.to_csv('ford_transformed.csv',header = True,index= False)\n",
    "\n",
    "# cclass.to_csv('cclass_transformed.csv',header = True,index= False)\n",
    "# focus.to_csv('focus_transformed.csv',header = True,index= False)\n",
    "# hyundai.to_csv('huydai_transformed.csv',header = True,index= False)\n",
    "# merc.to_csv('merc_transformed.csv',header = True,index= False)\n",
    "# skoda.to_csv('skoda_transformed.csv',header = True,index= False)\n",
    "# toyata.to_csv('toyata_transformed.csv',header = True,index= False)\n",
    "# vauxhall.to_csv('vaxhall_transformed.csv',header = True,index= False)\n",
    "# vw.to_csv('vw_transformed.csv',header = True,index= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fedbiomed Researcher to train a model on a Used Cars dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use for developing (autoreloads changes made across packages)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start the network and setting the client up\n",
    "Before running this notebook, you shoud start the network from fedbiomed-network, as detailed in https://gitlab.inria.fr/fedbiomed/fedbiomed-network\n",
    "Therefore, it is necessary to previously configure a node:\n",
    "Also ensure that you have run data-preprocessing-used-cars-dataset.ipynb notebook to preprocess the used cars dataset\n",
    "1. `./scripts/fedbiomed_run node add`\n",
    "  * Select option 1 to add a csv file to the client\n",
    "  * Choose the name, tags and description of the dataset\n",
    "  * Spin as many nodes as you want(max nodes 11 for 11 csv files in used cars dataset). Hold out one file for testing.\n",
    "  * Load the .csv file generated using above mentioned notebook to individual nodes\n",
    "2. Check that your data has been added by executing `./scripts/fedbiomed_run node list`\n",
    "3. Run the node using `./scripts/fedbiomed_run node start`. Wait until you get `Connected with result code 0`. it means you are online."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create an experiment to train a model on the data found"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declare a torch.nn MyTrainingPlan class to send for training on the node"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from fedbiomed.researcher.environ import TMP_DIR\n",
    "import tempfile\n",
    "tmp_dir_model = tempfile.TemporaryDirectory(dir=TMP_DIR+'/')\n",
    "model_file = tmp_dir_model.name + '/class_export_csv.py'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note : write **only** the code to export in the following cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%%writefile \"$model_file\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.torchnn import TorchTrainingPlan\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'MyTrainingPlan')\n",
    "class MyTrainingPlan(TorchTrainingPlan):       \n",
    "    def __init__(self, kwargs):\n",
    "        super(MyTrainingPlan, self).__init__()\n",
    "        # kwargs should match the model arguments to be passed below to the experiment class\n",
    "        self.in_features = kwargs['in_features']\n",
    "        self.out_features = kwargs['out_features']\n",
    "        self.fc1 = nn.Linear(self.in_features, 5)\n",
    "        self.fc2 = nn.Linear(5, self.out_features)\n",
    "        \n",
    "        # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "        # In this case, we need the torch Dataset and DataLoader classes\n",
    "        # We need pandas to read the local .csv file at the client side\n",
    "        deps = [\"from torch.utils.data import Dataset, DataLoader\",\n",
    "                \"import pandas as pd\"]\n",
    "        self.add_dependency(deps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.forward(data).float()\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        loss   = torch.sqrt(criterion(output, target.unsqueeze(1)))\n",
    "        return loss\n",
    "\n",
    "    class csv_Dataset(Dataset):\n",
    "    # Here we define a custom Dataset class inherited from the general torch Dataset class\n",
    "    # This class takes as argument a .csv file path and creates a torch Dataset \n",
    "        def __init__(self, dataset_path, x_dim):\n",
    "            self.input_file = pd.read_csv(dataset_path,sep=',',index_col=False)\n",
    "            x_train = self.input_file.loc[:,('year','transmission','mileage','tax','mpg','engineSize')].values\n",
    "            y_train = self.input_file.loc[:,'price'].values\n",
    "            self.X_train = torch.from_numpy(x_train).float()\n",
    "            self.Y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "        def __len__(self):            \n",
    "            return len(self.Y_train)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "\n",
    "            return (self.X_train[idx], self.Y_train[idx])\n",
    "        \n",
    "    def training_data(self,  batch_size = 48):\n",
    "    # The training_data creates the Dataloader to be used for training in the general class TorchTrainingPlan of fedbiomed\n",
    "        dataset = self.csv_Dataset(self.dataset_path, self.in_features)\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        data_loader = DataLoader(dataset, **train_kwargs)\n",
    "        return data_loader"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Writing /home/fedbiomed/fedbiomed/var/tmp/tmplcbohsuc/class_export_csv.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# model parameters \n",
    "model_args = {\n",
    "    'in_features': 6, \n",
    "    'out_features': 1\n",
    "}\n",
    "\n",
    "# training parameters \n",
    "training_args = {\n",
    "    'batch_size': 40, \n",
    "    'lr': 1e-3, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,  \n",
    "    #'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define an experiment\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of client ID with `clients`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `rounds` rounds, applying the `client_selection_strategy` between the rounds"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "# Calling the training data with specified tags. Change the following tag accordingly\n",
    "tags =  ['UsedCars']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 #clients=None,\n",
    "                 model_path=model_file,\n",
    "                 model_class='MyTrainingPlan',\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 rounds=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 client_selection_strategy=None)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Messaging 6309fcbb-bae7-4c2a-adb9-631e5b9db5b4  connected with result code 0\n",
      "Searching for clients with data tags: ['UsedCars'] ...\n",
      "2021-09-13 16:57:12.241643 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'success': True, 'databases': [{'name': 'UsedCars', 'data_type': 'csv', 'tags': ['UsedCars'], 'description': 'UsedCars', 'shape': [10781, 6], 'dataset_id': 'dataset_3843dd0a-ea4e-4281-b955-e68e71065448'}], 'count': 1, 'node_id': 'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'command': 'search'}\n",
      "2021-09-13 16:57:12.284651 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'success': True, 'databases': [{'name': 'UsedCars', 'data_type': 'csv', 'tags': ['UsedCars'], 'description': 'UsedCars', 'shape': [10668, 6], 'dataset_id': 'dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b'}], 'count': 1, 'node_id': 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe', 'command': 'search'}\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `rounds` are done for all the clients"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "exp.run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sampled clients in round  0   ['client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe']\n",
      "[ RESEARCHER ] Send message to client  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'training_args': {'batch_size': 40, 'lr': 0.001, 'epochs': 2, 'dry_run': False}, 'model_args': {'in_features': 6, 'out_features': 1}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_cac1f991-2efd-4780-8878-d0d70e2ac890.py', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_4e8c25ac-9f49-4027-b5f6-798d2afd0394.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67': ['dataset_3843dd0a-ea4e-4281-b955-e68e71065448']}}\n",
      "researcher_702f019d-9c48-47c8-8811-14cb5d5560db\n",
      "[ RESEARCHER ] Send message to client  client_41d55762-b0d3-4050-9ee1-07537fcf7abe {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'training_args': {'batch_size': 40, 'lr': 0.001, 'epochs': 2, 'dry_run': False}, 'model_args': {'in_features': 6, 'out_features': 1}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_cac1f991-2efd-4780-8878-d0d70e2ac890.py', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_4e8c25ac-9f49-4027-b5f6-798d2afd0394.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_41d55762-b0d3-4050-9ee1-07537fcf7abe': ['dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b']}}\n",
      "researcher_702f019d-9c48-47c8-8811-14cb5d5560db\n",
      "2021-09-13 16:57:27.744705 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'success': True, 'node_id': 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe', 'dataset_id': 'dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/node_params_ebab3bca-8d18-45d9-acb9-6326bc934c65.pt', 'timing': {'rtime_training': 1.6344226999790408, 'ptime_training': 1.6524848999999904}, 'msg': '', 'command': 'train'}\n",
      "2021-09-13 16:57:27.826814 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'success': True, 'node_id': 'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'dataset_id': 'dataset_3843dd0a-ea4e-4281-b955-e68e71065448', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/node_params_8fdf28fc-1f1f-4b54-8b6e-0c046e3dd584.pt', 'timing': {'rtime_training': 1.640171500039287, 'ptime_training': 1.6577793999999813}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_41d55762-b0d3-4050-9ee1-07537fcf7abe \n",
      "\t- from http://localhost:8844/media/uploads/2021/09/13/node_params_ebab3bca-8d18-45d9-acb9-6326bc934c65.pt\n",
      "Downloading model params after training on  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 \n",
      "\t- from http://localhost:8844/media/uploads/2021/09/13/node_params_8fdf28fc-1f1f-4b54-8b6e-0c046e3dd584.pt\n",
      "Clients that successfully reply in round  0   ['client_41d55762-b0d3-4050-9ee1-07537fcf7abe', 'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67']\n",
      "Sampled clients in round  1   ['client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe']\n",
      "[ RESEARCHER ] Send message to client  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'training_args': {'batch_size': 40, 'lr': 0.001, 'epochs': 2, 'dry_run': False}, 'model_args': {'in_features': 6, 'out_features': 1}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_cac1f991-2efd-4780-8878-d0d70e2ac890.py', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/researcher_params_5119bd82-ea51-467f-9ef2-1b9a9571c8e7.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67': ['dataset_3843dd0a-ea4e-4281-b955-e68e71065448']}}\n",
      "researcher_702f019d-9c48-47c8-8811-14cb5d5560db\n",
      "[ RESEARCHER ] Send message to client  client_41d55762-b0d3-4050-9ee1-07537fcf7abe {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'training_args': {'batch_size': 40, 'lr': 0.001, 'epochs': 2, 'dry_run': False}, 'model_args': {'in_features': 6, 'out_features': 1}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_cac1f991-2efd-4780-8878-d0d70e2ac890.py', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/researcher_params_5119bd82-ea51-467f-9ef2-1b9a9571c8e7.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_41d55762-b0d3-4050-9ee1-07537fcf7abe': ['dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b']}}\n",
      "researcher_702f019d-9c48-47c8-8811-14cb5d5560db\n",
      "2021-09-13 16:57:35.916184 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'success': True, 'node_id': 'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'dataset_id': 'dataset_3843dd0a-ea4e-4281-b955-e68e71065448', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/node_params_4e46a793-f860-40dc-a350-b24d14646ada.pt', 'timing': {'rtime_training': 0.8470348999835551, 'ptime_training': 0.8567428000000064}, 'msg': '', 'command': 'train'}\n",
      "2021-09-13 16:57:36.006104 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'success': True, 'node_id': 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe', 'dataset_id': 'dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/node_params_8f13abf6-9a3d-44d8-b56c-72b75e9997c2.pt', 'timing': {'rtime_training': 0.836470799986273, 'ptime_training': 0.8508013000000005}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 \n",
      "\t- from http://localhost:8844/media/uploads/2021/09/13/node_params_4e46a793-f860-40dc-a350-b24d14646ada.pt\n",
      "Downloading model params after training on  client_41d55762-b0d3-4050-9ee1-07537fcf7abe \n",
      "\t- from http://localhost:8844/media/uploads/2021/09/13/node_params_8f13abf6-9a3d-44d8-b56c-72b75e9997c2.pt\n",
      "Clients that successfully reply in round  1   ['client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe']\n",
      "Sampled clients in round  2   ['client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe']\n",
      "[ RESEARCHER ] Send message to client  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'training_args': {'batch_size': 40, 'lr': 0.001, 'epochs': 2, 'dry_run': False}, 'model_args': {'in_features': 6, 'out_features': 1}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_cac1f991-2efd-4780-8878-d0d70e2ac890.py', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/researcher_params_8febef30-28e1-4506-a8e8-806f8f80bd6f.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67': ['dataset_3843dd0a-ea4e-4281-b955-e68e71065448']}}\n",
      "researcher_702f019d-9c48-47c8-8811-14cb5d5560db\n",
      "[ RESEARCHER ] Send message to client  client_41d55762-b0d3-4050-9ee1-07537fcf7abe {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'training_args': {'batch_size': 40, 'lr': 0.001, 'epochs': 2, 'dry_run': False}, 'model_args': {'in_features': 6, 'out_features': 1}, 'command': 'train', 'model_url': 'http://localhost:8844/media/uploads/2021/09/13/my_model_cac1f991-2efd-4780-8878-d0d70e2ac890.py', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/researcher_params_8febef30-28e1-4506-a8e8-806f8f80bd6f.pt', 'model_class': 'MyTrainingPlan', 'training_data': {'client_41d55762-b0d3-4050-9ee1-07537fcf7abe': ['dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b']}}\n",
      "researcher_702f019d-9c48-47c8-8811-14cb5d5560db\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-09-13 16:57:45.916037 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'success': True, 'node_id': 'client_41d55762-b0d3-4050-9ee1-07537fcf7abe', 'dataset_id': 'dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/node_params_f852c488-f912-43bb-bf2f-688516f9e572.pt', 'timing': {'rtime_training': 0.7563033000333235, 'ptime_training': 0.7666934000000083}, 'msg': '', 'command': 'train'}\n",
      "2021-09-13 16:57:45.986156 [ RESEARCHER ] message received. {'researcher_id': 'researcher_702f019d-9c48-47c8-8811-14cb5d5560db', 'job_id': '40227b54-d516-46ce-b94f-77166035feaf', 'success': True, 'node_id': 'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67', 'dataset_id': 'dataset_3843dd0a-ea4e-4281-b955-e68e71065448', 'params_url': 'http://localhost:8844/media/uploads/2021/09/13/node_params_3fdb8a71-4f9a-49c5-9c4c-ae2f398b5a67.pt', 'timing': {'rtime_training': 0.7873878999962471, 'ptime_training': 0.7975870000000214}, 'msg': '', 'command': 'train'}\n",
      "Downloading model params after training on  client_41d55762-b0d3-4050-9ee1-07537fcf7abe \n",
      "\t- from http://localhost:8844/media/uploads/2021/09/13/node_params_f852c488-f912-43bb-bf2f-688516f9e572.pt\n",
      "Downloading model params after training on  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 \n",
      "\t- from http://localhost:8844/media/uploads/2021/09/13/node_params_3fdb8a71-4f9a-49c5-9c4c-ae2f398b5a67.pt\n",
      "Clients that successfully reply in round  2   ['client_41d55762-b0d3-4050-9ee1-07537fcf7abe', 'client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67']\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Local training results for each round and each node are available in `exp.training_replies` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the training results for the last round below.\n",
    "\n",
    "Different timings (in seconds) are reported for each dataset of a node participating in a round :\n",
    "- `rtime_training` real time (clock time) spent in the training function on the node\n",
    "- `ptime_training` process time (user and system CPU) spent in the training function on the node\n",
    "- `rtime_total` real time (clock time) spent in the researcher between sending the request and handling the response, at the `Job()` layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies.keys())\n",
    "\n",
    "print(\"\\nList the clients for the last training round and their timings : \")\n",
    "round_data = exp.training_replies[rounds - 1].data\n",
    "for c in range(len(round_data)):\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = round_data[c]['node_id'],\n",
    "        rtraining = round_data[c]['timing']['rtime_training'],\n",
    "        ptraining = round_data[c]['timing']['ptime_training'],\n",
    "        rtotal = round_data[c]['timing']['rtime_total']))\n",
    "print('\\n')\n",
    "    \n",
    "exp.training_replies[rounds - 1].dataframe"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "List the training rounds :  dict_keys([0, 1, 2])\n",
      "\n",
      "List the clients for the last training round and their timings : \n",
      "\t- client_41d55762-b0d3-4050-9ee1-07537fcf7abe :    \n",
      "\t\trtime_training=0.76 seconds    \n",
      "\t\tptime_training=0.77 seconds    \n",
      "\t\trtime_total=10.01 seconds\n",
      "\t- client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67 :    \n",
      "\t\trtime_training=0.79 seconds    \n",
      "\t\tptime_training=0.80 seconds    \n",
      "\t\trtime_total=10.03 seconds\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>msg</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>params_path</th>\n",
       "      <th>params</th>\n",
       "      <th>timing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b</td>\n",
       "      <td>client_41d55762-b0d3-4050-9ee1-07537fcf7abe</td>\n",
       "      <td>/home/fedbiomed/fedbiomed/var/tmp/my_model_af3...</td>\n",
       "      <td>{'fc1.weight': [[tensor(2.2414), tensor(1.4931...</td>\n",
       "      <td>{'rtime_training': 0.7563033000333235, 'ptime_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>dataset_3843dd0a-ea4e-4281-b955-e68e71065448</td>\n",
       "      <td>client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67</td>\n",
       "      <td>/home/fedbiomed/fedbiomed/var/tmp/my_model_367...</td>\n",
       "      <td>{'fc1.weight': [[tensor(2.2512), tensor(1.5125...</td>\n",
       "      <td>{'rtime_training': 0.7873878999962471, 'ptime_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   success msg                                    dataset_id  \\\n",
       "0     True      dataset_92d53d50-548d-4fc6-a98d-5ca7233a2c8b   \n",
       "1     True      dataset_3843dd0a-ea4e-4281-b955-e68e71065448   \n",
       "\n",
       "                                     node_id  \\\n",
       "0  client_41d55762-b0d3-4050-9ee1-07537fcf7abe   \n",
       "1  client_293f2b07-c5c0-4ac1-9ea2-28fe09fd9f67   \n",
       "\n",
       "                                         params_path  \\\n",
       "0  /home/fedbiomed/fedbiomed/var/tmp/my_model_af3...   \n",
       "1  /home/fedbiomed/fedbiomed/var/tmp/my_model_367...   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'fc1.weight': [[tensor(2.2414), tensor(1.4931...   \n",
       "1  {'fc1.weight': [[tensor(2.2512), tensor(1.5125...   \n",
       "\n",
       "                                              timing  \n",
       "0  {'rtime_training': 0.7563033000333235, 'ptime_...  \n",
       "1  {'rtime_training': 0.7873878999962471, 'ptime_...  "
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Federated parameters for each round are available in `exp.aggregated_params` (index 0 to (`rounds` - 1) ).\n",
    "\n",
    "For example you can view the federated parameters for the last round of the experiment :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(\"\\nList the training rounds : \", exp.aggregated_params.keys())\n",
    "\n",
    "print(\"\\nAccess the federated params for the last training round :\")\n",
    "print(\"\\t- params_path: \", exp.aggregated_params[rounds - 1]['params_path'])\n",
    "print(\"\\t- parameter data: \", exp.aggregated_params[rounds - 1]['params'].keys())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "List the training rounds :  dict_keys([0, 1, 2])\n",
      "\n",
      "Access the federated params for the last training round :\n",
      "\t- params_path:  /home/fedbiomed/fedbiomed/var/tmp/researcher_params_b06b09d0-e859-4579-861e-4273f33ca468.pt\n",
      "\t- parameter data:  odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "fed_model = exp.model_instance\n",
    "fed_model.load_state_dict(exp.aggregated_params[rounds - 1]['params'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    " fed_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MyTrainingPlan(\n",
       "  (fc1): Linear(in_features=6, out_features=5, bias=True)\n",
       "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Hold one file for testing the fed model\n",
    "test_dataset_path =\"__PATH to ford_transformed.csv___\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "def cal_rmse(actual, prediction):\n",
    "    return ((actual- prediction)**2).mean()**0.5\n",
    "\n",
    "def testing_rmse(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    device = 'cpu'\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            preds.append(output.numpy().flatten())\n",
    "    rmse = cal_rmse(data_loader.dataset.Y_train.numpy(),np.hstack(preds))\n",
    "    return rmse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "class csv_Dataset(Dataset):\n",
    "        def __init__(self, dataset_path):\n",
    "            self.input_file = pd.read_csv(dataset_path,sep=',',index_col=False)\n",
    "            x_train = self.input_file.loc[:,('year','transmission','mileage','tax','mpg','engineSize')].values\n",
    "            y_train = self.input_file.loc[:,'price'].values\n",
    "            self.X_train = torch.from_numpy(x_train).float()\n",
    "            self.Y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "        def __len__(self):            \n",
    "            return len(self.Y_train)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "\n",
    "            return (self.X_train[idx], self.Y_train[idx])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dataset = csv_Dataset(test_dataset_path)\n",
    "train_kwargs = {'batch_size': 64, 'shuffle': True}\n",
    "data_loader = DataLoader(dataset, **train_kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "rmse = testing_rmse(fed_model, data_loader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "rmse"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7471.202045186571"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e416aa0399b226346633f35c0f9bb77d7e7cf1619eb46cae5c1dd017cab61cfc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
