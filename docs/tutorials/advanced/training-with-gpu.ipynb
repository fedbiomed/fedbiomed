{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch model training using a GPU\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates using a Nvidia GPU for training a model.\n",
    "\n",
    "The nodes for this example need to run on a machine providing a Nvidia GPU with enough GPU memory (and from a not-too-old model, so that it is supported by PyTorch).\n",
    "\n",
    "If GPU doesn't have enough memory you will get a **out of memory error** at run time.\n",
    "\n",
    "You can check [Fed-BioMed GPU documentation](../../../user-guide/nodes/using-gpu) for some background about using GPUs with Fed-BioMed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the network\n",
    "Before running this notebook, start the network with `{FEDBIOMED_DIR}/scripts/fedbiomed_run network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the nodes up\n",
    "We need at least 1 node, let's test using 3 nodes.\n",
    "\n",
    "1. For each node, add the MNIST dataset :\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config1.ini add\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config2.ini add\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config3.ini add\n",
    "```\n",
    "  * Select option 2 (default) to add MNIST to the node\n",
    "  * Confirm default tags by hitting \"y\" and ENTER\n",
    "  * Pick the folder where MNIST is already downloaded (or where to download MNIST)\n",
    "  \n",
    "2. Check that your data has been added by executing\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config1.ini list\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config2.ini list\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config3.ini list\n",
    "```\n",
    "\n",
    "3. Run the first node using\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config1.ini start --gpu\n",
    "```\n",
    "so that the node offers to use GPU for training, with the default GPU device.\n",
    "\n",
    "4. Run the second node using\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config2.ini start --gpu-only --gpunum 1\n",
    "```\n",
    "so that the node enforces use of GPU for training even if the researcher doesn't request it, and requests using the 2nd GPU (device 1) but will fallback to default device if you don't have 2 GPUs on this machine.\n",
    "\n",
    "5. Run the third node using\n",
    "```shell\n",
    "{FEDBIOMED_DIR}/scripts/fedbiomed_run node config config3.ini start\n",
    "```\n",
    "so that the node doesn't offer to use GPU for training (default behaviour).\n",
    "\n",
    "6. Wait until you get `Starting task manager` for each node, it means you are online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All this part is the same as when running a model using CPU : model in unchanged**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a training plan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the training plan to be used.\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    # Defines and return model\n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "\n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "\n",
    "    # Declares and returns dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        loader_arguments = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **loader_arguments)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the experiment parameters\n",
    "\n",
    "`training_args` are used by the researcher to **request the nodes to use GPU for training, if the node has a GPU and offers to use it.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, },\n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3\n",
    "    },\n",
    "    'use_gpu': True, # Activates GPU\n",
    "    'epochs': 1,\n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and run the experiment\n",
    "\n",
    "**All this part is the same as when running a model using CPU : experiment declaration and running is unchanged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed training a `TorchTrainingPlan` using a GPU for acceleration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}