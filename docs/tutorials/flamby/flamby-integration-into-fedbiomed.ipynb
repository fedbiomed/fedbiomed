{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9424f5f5",
   "metadata": {},
   "source": [
    "# FLamby in Fed-BioMed\n",
    "\n",
    "This tutorial demonstrates how to use FLamby datasets in Fed-BioMed. You'll learn:\n",
    "- How to download FLamby datasets\n",
    "- How to deploy FLamby datasets for different centers using separate data partitioning \n",
    "- How to define datasets for FLamby examples in your federated learning experiments\n",
    "\n",
    "## Overview\n",
    "\n",
    "FLamby is a comprehensive benchmark suite for federated learning in healthcare. The datasets are not included directly in the FLamby installation due to licensing and size constraints. Each dataset must be downloaded separately using dedicated download scripts provided by the FLamby library.\n",
    "\n",
    "This notebook provides a comprehensive guide on how to:\n",
    "\n",
    "1. **Discover available FLamby datasets** - Find which datasets are available in your FLamby installation\n",
    "2. **Download datasets programmatically** - Use Python subprocess to execute download scripts\n",
    "3. **Deploy downloaded datasets** - Configure datasets for use with Fed-BioMed nodes\n",
    "4. **Verify successful downloads** - Ensure datasets are complete and properly configured\n",
    "\n",
    "For detailed information about FLamby integration concepts and training plan implementation, please visit the [FLamby dataset introduction tutorial](./index.md).\n",
    "\n",
    "This hands-on tutorial will focus specifically on deploying the **Fed Heart Disease dataset** that comes with FLamby, providing you with step-by-step instructions to successfully deploy this dataset for federated learning experiments.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "- **FLamby installed**: `pip install flamby`\n",
    "- **wget dependency**: `pip install wget` \n",
    "- **Fed-BioMed installed**: Make sure your Fed-BioMed environment is properly configured\n",
    "- **Sufficient disk space**: FLamby datasets can be several GB in size\n",
    "- **Internet connection**: Required for downloading datasets from external sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635560d",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "In this section, we'll import the necessary libraries and explore the available FLamby datasets. This step helps us understand what datasets are available in your FLamby installation before proceeding with downloads.\n",
    "\n",
    "The code below will:\n",
    "- Import essential Python libraries for file handling and dataset discovery\n",
    "- Load the FLamby datasets module \n",
    "- Display a list of all available FLamby datasets in your installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1070d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkgutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89325ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fed_camelyon16',\n",
       " 'fed_dummy_dataset',\n",
       " 'fed_heart_disease',\n",
       " 'fed_isic2019',\n",
       " 'fed_ixi',\n",
       " 'fed_kits19',\n",
       " 'fed_lidc_idri',\n",
       " 'fed_synthetic',\n",
       " 'fed_tcga_brca',\n",
       " 'split_utils']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from flamby import datasets\n",
    "\n",
    "# List of available FLamby datasets\n",
    "list(i.name for i in pkgutil.iter_modules(datasets.__path__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09cf1ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e0c89ef",
   "metadata": {},
   "source": [
    "Datasets have to downloaded using `download.py` script provided in the Flamby library/module. Therrefore, we have to find the correct download script for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93aea439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n",
      "See https://archive-beta.ics.uci.edu/ml/datasets/heart+disease.\n",
      "\n",
      "Creators of the dataset:\n",
      "  1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n",
      "  2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n",
      "  3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n",
      "  4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\n",
      "\n",
      "To cite this dataset, cite the following: Janosi, Andras, Steinbrunn, William, Pfisterer, Matthias, Detrano, Robert & M.D., M.D.. (1988). Heart Disease. UCI Machine Learning Repository.\n",
      "\n",
      "You have already downloaded the heart disease dataset, aborting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import flamby.datasets.fed_heart_disease\n",
    "dataset_root = Path(flamby.datasets.fed_heart_disease.__file__).parent\n",
    "download_script = dataset_root / \"dataset_creation_scripts\" / \"download.py\"\n",
    "!python {download_script} --output-folder ./data/fed_heart_disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec9c5f",
   "metadata": {},
   "source": [
    "## Deploying Datasets \n",
    "\n",
    "After the datasets are downloaded, they can be deployed on Fed-BioMed nodes. To deploy datasets, Fed-BioMed [`CustomDataset`](../../user-guide/datasets/custom-dataset.md) type will be used. \n",
    "\n",
    "Please execute the following commands to create Fed-BioMed node components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb705809",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc89b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!fedbiomed component create -c node --path ./node-1 -n my-first-node\n",
    "!fedbiomed component create -c node --path ./node-2 -n my-second-node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b393a",
   "metadata": {},
   "source": [
    "After the nodes are create, FLamby dataset can be deployed. To do that, a JSON file has tobe created that contains where data located and which center/partition is going to be be used for that dataset. \n",
    "\n",
    "Please keep in mind that this is scnaiors for testing, since FLamby datasets are downloaded once and repartioned after dataset definiiition should be passed through JSON file to be able to deploy two different nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5967b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "# Get the absolute path to the downloaded FLamby dataset\n",
    "abs_path = os.path.abspath(\"./data/fed_heart_disease\")\n",
    "\n",
    "# Create dataset configuration for Node 1 (using center/partition 1)\n",
    "dataset_description = {\"center\": 1, \"dataset-path\": abs_path}\n",
    "\n",
    "# Create dataset configuration for Node 2 (using center/partition 2) \n",
    "dataset_description_2 = {\"center\": 2, \"dataset-path\": abs_path}\n",
    "\n",
    "# Save dataset configuration for Node 1\n",
    "node_data_path = os.path.abspath(\"./node-1/data/dataset_description.json\")\n",
    "with open(node_data_path, 'w') as f:\n",
    "    json.dump(dataset_description, f)\n",
    "\n",
    "# Save dataset configuration for Node 2\n",
    "node_data_path_2 = os.path.abspath(\"./node-2/data/dataset_description.json\")\n",
    "with open(node_data_path_2, 'w') as f:\n",
    "    json.dump(dataset_description_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d53189",
   "metadata": {},
   "source": [
    "The JSON files defined above are used in the `TrainingPlan` to load the correct partition for each node. The datasets still need to be deployed on the nodes. There are two options: (1) use the interactive CLI to define the dataset name, tags, and data path one by one; or (2) use a JSON file that contains the dataset metadata (tags, name, path). To keep this tutorial simple, we will use the JSON file method to add datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d73e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_node_1 = {\"name\": \"fed_heart_disease_node_1\",\n",
    "                      \"data_type\": \"custom\",\n",
    "                      \"tags\": \"flamby,fed_heart_disease\",\n",
    "                      \"description\": \"Heart disease dataset for federated learning\",\n",
    "                      \"path\": node_data_path}\n",
    "\n",
    "dataset_for_node_2 = {\"name\": \"fed_heart_disease_node_2\",\n",
    "                      \"data_type\": \"custom\",\n",
    "                      \"tags\": \"flamby,fed_heart_disease\",\n",
    "                      \"description\": \"Heart disease dataset for federated learning\",\n",
    "                      \"path\": node_data_path_2}\n",
    "\n",
    "with open('./node_1_dataset_metadata.json', 'w') as f:\n",
    "    json.dump(dataset_for_node_1, f)\n",
    "\n",
    "with open('./node_2_dataset_metadata.json', 'w') as f:\n",
    "    json.dump(dataset_for_node_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7188017",
   "metadata": {},
   "source": [
    "After dataset metadata/descriptor JSON files are saved, the dataset can be deployed on the node using the command below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975f4adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# \u001b[1;32mUsing component located at:\u001b[0m \u001b[1m./node-1\u001b[0m #\n",
      "Dataset description file provided: adding these data\n",
      "2025-11-04 16:32:56,735 fedbiomed INFO - Dataset absolute path: /Users/scz/dev/fedbiomed/docs/tutorials/flamby/node-1/data/dataset_description.json\n",
      "\n",
      "Great! Take a look at your data:\n",
      "name                      data_type    tags                             description                                   path                                                                                 dataset_id                                    dataset_parameters\n",
      "------------------------  -----------  -------------------------------  --------------------------------------------  -----------------------------------------------------------------------------------  --------------------------------------------  --------------------\n",
      "fed_heart_disease_node_1  custom       ['flamby', 'fed_heart_disease']  Heart disease dataset for federated learning  /Users/scz/dev/fedbiomed/docs/tutorials/flamby/node-1/data/dataset_description.json  dataset_b64dc024-6f49-4c36-88fe-17ed50e57970  {}\n",
      "\n",
      "# \u001b[1;32mUsing component located at:\u001b[0m \u001b[1m./node-2\u001b[0m #\n",
      "Dataset description file provided: adding these data\n",
      "2025-11-04 16:32:59,192 fedbiomed INFO - Dataset absolute path: /Users/scz/dev/fedbiomed/docs/tutorials/flamby/node-2/data/dataset_description.json\n",
      "\n",
      "Great! Take a look at your data:\n",
      "name                      data_type    tags                             description                                   path                                                                                 dataset_id                                    dataset_parameters\n",
      "------------------------  -----------  -------------------------------  --------------------------------------------  -----------------------------------------------------------------------------------  --------------------------------------------  --------------------\n",
      "fed_heart_disease_node_2  custom       ['flamby', 'fed_heart_disease']  Heart disease dataset for federated learning  /Users/scz/dev/fedbiomed/docs/tutorials/flamby/node-2/data/dataset_description.json  dataset_964f4fbb-3006-40df-9cd9-40a4f99f8dd9  {}\n"
     ]
    }
   ],
   "source": [
    "!fedbiomed node -p ./node-1 dataset add --file ./node_1_dataset_metadata.json\n",
    "!fedbiomed node -p ./node-2 dataset add --file ./node_2_dataset_metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35308cda",
   "metadata": {},
   "source": [
    "## Writing the TrainingPlan\n",
    "\n",
    "Let's demonstrate downloading the popular Fed Heart Disease dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.dataset import CustomDataset\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from flamby.datasets.fed_heart_disease import (\n",
    "    FedHeartDisease, \n",
    "    Baseline, \n",
    "    BaselineLoss, \n",
    "    Optimizer\n",
    ")\n",
    "from fedbiomed.common.data import DataManager\n",
    "\n",
    "class FedHeartTrainingPlan(TorchTrainingPlan):\n",
    "    def init_model(self, model_args):\n",
    "        return Baseline()\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return Optimizer(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\"from flamby.datasets.fed_heart_disease import FedHeartDisease, Baseline, BaselineLoss, Optimizer\",\n",
    "                \"from fedbiomed.common.datamanager import DataManager\", \n",
    "                \"from fedbiomed.common.dataset import CustomDataset\"\n",
    "                ]\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        return BaselineLoss().forward(output, target)\n",
    "\n",
    "    class MyFedHeartDataset(CustomDataset):\n",
    "\n",
    "        def read(self):\n",
    "            \"\"\"Read FLamby data\"\"\"            \n",
    "            \n",
    "            # Read json file that is deployed on the node\n",
    "            import json\n",
    "            with open(self.path) as f:\n",
    "                flamby_data = json.load(f)\n",
    "\n",
    "            # Create data file\n",
    "            self.data = FedHeartDisease(\n",
    "                center=flamby_data[\"center\"], \n",
    "                data_path=flamby_data[\"dataset-path\"]\n",
    "            )\n",
    "\n",
    "        def get_item(self, item):\n",
    "            \"\"\"Get item\"\"\"\n",
    "            return self.data[item]\n",
    "        \n",
    "        def __len__(self):\n",
    "            \"\"\"Dataset length\"\"\"\n",
    "            return len(self.data)\n",
    "\n",
    "    def training_data(self, batch_size=2):\n",
    "        dataset = self.MyFedHeartDataset()\n",
    "        train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09d990",
   "metadata": {},
   "source": [
    "After defining the training plan, set `model_args` and `training_args`. This tutorial uses the simple FLamby baseline model, so no additional model-specific arguments are required (you can leave `model_args` empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35281215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 16, },\n",
    "    'optimizer_args': {\n",
    "        'lr': 0.001,\n",
    "    },\n",
    "    'epochs': 2,\n",
    "    'dry_run': False,\n",
    "    'log_interval': 2,\n",
    "    'test_ratio' : 0.2,\n",
    "    'test_batch_size': 16,\n",
    "    'test_on_global_updates': True,\n",
    "    'test_on_local_updates': True,\n",
    "    'batch_maxnum': 10 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7df4126",
   "metadata": {},
   "source": [
    "### Define the Experiment\n",
    "\n",
    "The `Experiment` ties nodes, datasets, the training plan and aggregation into a single federated run.\n",
    "\n",
    "Key fields:\n",
    "- `tags` — dataset tags used to select participating nodes.\n",
    "- `training_plan_class` — training plan implementing model, loss and optimizer.\n",
    "- `model_args` — params passed to the training plan for model init.\n",
    "- `training_args` — data loader, optimizer, epoch and runtime options.\n",
    "- `aggregator` — server-side aggregation strategy (e.g. `FedAverage()`).\n",
    "- `round_limit` — number of federated rounds to execute.\n",
    "\n",
    "Please make sure that two nodes that has the datasets deployed are up and running before running your experiment. \n",
    "\n",
    "```shell\n",
    "fedbiomed node -p ./node-1 start\n",
    "fedbiomed node -p ./node-2 start\n",
    "```\n",
    "\n",
    "Note: ensure deployed datasets use matching tags and correct descriptor JSONs. For fast development, lower `round_limit`, enable `dry_run`, or set `batch_maxnum`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f105cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['flamby', 'fed_heart_disease']\n",
    "num_rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=FedHeartTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bd331",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "- Ensure the FLamby dataset is downloaded to the location referenced by the dataset descriptor JSON files (the path in `\"dataset-path\"`). An empty or missing data folder will cause data-loading errors (for example IndexError).\n",
    "- Verify each node's `dataset_description.json` exists and contains the required fields: at minimum `\"dataset-path\"` (absolute or relative path to the downloaded FLamby data) and `\"center\"` (the partition/center number).\n",
    "- If you get errors when adding a dataset with the `fedbiomed` CLI using the `--file` option, validate the JSON for correct syntax, field names, and valid paths. If the issue persists, add the dataset interactively instead:\n",
    "    `fedbiomed node -p <path-to-node> dataset add`\n",
    "    and follow the prompts to provide the dataset name, tags, and path."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
