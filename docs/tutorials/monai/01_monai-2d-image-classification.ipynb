{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated 2d image classification with MONAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed the 2d image classification example provided in the project MONAI (https://monai.io/):\n",
    "\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/2d_classification/mednist_tutorial.ipynb\n",
    "\n",
    "Being MONAI based on PyTorch, the deployment within Fed-BioMed follows seamlessly the same general structure of general PyTorch training plans.\n",
    "\n",
    "Following the MONAI example, this tutorial is based on the MedNIST dataset.\n",
    "\n",
    "## Creating MedNIST nodes\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "To proceed with the tutorial, we created an iid partitioning of the MedNIST dataset between 3 clients. Each client has 3000 image samples for each class. The training partitions are availables at the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1vLIcBdtdAhh6K-vrgCFy_0Y55dxOWZwf/view\n",
    "\n",
    "The dataset owned by each client has structure:\n",
    "\n",
    "\n",
    "└── client_*/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "    \n",
    "    └── BreastMRI/\n",
    "    \n",
    "    └── CXR/\n",
    "    \n",
    "    └── ChestCT/\n",
    "    \n",
    "    └── Hand/\n",
    "    \n",
    "    └── HeadCT/   \n",
    "\n",
    "To create the federated dataset, we follow the standard procedure for node creation/population of Fed-BioMed. \n",
    "\n",
    "we create a first node by using the commands\n",
    "\n",
    "`source {FEDBIOMED_DIR}/scripts/fedbiomed_environment node`\n",
    "\n",
    "`{FEDBIOMED_DIR}/scripts/fedbiomed_run node start`\n",
    "\n",
    "We then poulate the node with the data of first client:\n",
    "\n",
    "`{FEDBIOMED_DIR}/scripts/fedbiomed_run node dataset add`\n",
    "\n",
    "We select option 3 (images) to add MedNIST partition of client 1, by just picking the folder of client 1. \n",
    "Assign tag `#MEDNIST, #dataset` to the data when asked.\n",
    "\n",
    "We can further check that the data has been added by executing `{FEDBIOMED_DIR}/scripts/fedbiomed_run node dataset list`\n",
    "\n",
    "Following the same procedure, we create the other two nodes with the datasets of client 2 and client 3 respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Fed-BioMed Researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start the researcher environment with the command `source {FEDBIOMED_DIR}/scripts/fedbiomed_environment researcher`, and open the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first quesry the network for the mednist dataset. In this case, the nodes are sharing the respective partitions unsing the same tag `mednist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "from fedbiomed.researcher.config import config\n",
	"req = Requests(config)\n",
    "req.list(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for network and data loader of the MONAI tutorial can now be deployed in Fed-BioMed.\n",
    "We first import the necessary modules from `fedbiomed` and `monai` libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the training plan. Note that we can simply use the standard `TorchTrainingPlan` natively provided in Fed-BioMed. We reuse the `MedNISTDataset` data loader defined in the original MONAI tutorial, which is returned by the method `training_data`, which also implements the data parsing from the nodes `dataset_path`. Following the MONAI tutorial, the model is the `DenseNet121`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\n",
    "\n",
    "# Here we define the training plan to be used. \n",
    "# You can use any class name (here 'MyTrainingPlan')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    # Declare dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"import numpy as np\",\n",
    "                \"import os\",\n",
    "                \"from monai.apps import download_and_extract\",\n",
    "                \"from monai.config import print_config\",\n",
    "                \"from monai.data import decollate_batch\",\n",
    "                \"from monai.metrics import ROCAUCMetric\",\n",
    "                \"from monai.networks.nets import DenseNet121\",\n",
    "                \"from monai.transforms import ( Activations, AddChannel, AsDiscrete, Compose, LoadImage, RandFlip, RandRotate, RandZoom, ScaleIntensity, EnsureType, )\",\n",
    "                \"from monai.utils import set_determinism\"]\n",
    "        \n",
    "        return deps\n",
    "    \n",
    "    # Define and return model\n",
    "    def init_model(self):\n",
    "\n",
    "        model = DenseNet121(spatial_dims=2, in_channels=1,\n",
    "                    out_channels = self.model_args()[\"num_class\"])\n",
    "        \n",
    "        return model \n",
    "        \n",
    "    class MedNISTDataset(torch.utils.data.Dataset):\n",
    "            def __init__(self, image_files, labels, transforms):\n",
    "                self.image_files = image_files\n",
    "                self.labels = labels\n",
    "                self.transforms = transforms\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_files)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return self.transforms(self.image_files[index]), self.labels[index]\n",
    "    \n",
    "    def parse_data(self, path):\n",
    "        \n",
    "        class_names = sorted(x for x in os.listdir(path)\n",
    "                     if os.path.isdir(os.path.join(path, x)))\n",
    "        num_class = len(class_names)\n",
    "        image_files = [\n",
    "                        [\n",
    "                            os.path.join(path, class_names[i], x)\n",
    "                            for x in os.listdir(os.path.join(path, class_names[i]))\n",
    "                        ]\n",
    "                        for i in range(num_class)\n",
    "                      ]\n",
    "        \n",
    "        return image_files, num_class\n",
    "    \n",
    "    def training_data(self):\n",
    "        self.image_files, num_class = self.parse_data(self.dataset_path)\n",
    "        \n",
    "        if self.model_args()[\"num_class\"] != num_class:\n",
    "                raise Exception('number of available classes does not match declared classes')\n",
    "        \n",
    "        num_each = [len(self.image_files[i]) for i in range(self.model_args()[\"num_class\"])]\n",
    "        image_files_list = []\n",
    "        image_class = []\n",
    "        \n",
    "        for i in range(self.model_args()[\"num_class\"]):\n",
    "            image_files_list.extend(self.image_files[i])\n",
    "            image_class.extend([i] * num_each[i])\n",
    "        num_total = len(image_class)\n",
    "        \n",
    "        \n",
    "        length = len(image_files_list)\n",
    "        indices = np.arange(length)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        val_split = int(1. * length) \n",
    "        train_indices = indices[:val_split]\n",
    "\n",
    "        train_x = [image_files_list[i] for i in train_indices]\n",
    "        train_y = [image_class[i] for i in train_indices]\n",
    "\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImage(image_only=True),\n",
    "                AddChannel(),\n",
    "                ScaleIntensity(),\n",
    "                RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "                RandFlip(spatial_axis=0, prob=0.5),\n",
    "                RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "                EnsureType(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_transforms = Compose(\n",
    "            [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "        y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "        y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])\n",
    "                \n",
    "        train_ds = self.MedNISTDataset(train_x, train_y, train_transforms)\n",
    "        \n",
    "        return DataManager(dataset=train_ds,  shuffle=True)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.cross_entropy(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set the model and training parameters. Note that we use only 1 epoch for this experiment, and perform the training on ~26% of the locally available training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'num_class': 6,  \n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 20, }, \n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-5\n",
    "    }, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum':250 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment can be now defined, by providing the `mednist` tag, and running the local training on nodes with training plan defined in `training_plan_path`, standard `aggregator` (FedAvg) and `client_selection_strategy` (all nodes used). Federated learning is going to be perfomed through 3 optimization rounds.\n",
    "\n",
    "## WARNING:\n",
    "\n",
    "**For running this experiment, you need a computer with the following specifications:**\n",
    "\n",
    "- more than 16 GB of RAM\n",
    "- 2.5 GHz processor or higher, with at least 4 cores\n",
    "\n",
    "\n",
    "\n",
    "If your computer specification are lower, you can reduce the number of data passed when training model (set `batchnum` from 250 to 25) and the number of `rounds` (from 3 to 1) but model performances may decrease dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the federated model is obtained, it is possible to test it locally on an independent testing partition.\n",
    "The test dataset is available at this link:\n",
    "\n",
    "https://drive.google.com/file/d/1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the testing dataset on the local temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "from fedbiomed.researcher.config import config\n",
    "\n",
    "tmp_dir = tempfile.TemporaryDirectory(dir=config.vars['TMP_DIR']+os.sep)\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=1YbwA0WitMoucoIa_Qao7IC1haPfDp-XD\"\n",
    "base_dir = tmp_dir.name\n",
    "test_file = os.path.join(base_dir, \"MedNIST_testing.zip\")\n",
    "\n",
    "gdown.download(resource, test_file, quiet=False)\n",
    "\n",
    "zf = zipfile.ZipFile(test_file)\n",
    "\n",
    "for file in zf.infolist():\n",
    "    zf.extract(file, base_dir)\n",
    "    \n",
    "data_dir = os.path.join(base_dir, \"MedNIST_testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data and create the testing data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir)\n",
    "                     if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "test_split = int(0.1 * length)\n",
    "test_indices = indices[:test_split]\n",
    "\n",
    "test_x = [image_files_list[i] for i in test_indices]\n",
    "test_y = [image_class[i] for i in test_indices]\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [LoadImage(image_only=True), AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "y_pred_trans = Compose([EnsureType(), Activations(softmax=True)])\n",
    "y_trans = Compose([EnsureType(), AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define testing metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the federated model we need to create a model instance and assign to it the model parameters estimated at the last federated optimization round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exp.training_plan().model()\n",
    "model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the testing performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0],\n",
    "            test_data[1],\n",
    "        )\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spite of the relatively small training performed on the data shared in the 3 nodes, the performance of the federated model seems pretty good. Well done! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
