{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e87007",
   "metadata": {},
   "source": [
    "# Fed-BioMed to train a federated SGD regressor model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0bc07",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "\n",
    "This tutorial shows how to deploy in Fed-BioMed to solve a federated regression problem with scikit-learn.\n",
    "\n",
    "In this tutorial we are using the wrapper of Fed-BioMed for the [SGD regressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html).\n",
    "The goal of the notebook is to train a model on a realistic dataset of (synthetic) medical information mimicking the [ADNI dataset](http://adni.loni.usc.edu/). \n",
    "\n",
    "## Creating nodes\n",
    "\n",
    "To proceed with the tutorial, we create 3 clients with corresponding dataframes of clinical information in .csv format. Each client has 300 data points composed by several features corresponding to clinical and medical imaging information. **The data is entirely synthetic and randomly sampled to mimick the variability of the real ADNI dataset**. The training partitions are available at the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1R39Ir60oQi8ZnmHoPz5CoGCrVIglcO9l/view?usp=sharing\n",
    "\n",
    "The federated task we aim at solve is to predict a clinical variable (the mini-mental state examination, MMSE) from a combination of demographic and imaging features. The regressors variables are the following features:\n",
    "\n",
    "```python\n",
    "['SEX', 'AGE', 'PTEDUCAT', 'WholeBrain.bl', 'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "```\n",
    "\n",
    "and the target variable is:\n",
    "```python\n",
    "['MMSE.bl']\n",
    "```    \n",
    "\n",
    "To create the federated dataset, we follow the standard procedure for node creation/population of Fed-BioMed. \n",
    "\n",
    "we create a first node by using the commands\n",
    "\n",
    "```shell\n",
    "$ fedbiomed node -p my-node start\n",
    "```\n",
    "\n",
    "We then populate the node with the data of first client:\n",
    "\n",
    "```shell\n",
    "$ fedbiomed node -d my-node dataset add`\n",
    "``` \n",
    "We select option 1 (csv) to add the .csv partition of client 1, by just picking the .csv of client 1. We use `adni` as tag to save the selected dataset. We can further check that the data has been added by executing `fedbiomed node -d my-node dataset list`\n",
    "\n",
    "<div class=\"note\">\n",
    "    <p>Following the same procedure, we create the other two nodes with the datasets of client 2 and client 3 respectively.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5411d74",
   "metadata": {},
   "source": [
    "## Fed-BioMed Researcher\n",
    "\n",
    "We are now ready to start the researcher environment with the following command. This command will activate researcher environment and start Jupyter Notebook.\n",
    "```shell\n",
    "$ fedbiomed researcher start\n",
    "```\n",
    "\n",
    "We can first query the network for the `adni` dataset. In this case, the nodes are sharing the respective partitions using the same tag `adni`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "from fedbiomed.researcher.config import config\n",
    "req = Requests(config)\n",
    "req.list(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924bf21",
   "metadata": {},
   "source": [
    "## Create an experiment to train a model on the data found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9aaa87",
   "metadata": {},
   "source": [
    "The class `FedSGDRegressor` constitutes the Fed-BioMed wrapper for executing Federated Learning using Scikit-Learn `SGDRegressor` model based on mini-batch Stochastic Gradient Descent (SGD). As we have done with Pytorch model in previous chapter, we create a new training plan class `SGDRegressorTrainingPlan` that inherits from it. For a refresher on how Training Plans work in Fed-BioMed, please refer to our [Training Plan user guide](../../../user-guide/researcher/training-plan).\n",
    "\n",
    "In scikit-learn Training Plans, you typically need to define only the `training_data` function, and optionally an `init_dependencies` function if your code requires additional module imports. \n",
    "\n",
    "The `training_data` function defines how datasets should be loaded in nodes to make them ready for training. It takes a `batch_size` argument and returns a `DataManager` class. For scikit-learn, the `DataManager` must be instantiated with a `dataset` and a `target` argument, both `np.ndarrays` of the same length.\n",
    "\n",
    "We note that this model performs a common standardization across federated datasets by **centering with respect to the same parameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10cc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fedbiomed.common.training_plans import FedSGDRegressor\n",
    "from fedbiomed.common.data import DataManager\n",
    "\n",
    "class SGDRegressorTrainingPlan(FedSGDRegressor):\n",
    "    def training_data(self):\n",
    "        dataset = pd.read_csv(self.dataset_path,delimiter=',')\n",
    "        regressors_col = ['AGE', 'WholeBrain.bl',\n",
    "                          'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "        target_col = ['MMSE.bl']\n",
    "\n",
    "        # mean and standard deviation for normalizing dataset\n",
    "        # it has been computed over the whole dataset\n",
    "        scaling_mean = np.array([72.3, 0.7, 0.0, 0.0, 0.0, 0.0])\n",
    "        scaling_sd = np.array([7.3e+00, 5.0e-02, 1.1e-02, 1.0e-03, 2.0e-03, 1.0e-03])\n",
    "\n",
    "        X = (dataset[regressors_col].values-scaling_mean)/scaling_sd\n",
    "        y = dataset[target_col]\n",
    "        return DataManager(dataset=X, target=y.values.ravel(), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cda129",
   "metadata": {},
   "source": [
    "Provide dynamic arguments for the model and training. These may potentially be changed at every round.\n",
    "\n",
    "### Model arguments\n",
    "\n",
    "`model_args` is a dictionary with the arguments related to the model, that will be passed to the `SGDRegressor` constructor. In this case, these include `n_features`, `random_state` and `eta0`. \n",
    "\n",
    "**IMPORTANT** For regression tasks, you are **required** to specify the following field:\n",
    "- `n_features`: the number of features in each input sample (in our case, the number of pixels in the images)\n",
    "\n",
    "### Training arguments\n",
    "\n",
    "`training_args` is a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.metrics import MetricTypes\n",
    "RANDOM_SEED = 1234\n",
    "\n",
    "model_args = {\n",
    "    'eta0':0.05,\n",
    "    'n_features': 6,\n",
    "    'random_state': RANDOM_SEED\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'epochs': 1,\n",
    "    'test_ratio':.2,\n",
    "    'test_metric': MetricTypes.MEAN_SQUARE_ERROR,\n",
    "    'test_on_local_updates': True,\n",
    "    'test_on_global_updates': True,\n",
    "    'loader_args': { 'batch_size': 30, },\n",
    "#    'batch_maxnum': 2,  # can be used to debugging to limit the number of batches per epoch\n",
    "#    'log_interval': 1,  # output a logging message every log_interval batches\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2b46d",
   "metadata": {},
   "source": [
    "The experiment can be now defined, by providing the `adni` tag, and running the local training on nodes with training plan defined in `training_plan_path`, standard `aggregator` (FedAvg) and `client_selection_strategy` (all nodes used). Federated learning is going to be performed through 10 optimization rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1341",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['adni']\n",
    "\n",
    "# Add more rounds for results with better accuracy\n",
    "#\n",
    "#rounds = 40\n",
    "rounds = 10\n",
    "\n",
    "# select nodes participating in this experiment\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=SGDRegressorTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff55da",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# start federated training\n",
    "exp.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975d6d0",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2a782",
   "metadata": {},
   "source": [
    "##  Testing\n",
    "\n",
    "Once the federated model is obtained, it is possible to test it locally on an independent testing partition.\n",
    "The test dataset is available at this link:\n",
    "\n",
    "https://drive.google.com/uc?id=19kxuI146WA2fhcOU2_AvF8dy-ppJkzW7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5335f2d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d9b2",
   "metadata": {},
   "source": [
    "Download the testing dataset on the local temporary folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500a4f0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fedbiomed.researcher.config import config\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=19kxuI146WA2fhcOU2_AvF8dy-ppJkzW7\"\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory(dir=config.vars['TMP_DIR'])\n",
    "base_dir = tmpdir.name\n",
    "\n",
    "test_file = os.path.join(base_dir, \"test_data.zip\")\n",
    "gdown.download(resource, test_file, quiet=False)\n",
    "\n",
    "zf = zipfile.ZipFile(test_file)\n",
    "\n",
    "for file in zf.infolist():\n",
    "    zf.extract(file, base_dir)\n",
    "\n",
    "# loading testing dataset\n",
    "test_data = pd.read_csv(os.path.join(base_dir,'adni_validation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73be6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb078c6",
   "metadata": {},
   "source": [
    "Here we extract the relevant regressors and target from the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors_col = ['AGE', 'WholeBrain.bl', 'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "target_col = ['MMSE.bl']\n",
    "X_test = test_data[regressors_col].values\n",
    "y_test = test_data[target_col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6d380",
   "metadata": {},
   "source": [
    "To inspect the model evolution across FL rounds, we export `exp.aggregated_params()` containing models parameters collected at the end of each round. The MSE should be decreasing at each iteration with the federated parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_mean = np.array([72.3, 0.7, 0.0, 0.0, 0.0, 0.0])\n",
    "scaling_sd = np.array([7.3e+00, 5.0e-02, 1.1e-02, 1.0e-03, 2.0e-03, 1.0e-03])\n",
    "\n",
    "testing_error = []\n",
    "\n",
    "\n",
    "# we create here several instances of SGDRegressor using same sklearn arguments\n",
    "# we have used for Federated Learning training\n",
    "fed_model = exp.training_plan().model()\n",
    "regressor_args = {key: model_args[key] for key in model_args.keys() if key in fed_model.get_params().keys()}\n",
    "\n",
    "for i in range(rounds):\n",
    "    fed_model.coef_ = exp.aggregated_params()[i]['params']['coef_'].copy()\n",
    "    fed_model.intercept_ = exp.aggregated_params()[i]['params']['intercept_'].copy()\n",
    "    mse = np.mean((fed_model.predict((X_test-scaling_mean)/scaling_sd) - y_test)**2)\n",
    "    testing_error.append(mse)\n",
    "\n",
    "plt.plot(testing_error)\n",
    "plt.title('FL testing loss')\n",
    "plt.xlabel('FL round')\n",
    "plt.ylabel('testing loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60406da1",
   "metadata": {},
   "source": [
    "We finally inspect the predictions of the final federated model on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = fed_model.predict((X_test-scaling_mean)/scaling_sd)\n",
    "plt.scatter(y_predicted, y_test, label='model prediction')\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('target')\n",
    "plt.title('Federated model testing prediction')\n",
    "\n",
    "first_diag = np.arange(np.min(y_test.flatten()),\n",
    "                       np.max(y_test.flatten()+1))\n",
    "plt.scatter(first_diag, first_diag, label='correct Target')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
