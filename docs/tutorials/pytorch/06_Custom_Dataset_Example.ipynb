{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc2807d",
   "metadata": {},
   "source": [
    "# PyTorch MNIST Basic Example\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The **Goal** of this example is to show you how to train with a locally defined `CustomDataset` by embedding it in a TorchTrainingPlan, then launching a small federated run from the Researcher using Experiment. We use a single node for clarity and the Wine Quality (red) CSV as a toy dataset.\n",
    "\n",
    "Setup assumptions:\n",
    "\n",
    "- You have at least one Fed‑BioMed node running locally\n",
    "- You added a dataset entry that points to a directory holding or receiving the CSV (see the dataset add note below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c5d9a",
   "metadata": {},
   "source": [
    "### 1) Custom Dataset class\n",
    "\n",
    "`CustomDataset` lets you make any file/folder usable for training, as long as you:\n",
    "\n",
    "- Implement:\n",
    "\n",
    "    - `read(self)`: load and preprocess data once (e.g., read CSV, build arrays) and store into instance fields.\n",
    "    - `__len__(self)`: number of samples.\n",
    "    - `get_item(self, index)`: return exactly a tuple `(data, target)` for the given index.\n",
    "and\n",
    "- Do not override `__init__` or `__getitem__`. These are managed by Fed‑BioMed so it can apply format checks and safety validations.\n",
    "- `target` can be `None` in unsupervised settings. In supervised tasks (like this one), return a proper target (float, int, tensor, etc.).\n",
    "\n",
    "**Good practice:**\n",
    "\n",
    "- Prepare features as float arrays/tensors\n",
    "- Keep get_item focused and fast; heavy work belongs in read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aaec7f",
   "metadata": {},
   "source": [
    "### 2) Wine Dataset Example\n",
    "\n",
    "The example dataset downloads Wine Quality (red) from UCI if it’s not already present, parses it with csv.DictReader(delimiter=';'), then caches two arrays:\n",
    "\n",
    "- `self._X`: standardized continuous features (all columns except quality)\n",
    "- `self._y`: the quality score as the regression target\n",
    "\n",
    "`__len__` returns `len(self._y)` and `get_item(i)` returns a torch tensor pair: `(X[i], y[i])`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1479d1-6cf5-45a7-baaf-ff2136a5175e",
   "metadata": {},
   "source": [
    "### 3) Register a dataset on the node (once)\n",
    "\n",
    "Open the node dataset tool and add a Custom Dataset entry tagged wine:\n",
    "\n",
    "```$ fedbiomed node dataset add``` \n",
    "\n",
    "Choose Custom Dataset and set the folder that will hold winequality-red.csv (or where it will be downloaded). Use the tag wine (that’s what the Researcher will look for).\n",
    "\n",
    "Start the node:\n",
    "\n",
    "```$ fedbiomed node start```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69105c3c-fde9-4fd1-90e9-4e7e501fe951",
   "metadata": {},
   "source": [
    "### 4) Training plan (how the plan is wired)\n",
    "\n",
    "WineTrainingPlan inherits from TorchTrainingPlan and provides:\n",
    "\n",
    "- `init_model(model_args)`: builds a tiny MLP for regression. The input size `in_features` is passed via `model_args` (set to 11 for this dataset).\n",
    "\n",
    "- Inner `WineCSV` dataset class (defined inside the plan in your code): implements `read`, `__len__`, `get_item` and returns Tensors.\n",
    "\n",
    "- `training_data()`: constructs a `DataManager(dataset=WineCSV())`. \n",
    "\n",
    "- `training_step(data, target)`: one standard step using `MSELoss` for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.datamanager import DataManager\n",
    "from fedbiomed.common.dataset_types import DataReturnFormat\n",
    "from fedbiomed.common.dataset import CustomDataset\n",
    "\n",
    "class WineTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "        # infer input dim cheaply from one sample\n",
    "        in_dim = model_args['in_features']\n",
    "        hidden = model_args.get(\"hidden\", 64)\n",
    "        return nn.Sequential(nn.Linear(in_dim, hidden), nn.ReLU(), nn.Linear(hidden, 1))\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        lr = optimizer_args.get(\"lr\", 1e-3)\n",
    "        return torch.optim.Adam(self.model().parameters(), lr=lr)\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        deps = [\n",
    "            'from fedbiomed.common.dataset import CustomDataset',\n",
    "            'import os',\n",
    "            'import urllib.request',\n",
    "            'import csv',\n",
    "            'import numpy as np'\n",
    "        ]\n",
    "        return deps\n",
    "\n",
    "    class WineCSV(CustomDataset):\n",
    "        URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "        FNAME = \"winequality-red.csv\"\n",
    "        TARGET = \"quality\"\n",
    "\n",
    "        def read(self) -> None:\n",
    "            \n",
    "            # Fed‑BioMed provides self.path \n",
    "            os.makedirs(self.path, exist_ok=True)\n",
    "            csv_fp = os.path.join(self.path, self.FNAME)\n",
    "            if not os.path.exists(csv_fp):\n",
    "                with urllib.request.urlopen(self.URL, timeout=30) as r:\n",
    "                    data = r.read()\n",
    "                with open(csv_fp, \"wb\") as f:\n",
    "                    f.write(data)\n",
    "    \n",
    "            with open(csv_fp, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "                rows = list(csv.DictReader(f, delimiter=\";\"))\n",
    "            if not rows:\n",
    "                print(f\"Empty CSV at {csv_fp}\")\n",
    "    \n",
    "            cols = list(rows[0].keys())\n",
    "            if self.TARGET not in cols:\n",
    "                print(f\"Target '{self.TARGET}' not found\")\n",
    "    \n",
    "            feats = [c for c in cols if c != self.TARGET]\n",
    "            X = np.array([[float(r[c]) for c in feats] for r in rows], dtype=np.float32)\n",
    "            y = np.array([float(r[self.TARGET]) for r in rows], dtype=np.float32)\n",
    "    \n",
    "            # (optional) simple standardization\n",
    "            X = (X - X.mean(0, keepdims=True)) / (X.std(0, keepdims=True) + 1e-8)\n",
    "    \n",
    "            self._X, self._y = X, y\n",
    "    \n",
    "        def __len__(self) -> int:\n",
    "            return len(self._y)\n",
    "    \n",
    "        def get_item(self, index: int):\n",
    "            return torch.tensor(self._X[index]), torch.tensor(self._y[index])\n",
    "    \n",
    "    def training_data(self):\n",
    "        wine_dataset = self.WineCSV()\n",
    "        return DataManager(dataset=wine_dataset)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        predictions = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.mse_loss(predictions, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "model_args = {\n",
    "    'in_features': 11, # number of feature columns\n",
    "}\n",
    "\n",
    "# training parameters\n",
    "training_args = {\n",
    "    'loader_args': { \n",
    "        'batch_size': 64, \n",
    "        'shuffle': True \n",
    "    },\n",
    "    'optimizer_args': {\n",
    "          'lr': 1e-3\n",
    "    },\n",
    "    'epochs': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124942b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['wine']\n",
    "rounds = 5\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=WineTrainingPlan,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68853e59-f98d-431a-be57-e31a0eb02761",
   "metadata": {},
   "source": [
    "### 5) Conclusion\n",
    "\n",
    "We have successfully trained a model, using our own customized read and get_item methods. This customization allows us to both filter the data that we read and the sample we get during each training step. Try changing the read function to select specific columns and/or less data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a50cc36-cbe9-4fe6-b600-549160728ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
