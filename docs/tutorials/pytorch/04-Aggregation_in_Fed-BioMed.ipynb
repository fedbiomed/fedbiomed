{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c753a58",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch aggregation methods in Fed-BioMed\n",
    "\n",
    "**Difficulty level**: **advanced**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial focuses on how to deal with heterogeneous dataset by changing its `Aggregator`. Fed-BioMed provides different methods for Aggregation. Selecting an appropriate Aggregation method can be critical when being confronted to unbalanced or heterogeneous datasets.\n",
    "\n",
    "`Aggregators` provide a way to merge local models sent by `Nodes` into a global, more generalized model. Please note that designing `Nodes` sampling `Strategies` could also help when working on heterogeneous datasets.\n",
    "\n",
    "For more information about `Aggregators` object in Fed-BioMed, and on how to create your own `Aggregator`; please see [`Aggregators` in the User Guide](../../../user-guide/researcher/aggregation) \n",
    "\n",
    "### Before you start\n",
    "For this tutorial, we will be using heterogeneous the MedNIST dataset. MedNIST is a collection of 2-D grayscale medical images. The MedNIST dataset was gathered from several sets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license and is distributed by MONAI for teaching and benchmarking simple deep-learning pipelines. For more information regarding the dataset please see [MedNIST Dataset](../../../user-guide/datasets/mednist-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58226b70-b445-4030-afbf-c226615c1850",
   "metadata": {},
   "source": [
    "## 1. Defining an `Experiment` using `FedAverage` `Aggregator`\n",
    "\n",
    "First, let's reuse the `TorchTrainingPlan` that is defined in the [previous MedNIST tutorial](../04_Transfer-learning_tutorial_usingDenseNet-121.ipynb). FedAveraging has been introduced by McMahan et al. as the first aggregation method in the Federated Learning literature. It does the weighted sum of all `Nodes` local models parameters in order to obtain a global model:\n",
    "\n",
    "In this tutorial, we will keep the same `TrainingPlan` (and thus the same model) for all the `Experiments`, we will only be changing the `Aggregators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c872dd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.datamanager import DataManager\n",
    "from fedbiomed.common.dataset import MedNistDataset\n",
    "\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "        model = models.densenet121(weights=None)  # here model coefficients are set to random weights\n",
    "\n",
    "        # add the classifier \n",
    "        num_classes = model_args['num_classes'] \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier= nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )      \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import transforms, models\",\n",
    "            \"import torch.optim as optim\",\n",
    "            \"from torchvision.models import densenet121\",\n",
    "            \"from fedbiomed.common.dataset import MedNistDataset\"\n",
    "        ]\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def training_data(self):\n",
    "\n",
    "        # Transform images and do data augmentation \n",
    "        preprocess = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "        target_transform = transforms.Lambda(lambda y: y.long())\n",
    "    \n",
    "        train_data = MedNistDataset(transform = preprocess, target_transform=target_transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd8684",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define hereafter parameters for `Experiment` to be used with vanilla `FedAverage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6df1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': {\n",
    "        'batch_size': 32,\n",
    "    }, \n",
    "    'random_seed': 1234,\n",
    "    'optimizer_args': {'lr': 1e-3}, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'num_updates': 50, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6, # adapt this number to the number of classes in your dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340ba9a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We then import `FedAverage` `Aggregator` from Fed-BioMed's `Aggregators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287b3d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators import FedAverage\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 3\n",
    "\n",
    "exp_fed_avg = Experiment()\n",
    "exp_fed_avg.set_model_args(model_args=model_args)\n",
    "exp_fed_avg.set_training_args(training_args=training_args)\n",
    "exp_fed_avg.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_fed_avg.set_tags(tags = tags)\n",
    "exp_fed_avg.set_training_data(training_data=None, from_tags=True)\n",
    "exp_fed_avg.set_aggregator(aggregator=FedAverage())\n",
    "exp_fed_avg.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_fed_avg.set_round_limit(rounds)\n",
    "exp_fed_avg.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa8f02",
   "metadata": {},
   "source": [
    "Activate Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de222a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fe786",
   "metadata": {},
   "outputs": [],
   "source": [
    "fedavg_tensorboard_dir = exp_fed_avg.tensorboard_results_path\n",
    "\n",
    "%tensorboard --logdir {fedavg_tensorboard_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7a682",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_fed_avg.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4f89d",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0849f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fed_avg.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f587bda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Defining an `Experiment` using `FedProx` `Aggregator`\n",
    "\n",
    "\n",
    "In order to improve our results, we can change our `Aggregator`, by changing `FedAverage` into `FedProx`. \n",
    "Since `FedProx` is a `FedAverge` aggregator with a regularization term, we are reusing `FedAverage` `Aggregator` but we will be adding to the `training_args` `fedprox_mu`, that is the regularization parameter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10780ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args_fedprox = {\n",
    "    'loader_args': {\n",
    "        'batch_size': 32,\n",
    "    }, \n",
    "    'random_seed': 1234,\n",
    "    'optimizer_args': {'lr': 1e-3}, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'num_updates': 50,\n",
    "    'fedprox_mu': .1,  # This parameter indicates that we are going to use FedProx\n",
    "    \n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6, # adapt this number to the number of classes in your dataset\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d3573",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators import FedAverage\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 3\n",
    "\n",
    "exp_fedprox = Experiment()\n",
    "\n",
    "\n",
    "exp_fedprox.set_model_args(model_args=model_args)\n",
    "exp_fedprox.set_training_args(training_args=training_args_fedprox)\n",
    "exp_fedprox.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_fedprox.set_tags(tags = tags)\n",
    "exp_fedprox.set_training_data(training_data=None, from_tags=True)\n",
    "exp_fedprox.set_aggregator(aggregator=FedAverage())\n",
    "exp_fedprox.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_fedprox.set_round_limit(rounds)\n",
    "exp_fedprox.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8764aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fedprox_tensorboard_dir = exp_fedprox.tensorboard_results_path\n",
    "\n",
    "%tensorboard --logdir {fedavg_tensorboard_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abc04a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_fedprox.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff24c33",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fedprox.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bdb8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Defining an `Experiment` using `SCAFFOLD` `Aggregator`\n",
    "\n",
    "\n",
    "The `Scaffold` aggregator's purpose is to limit the so called *client drift* that may happen when dealing with heterogeneous datasset across `Nodes`. \n",
    "\n",
    "In order to use `Scaffold`, we will have to import another `Aggregator` from `fedbiomed.researcher.aggregators` module, as you can see below.\n",
    "\n",
    "`Scaffold` takes `server_lr` and `fds` the as arguments:\n",
    " - `server_lr` is the Server Learning Rate (it is used to perform a gradient descent on global model's updates on `Scaffold` aggregation)\n",
    " - `fds` is the `Federated Dataset` containing information about the `Nodes` connected to the network after issuing a `TrainRequest`\n",
    "\n",
    "*Please note that it is possible to use `Scaffold` with a regularization parameter as suggested in `FedProx`. For that, you just have to specify `fedprox_mu` into the `training_args` dictionary, as shown in the `FedProx` example*\n",
    "\n",
    "**Attention**: this version of `Scaffold` exchanges correction terms that are not protected, even when using [Secure Aggregation](../../../user-guide/secagg/introduction). Please do not use this version of `Scaffold` under heavy security constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33bb89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.aggregators import Scaffold\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "server_lr = .8\n",
    "exp_scaffold = Experiment()\n",
    "\n",
    "exp_scaffold.set_model_args(model_args=model_args)\n",
    "exp_scaffold.set_training_args(training_args=training_args)\n",
    "exp_scaffold.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_scaffold.set_tags(tags = tags)\n",
    "exp_scaffold.set_training_data(training_data=None, from_tags=True)\n",
    "exp_scaffold.set_aggregator(Scaffold(server_lr=server_lr))\n",
    "exp_scaffold.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_scaffold.set_round_limit(rounds)\n",
    "exp_scaffold.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6887568",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d68bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_tensorboard_dir = exp_scaffold.tensorboard_results_path\n",
    "\n",
    "%tensorboard --logdir {fedavg_tensorboard_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da799e9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_scaffold.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9eb9a",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scaffold.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382a844",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Going further\n",
    "\n",
    "In this tutorial we presented 3 important `Aggregators` that can be found in the Federated Learning Literature. If you want to create your custom `Aggregator`, please check our [Aggregation User guide](../../../user-guide/researcher/aggregation)\n",
    "\n",
    "\n",
    "You may have noticed that thanks to Fed-BioMed's modular structure, it is possible to alternate from one aggregator to another while conducting an `Experiment`. For instance, you may start with the `SCAFFOLD` `Aggregator` for the 3 first rounds, and then switch to `FedAverage` `Aggregator` for the remaining rounds, as shown in the example below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e80fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.aggregators import Scaffold, FedAverage\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "server_lr = .8\n",
    "exp_multi_agg = Experiment()\n",
    "\n",
    "# selecting how many rounds of each aggregator we will perform\n",
    "rounds_scaffold = 3\n",
    "rounds_fedavg = 1\n",
    "\n",
    "exp_multi_agg.set_model_args(model_args=model_args)\n",
    "exp_multi_agg.set_training_args(training_args=training_args)\n",
    "exp_multi_agg.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_multi_agg.set_tags(tags = tags)\n",
    "exp_multi_agg.set_training_data(training_data=None, from_tags=True)\n",
    "exp_multi_agg.set_aggregator(Scaffold(server_lr=server_lr))\n",
    "exp_multi_agg.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_multi_agg.set_round_limit(rounds_scaffold + rounds_fedavg)\n",
    "\n",
    "exp_multi_agg.run(rounds=rounds_scaffold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effabcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_multi_agg.set_aggregator(FedAverage())\n",
    "exp_multi_agg.run(rounds=rounds_fedavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054b0af",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_multi_agg.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086fb124",
   "metadata": {},
   "source": [
    "For more advanced Aggregators and Regularizers, like `FedOpt`, you may be interested by [`DecLearn` optimizers](../../optimizers/01-fedopt-and-scaffold) that are compatible with Fed-BioMed and provide more options for Aggregation and Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10956881",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
