{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c753a58",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch aggregation methods in Fed-BioMed\n",
    "\n",
    "**Difficulty level**: **advanced**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial focuses on how to deal with heterogeneous dataset by changing its `Aggegator`. Fed-BioMed provides different methods for Aggregation. Selecting an appropriate Aggregation method can be critical when being confronted to unbalanced /heterogeneous datasets.\n",
    "\n",
    "`Aggregators` provides a way to merge local models sent by `Nodes` into a global, more generalized model. Please note that designing `Nodes` sampling `Strategies` could also help when working on heterogeneous datasets.\n",
    "\n",
    "For more information about `Aggregators` object in Fed-BioMed, and on how to create your own `Aggregator`; please see [`Aggregators` in the User Guide](../../../user-guide/researcher/aggregation)\n",
    "\n",
    "### Before you start\n",
    "For this tutorial, we will be using heterogenous [Fed-IXI dataset](https://brain-development.org/ixi-dataset/), provided by [FLamby](https://github.com/owkin/FLamby). FLamby comes with a few medical datasets that have heterogenous data properties. Please have a look at the notebooks on [how to use FLamby in Fed-BioMed tutorials](../../flamby/flamby/) before starting - you will indeed need to set up FLamby before running this tutorial.\n",
    "\n",
    "## 1. Defining an `Experiment` using `FedAverage` `Aggregator`\n",
    "\n",
    "First, let's re-use the `TorchTrainingPlan` that is defined in the [FLamby tutorials](../../flamby/flamby-integration-into-fedbiomed). FedAveraging has been introduced by McMahan et al. as the first aggregation method in the Federated Learning literature. It does the weighted sum of all `Nodes` local models parameters in order to obtain a global model:\n",
    "\n",
    "In this tutorial, we will keep the same `TrainingPlan` (and thus the same model) for all the `Experimentations`, we will be changing only `Aggregators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c872dd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from flamby.datasets.fed_ixi import Baseline, BaselineLoss, Optimizer\n",
    "from fedbiomed.common.data import FlambyDataset, DataManager\n",
    "       \n",
    "\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    def init_model(self, model_args):\n",
    "        return Baseline()\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return Optimizer(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\"from flamby.datasets.fed_ixi import Baseline, BaselineLoss, Optimizer\",\n",
    "                \"from fedbiomed.common.data import FlambyDataset, DataManager\"]\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        return BaselineLoss().forward(output, target)\n",
    "\n",
    "    def training_data(self):\n",
    "        dataset = FlambyDataset()\n",
    "        loader_arguments = { 'shuffle': True}\n",
    "        return DataManager(dataset, **loader_arguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd8684",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define hereafter parameters for `Experiment` to be used with vanilla `FedAverage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6df1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'random_seed': 1234,\n",
    "    'loader_args': { 'batch_size': 8, },\n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'dry_run': False,\n",
    "    'num_updates': 50\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b444c5a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Activate Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba8d4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca107fbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.config import config\n",
    "import os\n",
    "\n",
    "\n",
    "fedavg_tensorboard_dir = os.path.join(config.root, 'fedavg_runs')\n",
    "os.makedirs(fedavg_tensorboard_dir, exist_ok=True)\n",
    "config.vars['TENSORBOARD_RESULTS_DIR'] = fedavg_tensorboard_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ed1d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir \"$fedavg_tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340ba9a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We then import `FedAverage` `Aggregator` from Fed-BioMed's `Aggregators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287b3d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators import FedAverage\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "tags =  ['flixi']\n",
    "\n",
    "rounds = 3\n",
    "\n",
    "\n",
    "exp_fed_avg = Experiment()\n",
    "exp_fed_avg.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_fed_avg.set_model_args(model_args=model_args)\n",
    "exp_fed_avg.set_training_args(training_args=training_args)\n",
    "exp_fed_avg.set_tags(tags = tags)\n",
    "exp_fed_avg.set_training_data(training_data=None, from_tags=True)\n",
    "exp_fed_avg.set_aggregator(aggregator=FedAverage())\n",
    "exp_fed_avg.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_fed_avg.set_round_limit(rounds)\n",
    "exp_fed_avg.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7a682",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_fed_avg.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4f89d",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0849f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fed_avg.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f587bda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Defining an `Experiment` using `FedProx` `Aggregator`\n",
    "\n",
    "\n",
    "In order to improve our results, we can change our `Aggregator`, by changing `FedAverage` into `FedProx`. \n",
    "Since `FedProx` is a `FedAverge` aggregator with a regularization term, we are re-using `FedAverage` `Aggregator` but we will be adding to the `training_args` `fedprox_mu`, that is the regularization parameter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47fe48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's create a new folder for storing tensorbaord results for FedProx aggregator\n",
    "import os\n",
    "from fedbiomed.researcher.config import config\n",
    "\n",
    "\n",
    "fedprox_tensorboard_dir = os.path.join(config.root, 'fedprox_runs')\n",
    "os.makedirs(fedprox_tensorboard_dir, exist_ok=True)\n",
    "\n",
    "config.vars['TENSORBOARD_RESULTS_DIR'] = fedprox_tensorboard_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b604d59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0116b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir \"$fedprox_tensorboard_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10780ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args_fedprox = {\n",
    "    'random_seed': 1234,\n",
    "    'loader_args': { 'batch_size': 8, },\n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'dry_run': False,\n",
    "    'num_updates': 50, \n",
    "    'fedprox_mu': .1  # This parameter indicates that we are going to use FedProx\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d3573",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators import FedAverage\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "tags =  ['flixi']\n",
    "rounds = 3\n",
    "\n",
    "exp_fedprox = Experiment()\n",
    "\n",
    "\n",
    "exp_fedprox.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_fedprox.set_model_args(model_args=model_args)\n",
    "exp_fedprox.set_training_args(training_args=training_args_fedprox)\n",
    "exp_fedprox.set_tags(tags = tags)\n",
    "exp_fedprox.set_training_data(training_data=None, from_tags=True)\n",
    "exp_fedprox.set_aggregator(aggregator=FedAverage())\n",
    "exp_fedprox.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_fedprox.set_round_limit(rounds)\n",
    "exp_fedprox.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abc04a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_fedprox.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff24c33",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_fedprox.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bdb8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Defining an `Experiment` using `SCAFFOLD` `Aggregator`\n",
    "\n",
    "\n",
    "`Scaffold` purpose is to limit the so called *client drift* that may happen when dealing with heterogenous datasset accross `Nodes`. \n",
    "\n",
    "In order to use `Scaffold`, we will have to import another `Aggregator` from `fedbiomed.researcher.aggregators` module, as you can see below.\n",
    "\n",
    "`Scaffold` takes `server_lr` and `fds` the as arguments.\n",
    " - `server_lr` is the server learning rate (in `Scaffold`, used to perform a gradient descent on global model's updates\n",
    " - `fds` is the `Federated Dataset` containing information about `Nodes` connected to the network after issuing a `TrainRequest`\n",
    "\n",
    "*Please note that it is possible to use `Scaffold` with a regularization parameter as suggested in `FedProx`. For that, you just have to specify `fedprox_mu` into the `training_args` dictionary, as shown in the `FedProx` example*\n",
    "\n",
    "**Attention**: this version of `Scaffold` exchanges correction terms that are not protected, even when using [Secure Aggregation](../../../user-guide/secagg/introduction). Please do not use this version of `Scaffold` under heavy security  constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afaaaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# let's create a new folder for storing tensorbaord results for SCAFFOLD aggregator\n",
    "scaffold_tensorboard_dir = os.path.join(config.root, 'scaffold_runs')\n",
    "os.makedirs(scaffold_tensorboard_dir, exist_ok=True)\n",
    "\n",
    "config.vars['TENSORBOARD_RESULTS_DIR'] = scaffold_tensorboard_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d15af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632af34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir \"$scaffold_tensorboard_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33bb89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.aggregators import Scaffold\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "server_lr = .8\n",
    "exp_scaffold = Experiment()\n",
    "\n",
    "exp_scaffold.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_scaffold.set_model_args(model_args=model_args)\n",
    "exp_scaffold.set_training_args(training_args=training_args)\n",
    "exp_scaffold.set_tags(tags = tags)\n",
    "exp_scaffold.set_training_data(training_data=None, from_tags=True)\n",
    "exp_scaffold.set_aggregator(Scaffold(server_lr=server_lr))\n",
    "exp_scaffold.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_scaffold.set_round_limit(rounds)\n",
    "exp_scaffold.set_tensorboard(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da799e9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_scaffold.run(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9eb9a",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scaffold.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382a844",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Going further\n",
    "\n",
    "In this tutorial we presented 3 important `Aggregators` that can be found in the Federated Learning Literature. If you want to create your custom `Aggregator`, please check our [Aggregation User guide](../../../user-guide/researcher/aggregation)\n",
    "\n",
    "\n",
    "You may have noticed that thanks to Fed-BioMed's modular structure, it is possible to alternate from one aggregator to another while conducting an `Experiment`. For instance, you may start with `SCAFFOLD` `Aggregator` for the 3 first rounds, and then switch to `FedAverage` `Aggregator` for the remaining rounds, as shown in the example below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e80fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.aggregators import Scaffold, FedAverage\n",
    "from fedbiomed.researcher.strategies.default_strategy import DefaultStrategy\n",
    "\n",
    "server_lr = .8\n",
    "exp_multi_agg = Experiment()\n",
    "\n",
    "# selecting how many rounds of each aggregator we will perform\n",
    "rounds_scaffold = 3\n",
    "rounds_fedavg = 1\n",
    "\n",
    "\n",
    "exp_multi_agg.set_training_plan_class(training_plan_class=MyTrainingPlan)\n",
    "exp_multi_agg.set_model_args(model_args=model_args)\n",
    "exp_multi_agg.set_training_args(training_args=training_args)\n",
    "exp_multi_agg.set_tags(tags = tags)\n",
    "exp_multi_agg.set_training_data(training_data=None, from_tags=True)\n",
    "exp_multi_agg.set_aggregator(Scaffold(server_lr=server_lr))\n",
    "exp_multi_agg.set_strategy(node_selection_strategy=DefaultStrategy())\n",
    "exp_multi_agg.set_round_limit(rounds_scaffold + rounds_fedavg)\n",
    "\n",
    "#exp_multi_agg.run(rounds=rounds_scaffold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effabcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_multi_agg.set_aggregator(FedAverage())\n",
    "exp_multi_agg.run(rounds=rounds_fedavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054b0af",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_multi_agg.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086fb124",
   "metadata": {},
   "source": [
    "For more advanced Aggregators and Regularizers, like `FedOpt`, you may be interested by [`DecLearn` optimizers](../../optimizers/01-fedopt-and-scaffold) that are compatible with Fed-BioMed and provide more options for Aggregation and Optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
