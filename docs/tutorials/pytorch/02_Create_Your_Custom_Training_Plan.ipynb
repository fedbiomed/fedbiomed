{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e9cf04",
   "metadata": {},
   "source": [
    "# How to Create Your Custom PyTorch Training Plan\n",
    "\n",
    "Fed-BioMed allows you to perform model training without changing your PyTorch training plan class completely. Integrating your PyToch model to Fed-BioMed only requires to add extra attributes and methods to train your model based on a federated approach.  In this tutorial, you will learn how to write/define your `TrainingPlan` (wrapping your model) in Fed-BioMed for PyTorch framework.  \n",
    "\n",
    "**Note:** Before starting this tutorial we highly recommend you to follow the previous tutorials to understand the basics of Fed-BioMed. \n",
    "\n",
    "In this tutorial, we will be using Celaba (CelebaFaces) dataset to train the model. You can see details of the dataset [here](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). In the following sections, you will have the **instructions** for **downloading** and **configuring** Celeba dataset for Fed-BioMed framework.\n",
    "\n",
    "\n",
    "## 1. Fed-BioMed Training Plan\n",
    "\n",
    "In this section, you will learn how to write your custom training plan. \n",
    "\n",
    "### What is Training Plan?\n",
    "\n",
    "The training plan is the class where all the methods and attributes are defined to train your model on the nodes. Each training plan should inherit the base training plan class of the belonging ML framework that is provided by Fed-BioMed. For more details, you can visit documentation for [training plan](../../../user-guide/researcher/training-plan).  The following code snippet shows a basic training plan that can be defined in Fed-BioMed for PyTorch framework.\n",
    "\n",
    "``` python\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "\n",
    "\n",
    "class CustomTrainingPlan(TorchTrainingPlan):\n",
    "    def init_model(self, model_args):\n",
    "        # Define here your model\n",
    "        # ...\n",
    "        return\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        # Add here the dependencies / third party libraries to be loaded\n",
    "        #...\n",
    "        return\n",
    "    \n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        # Define here your optimizer\n",
    "        #...\n",
    "        return\n",
    "\n",
    "    def training_data(self,  batch_size = 48):\n",
    "        # Define here how data are processed before feeding it to the model\n",
    "        # ...\n",
    "        return\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        # Define here the loss function\n",
    "        # ...\n",
    "        return\n",
    "\n",
    "```\n",
    "\n",
    "### `init_model` Method of Training Plan\n",
    "\n",
    "`init_model` method of the training plan is where you initialize your neural network module as in classical PyTorch model class. The network should be defined inside the training plan class and `init_model` should instantiate this network (`Module`), and return it.\n",
    "\n",
    "\n",
    "In this tutorial, we will be training a classification model for CelebA image dataset that will be able to predict whether the given face is smiling.\n",
    "\n",
    "```python\n",
    "def init_model(self, model_args: dict = {}):\n",
    "    return self.Net(model_args)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(model_args):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        # Classifier\n",
    "        self.fc1 = nn.Linear(3168, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "```\n",
    "\n",
    "### `init_dependencies` Method\n",
    "\n",
    "Next, you should define the `init_dependencies` to declare the modules that are used in the training plan. The modules should be supported by the Fed-BioMed.\n",
    "\n",
    "```python\n",
    "def init_depedencies(self)\n",
    "    # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "    deps = [\"from torch.utils.data import Dataset, DataLoader\",\n",
    "            \"from torchvision import transforms\",\n",
    "            \"import pandas as pd\",\n",
    "            \"from PIL import Image\",\n",
    "            \"import os\",\n",
    "            \"import numpy as np\"]\n",
    "    return deps\n",
    "```\n",
    "\n",
    "### `init_optimizer` Method\n",
    "\n",
    "To optimize your model, you will need an optimizer. This is where `init_optimizer` method comes into play. \n",
    "In this method, you may change the optimizer you want to use, add a PyTorch learning rate `Scheduler` or provide your custom optimizer.\n",
    "\n",
    "`init_optimizer` takes `optimizer_args` as argument, an entry from `training_args` (more details later) which is a dictionary containing parameters that may be needed for optimizer initalization (such as learning rate, `Adagrad` weights decay, `Adam` beta parameters, ...). `init_optimizer` method should return the initialized `optimizer`, that will be used to optimize model.\n",
    "\n",
    "Defining an `optimizer` in Fed-BioMed is pretty similar to PyTorch, as shown in the example below (using PyTorch's `SGD` optimizer):\n",
    "\n",
    "```python\n",
    "\n",
    "def init_optimizer(self, optimizer_args):\n",
    "    return torch.optim.SGD(self.model().parameters(), lr=optimizer_args['lr'])\n",
    "```\n",
    "\n",
    "By default (if this method is not specified in the `TrainingPlan`), model will be optimized using default `Adam` optimizer.\n",
    "\n",
    "\n",
    "### `training_data() and Custom Dataset`\n",
    "\n",
    "`training_data` is a method where the data is loaded for training on the node side. During each round of training, each node that particapates federated training builds the model, loads the dataset using the method `training_data`, and performs the `training_step` by passing loaded dataset.\n",
    "\n",
    "The dataset that we will be using in this tutorial is a image dataset. Therefore, your custom PyTorch `Dataset` should be be able to load images by given index . Please see the details of custom [PyTorch datasets](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). \n",
    "\n",
    "\n",
    "```python\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "\n",
    "            # Read the csv file that includes classes for each image\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir, self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "Now, you need to define a `training_data` method that will create a Fed-BioMed DataManager using custom `CelebaDataset` class.\n",
    "\n",
    "```python\n",
    "    def training_data(self):\n",
    "        # The training_data creates the dataset and returns DataManager to be used for training in the general class Torchnn of Fed-BioMed\n",
    "        dataset = self.CelebaDataset(\n",
    "            os.path.join(self.dataset_path, \"target.csv\"), os.path.join(self.dataset_path, \"data\")\n",
    "            )\n",
    "        loader_arguments = { 'shuffle': True}\n",
    "        return DataManager(dataset, **loader_arguments)\n",
    "```\n",
    "\n",
    "\n",
    "### `training_step()`\n",
    "\n",
    "The last method that needs to be defined is the `training_step`. This method is responsible for executing the forward method and calculating the loss value for the backward process of the network. To access the `forward` method of the `torch.nn.Module` that is defined in the `init_model`, the getter method `model()` of training plan class should be used.\n",
    "\n",
    "```python\n",
    "def training_step(self, data, target): \n",
    "    output = self.model().forward(data)\n",
    "    loss   = torch.nn.functional.nll_loss(output, target)\n",
    "    return loss\n",
    "```\n",
    "\n",
    "You are now ready to create your training plan class. All you need to do is to locate every method that has been explained in the previous sections in your traning plan class. In the next steps we will;\n",
    "\n",
    "1. launch the `Researcher`: `fedbiomed researcher start`\n",
    "2. download the CelebA dataset and deploy it on the nodes\n",
    "3. define our complete training\n",
    "4. create an experiment and run it\n",
    "5. evaluate our model using a testing dataset\n",
    "\n",
    "\n",
    "## 2.Configuring Nodes \n",
    "\n",
    "We will be working with [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) (CelebFaces) dataset. Therefore, please visit [here](https://drive.google.com/drive/folders/0B7EVK8r0v71pWEZsZE9oNnFzTm8?resourcekey=0-5BR16BdXnb8hVj6CNHKzLg) and download the files `img/img_align_celeba.zip` and `Anno/list_attr_celeba.txt`. After the download operation is completed;\n",
    "\n",
    "- Please go to `fbm-researcher/notebooks/data/Celeba` from the folder your are running the Fed-BioMed `Researcher`. \n",
    "- Create `Celeba_raw/raw` directory and copy the `list_attr_celeba.txt` file.\n",
    "- Extract the zip file `img_align_celeba.zip`\n",
    "\n",
    "Your folder should be same as the tree below;\n",
    "\n",
    "```\n",
    "Celeba\n",
    "    README.md\n",
    "    create_node_data.py    \n",
    "    .gitignore\n",
    " \n",
    "    Celeba_raw\n",
    "        raw\n",
    "            list_attr_celeba.txt\n",
    "            img_align_celeba.zip\n",
    "            img_align_celeba\n",
    "              lots of images \n",
    "```\n",
    "The dataset has to be processed and split to create three distinct datasets for Node 1, Node 2, and Node 3. You can do it easily by running the following script in your notebook. If you are working in a different directory than the `fbm-researcher/notebooks`, please make sure that you define/modify the correct paths in the following example.\n",
    "\n",
    "Running the following scripts might take some time, please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from fedbiomed.researcher.config import config\n",
    "\n",
    "# Celeba folder\n",
    "parent_dir = os.path.join(config.root, \"notebooks\", \"data\", \"Celeba\") \n",
    "celeba_raw_folder = os.path.join(\"Celeba_raw\", \"raw\")\n",
    "img_dir = os.path.join(parent_dir, celeba_raw_folder, 'img_align_celeba') + os.sep\n",
    "out_dir = os.path.join(parent_dir, \"celeba_preprocessed\")\n",
    "\n",
    "# Read attribute CSV and only load Smilling column\n",
    "df = pd.read_csv(os.path.join(parent_dir, celeba_raw_folder, 'list_attr_celeba.txt'),\n",
    "                 sep=\"\\s+\", skiprows=1, usecols=['Smiling'])\n",
    "\n",
    "# data is on the form : 1 if the person is smiling, -1 otherwise. we set all -1 to 0 for the model to train faster\n",
    "df.loc[df['Smiling'] == -1, 'Smiling'] = 0\n",
    "\n",
    "# Split csv in 3 parts\n",
    "length = len(df)\n",
    "data_node_1 = df.iloc[:int(length/3)]\n",
    "data_node_2 = df.iloc[int(length/3):int(length/3) * 2]\n",
    "data_node_3 = df.iloc[int(length/3) * 2:]\n",
    "\n",
    "# Create folder for each node\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_1\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_1\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_2\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_2\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_3\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_3\", \"data\"))\n",
    "\n",
    "# Save each node's target CSV to the corect folder\n",
    "data_node_1.to_csv(os.path.join(out_dir, 'data_node_1', 'target.csv'), sep='\\t')\n",
    "data_node_2.to_csv(os.path.join(out_dir, 'data_node_2', 'target.csv'), sep='\\t')\n",
    "data_node_3.to_csv(os.path.join(out_dir, 'data_node_3', 'target.csv'), sep='\\t')\n",
    "\n",
    "# Copy all images of each node in the correct folder\n",
    "for im in data_node_1.index:\n",
    "    shutil.copy(img_dir+im, os.path.join(out_dir,\"data_node_1\", \"data\", im))\n",
    "print(\"data for node 1 succesfully created\")\n",
    "\n",
    "for im in data_node_2.index:\n",
    "    shutil.copy(img_dir+im, os.path.join(out_dir, \"data_node_2\", \"data\", im))\n",
    "print(\"data for node 2 succesfully created\")\n",
    "\n",
    "for im in data_node_3.index:\n",
    "    shutil.copy(img_dir+im, os.path.join(out_dir, \"data_node_3\", \"data\", im))\n",
    "print(\"data for node 3 succesfully created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabc12a",
   "metadata": {},
   "source": [
    "Now if you go to the `fdm-researcher/notebooks/data/Celaba` directory you can see the folder called `celeba_preprocessed`. There will be three different folders that contain an image dataset for 3 nodes. The next step will be configuring the nodes and deplying the datasets. In the next steps, we will be configuring only two nodes. The dataset for the third node is going to be used for the testing. \n",
    "\n",
    "\n",
    "Create 2 nodes for training :  \n",
    " - `fedbiomed component create -c node --path ./my-first-node`\n",
    " - `fedbiomed component create -c node --path ./my-second-node`  \n",
    "\n",
    " **Note**: You may want to copy the dataset created into `Nodes`, in the folder `my-first-node/data` or  `./my-second-node/data` . This is not required for Fed-BioMed to work, since you can access dataset from outside `Node` component, but enables you to run the tutorials more easily. \n",
    " Commands for that will be:\n",
    "  - `cp -r fbm-researcher/notebooks/data/Celeba/celeba_preprocessed/data_node_1/ my-first-node/data/`\n",
    "  - `cp -r fbm-researcher/notebooks/data/Celeba/celeba_preprocessed/data_node_2/ my-second-node/data/`\n",
    "\n",
    "Add data to each node :  \n",
    " - `fedbiomed node --path ./my-first-node dataset add`\n",
    " - `fedbiomed node --path ./my-second-node dataset add`\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "### 2.1. Configuration Steps\n",
    "\n",
    "It is necessary to previously configure at least a node:\n",
    "1. `fedbiomed node --path ./my-first-node dataset add` or `fedbiomed node --path ./my-second-node dataset add`\n",
    "  * For each `Node`, select option `4` (images) to add an image dataset to the node\n",
    "  * Add a name and the tag for the dataset (tag should contain **'#celeba'** as it is the tag used for this training) and finally add the description\n",
    "  * Pick a data folder from the 3 generated datasets inside `fbm-researcher/data/Celeba/celeba_preprocessed` (eg: `data_node_1`) or direclty in the `Node` `data` folder\n",
    "  * Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "  \n",
    "2. Check that your data has been added by executing `fedbiomed node --path <component-directory> dataset list`\n",
    "3. Run the node using `fedbiomed node --path <component-directory> start`. Wait until you get `Starting task manager`. it means you are online.\n",
    "\n",
    "After the steps above are completed, you will be ready to train your classification model on two different nodes. \n",
    "\n",
    "## 3. Defining Custom PyTorch Model and Training Plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd2931",
   "metadata": {},
   "source": [
    "Next step is to create our `Net` class based on the methods that have been explained in the previous sections. This class is part of the training plan that will be passed to the Experiment.  Afterwards, the nodes will receive the training plan and perform the training by retrieving training data and passing it to the `training_step`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0929ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from fedbiomed.common.data import DataManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class CelebaTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    # Defines model\n",
    "    def init_model(self):\n",
    "        model = self.Net()\n",
    "        return model\n",
    "\n",
    "    # Here we define the custom dependencies that will be needed by our custom Dataloader\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torch.utils.data import Dataset\",\n",
    "                \"from torchvision import transforms\",\n",
    "                \"import pandas as pd\",\n",
    "                \"from PIL import Image\",\n",
    "                \"import os\",\n",
    "                \"import numpy as np\"]\n",
    "        return deps\n",
    "\n",
    "    # Torch modules class\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            #convolution layers\n",
    "            self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "            self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "            self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            # classifier\n",
    "            self.fc1 = nn.Linear(3168, 128)\n",
    "            self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.conv4(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "\n",
    "    class CelebaDataset(Dataset):\n",
    "        \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "        # we dont load the full data of the images, we retrieve the image with the get item.\n",
    "        # in our case, each image is 218*178 * 3colors. there is 67533 images. this take at leas 7G of ram\n",
    "        # loading images when needed takes more time during training but it wont impact the ram usage as much as loading everything\n",
    "        def __init__(self, txt_path, img_dir, transform=None):\n",
    "            df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "            self.img_dir = img_dir\n",
    "            self.txt_path = txt_path\n",
    "            self.img_names = df.index.values\n",
    "            self.y = df['Smiling'].values\n",
    "            self.transform = transform\n",
    "            print(\"celeba dataset finished\")\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "            img = transforms.ToTensor()(img)\n",
    "            label = self.y[index]\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return self.y.shape[0]\n",
    "\n",
    "    # The training_data creates the Dataloader to be used for training in the\n",
    "    # general class Torchnn of fedbiomed\n",
    "    def training_data(self):\n",
    "        dataset = self.CelebaDataset(os.path.join(self.dataset_path, \"target.csv\"), os.path.join(self.dataset_path, \"data\"))\n",
    "        loader_arguments = { 'shuffle': True}\n",
    "        return DataManager(dataset, **loader_arguments)\n",
    "\n",
    "    # This function must return the loss to backward it\n",
    "    def training_step(self, data, target):\n",
    "\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8d887",
   "metadata": {},
   "source": [
    "This group of arguments corresponds respectively to:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node-side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node-side.\n",
    "\n",
    "**Note:** Typos and/or lack of positional (required) arguments might raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09392303",
   "metadata": {},
   "source": [
    "## 4. Training Federated Model\n",
    "\n",
    "To provide training orchestration over two nodes we need to define an experiment which:\n",
    "\n",
    "- searches nodes serving data for the `tags`, \n",
    "- defines the local training on nodes with the training plan saved in `training_plan_path`, and federates all local updates at each round with `aggregator`\n",
    "- runs training for `round_limit`.\n",
    "\n",
    "You can visit [user guide](../../../user-guide/researcher/experiment) to know much more about experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed132c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#celeba']\n",
    "rounds = 3\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=CelebaTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38721584",
   "metadata": {},
   "source": [
    "Let's start the experiment.\n",
    "\n",
    "By default, this function doesn't stop until all the `round_limit` rounds are done for all the nodes. While the experiment runs you can open the terminals where you have started the nodes and see the training progress. However, the loss values obtained from each node during the training will be printed as output in real time. Since we are working on an image dataset, training might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e34946",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7df5e",
   "metadata": {},
   "source": [
    "Save trained model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb52c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227e429",
   "metadata": {},
   "source": [
    "### Loading Training Parameters\n",
    "\n",
    "After all the rounds have been completed, you retrieve the aggregated parameters from the last round and load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe862bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_model = exp.training_plan().model()\n",
    "fed_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e012d2",
   "metadata": {},
   "source": [
    "## 5. Testing Federated Model \n",
    "\n",
    "We will define a testing routine to extract the accuracy metrics on the testing dataset. We will use the dataset that has been extracted into `data_node_3`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec39d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def testing_Accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    device = \"cpu\"\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    loader_size = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            #only uses 10% of the dataset, results are similar but faster\n",
    "            if idx >= loader_size / 10:\n",
    "                pass\n",
    "                break\n",
    "\n",
    "    \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/(data_loader.batch_size * idx)\n",
    "\n",
    "    return(test_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b05f8b",
   "metadata": {},
   "source": [
    "We also need to define a custom Dataset class for the test dataset in order to load it using PyTorch's `DataLoader`. This will be the same class that has been already defined in the training plan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.config import config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "test_dataset_path = os.path.join(config.root,\n",
    "                                 \"notebooks\",\n",
    "                                 \"data\",\n",
    "                                 \"Celeba\",\n",
    "                                 \"celeba_preprocessed\",\n",
    "                                 \"data_node_3\")\n",
    "\n",
    "class CelebaDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, txt_path, img_dir, transform=None):\n",
    "        df = pd.read_csv(txt_path, sep=\"\\t\", index_col=0)\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_path = txt_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Smiling'].values\n",
    "        self.transform = transform\n",
    "        print(\"celeba dataset finished\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(os.path.join(self.img_dir,\n",
    "                                        self.img_names[index])))\n",
    "        img = transforms.ToTensor()(img)\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "\n",
    "dataset = CelebaDataset(os.path.join(test_dataset_path, \"target.csv\"), os.path.join(test_dataset_path, \"data\"))\n",
    "train_kwargs = { 'shuffle': True}\n",
    "data_loader = DataLoader(dataset, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42993d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_federated = testing_Accuracy(fed_model, data_loader)\n",
    "acc_federated[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e246bb08",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this tutorial, running a custom model on Fed-BioMed (by wrapping it in a custom training plan) for the PyTorch framework has been explained. Because the examples are designed for the development environment, we have been running nodes in the same host machine. In production, the nodes that you need to use to train your model will serve in remote servers. Please check out how to [deploy Nodes in a production environment](../../user-guide/deployment/deployment/introduction)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
