{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98fcfd9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MNIST classification with PyTorch, comparing federated model vs model trained locally\n",
    "\n",
    "**Overview of the tutorial**: \n",
    "\n",
    "In this tutorial, we are going to compare Federated models created through Fed-BioMed framework and a model trained locally (through `LocalJob` function provided by Fed-BioMed). To this end, we will re-use the model trained in the first [PyTorch tutorial: MNIST basic Example](../01_PyTorch_MNIST_Single_Node_Tutorial) and compare it to a model trained locally. Thus, it is recommended to run this first tutorial before this one.\n",
    "\n",
    "At the end of this tutorial, you will learn:\n",
    "\n",
    "* how to train a model in Pytorch designed for Fed-BioMed locally \n",
    "* how to evaluate both models\n",
    "\n",
    "\n",
    "**HINT** : to reload the notebook,  please click on the following button:\n",
    "\n",
    "`Kernel` -> `Restart and clear Output`\n",
    "\n",
    "![reload-notebook](../../../assets/img/sketch_reload_notebook.jpg#img-md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222988c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 0. Clean your environments\n",
    "\n",
    "Before executing notebook and starting nodes, it is safer to remove all configuration scripts automatically generated by Fed-BioMed. To do so, enter the following in a terminal:\n",
    "\n",
    "```shell\n",
    "source ${FEDBIOMED_DIR}/scripts/fedbiomed_environment clean\n",
    "```\n",
    "\n",
    "**Note:** `${FEDBIOMED_DIR}` is a path relative to based directory of the cloned Fed-BioMed repository. You can set it by running command `export FEDBIOMED_DIR=/path/to/fedbiomed`. This is not required for Fed-BioMed to work but enables you to run the tutorials more easily. \n",
    "\n",
    "## 1. Configuring Nodes \n",
    "\n",
    "In this tutorial, you will learn how to train your model with a single Fed-BioMed node. Thus, we need to configure a node and add MNIST dataset to it. Node configuration steps require `fedbiomed-node` conda environment. Please make sure that you have the necessary conda environment: this is explained in the [installation tutorial](../../installation/0-basic-software-installation). You can check your environment by running the following command.\n",
    "\n",
    "```\n",
    "$ conda env list\n",
    "```\n",
    "If you have all Fed-BioMed environments you are ready to go for the node configuration steps. \n",
    "\n",
    "Please open a terminal, `cd` to the base directory of the cloned fedbiomed project and follow the steps below.    \n",
    "\n",
    "* **Configuration Steps:**\n",
    "    * Run `${FEDBIOMED_DIR}/scripts/fedbiomed_run node add` in the terminal\n",
    "    * It will ask you to select the data type that you want to add. The second option (which is the default) has been configured to add the MNIST dataset. Please type `2` and continue. \n",
    "    * Please use default tags which are `#MNIST` and `#dataset`.\n",
    "    * For the next step, please select the directory that you want to download the MNIST dataset.\n",
    "    * After the download is completed you will see the details of the MNIST dataset on the screen.\n",
    " \n",
    "Please run the command below in the same terminal to make sure the MNIST dataset is successfully added to the node.  \n",
    "\n",
    "## 2. Running Tutorial: Basic PyTorch on MNIST dataset\n",
    "\n",
    "In this notebook tutorial, we are going to re-use the Convolution neural network model defined in this first tutorial. Hence, this notebook will be considered to be the continuation of the first tutorial. For more details; please refer to the forementioned tutorial material.\n",
    "\n",
    "## 3. Defining a Fed-BioMed Training Plan and Model on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e00407",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the training plan to be used.\n",
    "# You can use any class name (here 'MyTrainingPlan')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    # Defines and return model\n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "\n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "\n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self, batch_size = 48):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        loader_arguments = {'batch_size': batch_size, 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **loader_arguments)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b9c17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'batch_size': 48,\n",
    "    'optimizer_args': {\n",
    "        'lr': 1e-3\n",
    "    },\n",
    "    'epochs': 1,\n",
    "    'dry_run': False,\n",
    "    'batch_maxnum': 200 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58130598",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Training the Model in a Federated setting\n",
    "\n",
    "We will reproduce the same steps as in [Tutorial: Basic PyTorch on MNIST dataset](../01_PyTorch_MNIST_Single_Node_Tutorial). Remote model will be trained on a single Node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb055a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "remote_experiment = Experiment(tags=tags,\n",
    "                               training_plan_class=MyTrainingPlan,\n",
    "                               training_args=training_args,\n",
    "                               round_limit=rounds,\n",
    "                               aggregator=FedAverage(),\n",
    "                               node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853c361",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "remote_experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58083fc3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Training Fed-BioMed model locally\n",
    "\n",
    "In this section, we are going to re-use the defined model and train it locally using `localJob` function provide by Fed-BioMed. This function is only used for comparing model locally; on researcher side.\n",
    "\n",
    "To use `localJob` function could prove useful and wise for testing a federated model on your own system, and checking if it is working correctly before deploying it on nodes.\n",
    "\n",
    "First you need to create a folder containing your dataset on your system (ie on `environ['TMP_DIR']/local_mnist.tmp` folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a75ba5",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from fedbiomed.researcher.environ import environ\n",
    "\n",
    "local_mnist = os.path.join(environ['TMP_DIR'], 'local_mnist')\n",
    "print(f'Using directory {local_mnist} for MNIST local copy')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "datasets.MNIST(root = local_mnist, download = True, train = True, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea7656",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An object `localJob` has to be created: it mimics the functionalities of the class `Job` to run the model on the input local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19918a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The class local job mimics the class job used in the experiment\n",
    "from fedbiomed.researcher.job import localJob\n",
    "from fedbiomed.researcher.environ import environ\n",
    "\n",
    "# local train on same amount of data as federated with 1 node\n",
    "training_args['epochs'] *= rounds\n",
    "\n",
    "local_job = localJob(dataset_path = local_mnist,\n",
    "                     training_plan_class=MyTrainingPlan,\n",
    "                     training_args=training_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e155f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the localJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f90636",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local_job.start_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e49ed0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Retrieve the local models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ab8c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "local_model = local_job.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab8c86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Comparison between Federated model and model trained locally\n",
    "\n",
    "Let's try to compare our local model against the Federated model, on the MNIST testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4ee87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "def testing_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    device = 'cpu'\n",
    "\n",
    "    correct = 0\n",
    "    y_pred = []\n",
    "    y_actu = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            y_pred.extend(torch.flatten(pred).tolist()) \n",
    "            y_actu.extend(target.tolist())\n",
    "\n",
    "        y_pred = pd.Series(y_pred, name='Actual')\n",
    "        y_actu = pd.Series(y_actu, name='Predicted')\n",
    "        cm = pd.crosstab(y_actu, y_pred)\n",
    "        #correct = sum([cm.iloc[i,i] for i in range(len(cm))])\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100* correct/len(data_loader.dataset)\n",
    "\n",
    "    return(test_loss, accuracy, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894424b",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "test_set = datasets.MNIST(root = os.path.join(environ['TMP_DIR'], 'local_mnist.tmp'),\n",
    "                          download = True,\n",
    "                          train = False,\n",
    "                          transform = transform)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dff3e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load remote model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b2d86",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "remote_model = remote_experiment.training_plan().model()\n",
    "remote_model.load_state_dict(remote_experiment.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253700c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Compute errors for both remote (federated) and local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb4817",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remote accuracy and error computation\n",
    "remote_loss, remote_acc, remote_conf_matrix = testing_accuracy(remote_model, test_loader)\n",
    "\n",
    "\n",
    "# local accuracy and error computation\n",
    "local_loss, local_acc, local_conf_matrix = testing_accuracy(local_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c765c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nAccuracy local training: {:.4f}, \\nAccuracy federated training:  {:.4f}\\nDifference: {:.4f}'.format(\n",
    "             local_acc, remote_acc, abs(local_acc - remote_acc)))\n",
    "\n",
    "print('\\nError local training: {:.4f}, \\nError federated training:  {:.4f}\\nDifference: {:.4f}'.format(\n",
    "             local_loss, remote_loss, abs(local_loss - remote_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e712355",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plotting Confusion Matrix of both remote and local Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc72de4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19761b67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(fig, ax, conf_matrix, title, xlabel, ylabel, n_image=0):\n",
    "    \n",
    "    im = ax[n_image].imshow(conf_matrix)\n",
    "\n",
    "    ax[n_image].set_xticks(np.arange(10))\n",
    "    ax[n_image].set_yticks(np.arange(10))\n",
    "\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            text = ax[n_image].text(j, i, conf_matrix[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    ax[n_image].set_xlabel(xlabel)\n",
    "    ax[n_image].set_ylabel(ylabel)\n",
    "    ax[n_image].set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957f74d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2,figsize=(10,5)) \n",
    "plot_confusion_matrix(fig, axs, remote_conf_matrix.to_numpy(),\n",
    "                     'Confusion Matrix for remote model',\n",
    "                     'Actual targets',\n",
    "                      'Predicted targets', n_image=0)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(fig, axs, local_conf_matrix.to_numpy(),\n",
    "                     'Confusion Matrix for local model',\n",
    "                     'Actual targets',\n",
    "                      'Predicted targets', n_image=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b03d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Congrats! \n",
    "\n",
    "Now you know how to train a Fed-BioMed model designed with Pytorch framework locally.\n",
    "\n",
    "Check out other tutorials and documentation to learn more about Fed-BioMed Federated Learning Framework\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}