{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73501475-4e1f-454c-bc16-0320ecd51d57",
   "metadata": {},
   "source": [
    "# Transfer-learning in Fed-BioMed tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d343c58-9d11-400f-9e2e-9b0d1e840105",
   "metadata": {},
   "source": [
    "\n",
    "## Goal of this tutoriel\n",
    "\n",
    "This tutorial shows how to do 2d images classification example on MedNIST dataset using pretrained PyTorch model.\n",
    "\n",
    "The goal of this tutorial is to provide an example of transfer learning methods with Fed-BioMed for medical images classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4648375-0340-428a-88cf-97c5a52f5560",
   "metadata": {},
   "source": [
    "### About the model\n",
    "\n",
    "The model used is Densenet-121 model(“Densely Connected Convolutional Networks”) pretrained on ImageNet dataset. The Pytorch pretrained model [Densenet121](https://pytorch.org/vision/main/models/generated/torchvision.models.html) to perform image classification on the MedNIST dataset. \n",
    "The goal of this Densenet121 model is to predict the class of `MedNIST` medical images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463ce8b-8c65-4d51-85ad-47ce8fbc5528",
   "metadata": {},
   "source": [
    "### About MedNIST\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "MedNIST dataset is downloaded from the resources provided by the project [MONAI](https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz)\n",
    "\n",
    "The dataset MedNIST has 58954 images of size (3, 64, 64) distributed into 6 classes (10000 images per class except for BreastMRI class which has 8954 images). Classes are **AbdomenCT, BreastMRI, CXR, ChestCT, Hand, HeadCT**. It has the structure:\n",
    "\n",
    "└── MedNIST/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "\n",
    "    └── BreastMRI/\n",
    "\n",
    "    └── CXR/\n",
    "\n",
    "    └── ChestCT/\n",
    "\n",
    "    └── Hand/\n",
    "\n",
    "    └── HeadCT/   \n",
    "   \n",
    "\n",
    "## Transfer-learning\n",
    "Transfer learning is a machine learning technique where a model trained on one task is repurposed or adapted for a second related task. Transfer learning uses a pre-trained neural network on a large dataset, as [Imagenet](https://www.image-net.org) is used to train DenseNet model to perform classification of a wide diversity of images.\n",
    "\n",
    "The objective is that the knowledge gained from learning one task can be useful for learning another task (as we do here, the knowledge of DenseNet model trained on ImageNet is used to classify medical images in 6 categories). This is particularly beneficial when the amount of labeled data for the target task is limited, as the pre-trained model has already learned useful features and representations from a large dataset.\n",
    "\n",
    "Transfer learning is typically applied in one of two ways:\n",
    "\n",
    "- (I) Feature Extraction: In this approach, the pre-trained model is used as a fixed feature extractor. The earlier layers of the neural network, which capture general features and patterns, are frozen, and only the later layers are replaced or retrained for the new task. \n",
    "\n",
    "- (II) Fine-tuning: In this approach, the pre-trained model is further trained or partially trained on the new task. This allows the model to adapt its learned representations to the specifics of the new task while retaining some of the knowledge gained from the original task.\n",
    "\n",
    "\n",
    "In this example, we load on two nodes a sampled dataset ( 500 images and 1000 images) of MedNIST to illustrate   transfer-learning's effectiveness. The sampled dataset is made with a random selection of images and return a sampled dataset with balanced classes, to avoid classification's bias.\n",
    "We will run two independant TrainingPlan experiments, one without transfer-learning and the second with transfer learning.\n",
    "We will compare these two experiments running on DenseNet model with focus on loss value and accuracy as metrics to evaluate the effectiveness of Transfer-learning methods. \n",
    "\n",
    "**Nota**: This Transfer-Learning example is not to be confused with *Federated Transfer Learning-FTL* (see for example [this paper](https://arxiv.org/pdf/1902.04885)). The example only showcases here Transfer Learning on a Federated Learning use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf14e-d695-4831-8bdf-0e09f7c2f53e",
   "metadata": {},
   "source": [
    "### 1. Load dataset or sampled dataset\n",
    "- In a new Fed-BioMed environment, run the script python: `python fbm-researcher/notebooks/transfer-learning/download_sample_of_mednist.py -n 2`, with `-n 2` the number of `Nodes` you want to create ( for more details about this script, please run `python fbm-researcher/notebooks/transfer-learning/download_sample_of_mednist.py --help`)\n",
    "- The script will ask for each `Nodes` created the number of samples you want for your dataset. For example you could:\n",
    "    **Enter 500 the first time the script ask the number of samples, and 1000 the second time**\n",
    "    Scripts will output component directories for each of `Nodes`, with configured database, using the following naming convention: `node_MedNIST_<i>_sampled` where `<i>` corresponds to the number of Node created. Components will be created in the directory where this script is executed.\n",
    "    Eventually, it will add the dataset to the already created `Nodes`.\n",
    "- Finally launch your Nodes  by running: `fedbiomed node --path node_MedNIST_1_sampled start`.  In another terminal, run `fedbiomed node --path node_MedNIST_2_sampled start`.\n",
    "\n",
    "Wait until you get `Starting task manager`.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Launch the researcher \n",
    "- From the root directory of Fed-BioMed, run : `fedbiomed researcher start`\n",
    "- It opens the Jupyter notebook.\n",
    "\n",
    "To make sure that MedNIST dataset is loaded in the node we can send a request to the network to list the available dataset in the node. The list command should output an entry for mednist data.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf52151-a981-4189-8be4-ea5ca03fd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "from fedbiomed.researcher.config import config\n",
    "req = Requests(config)\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20148877-d424-4793-9d8b-693d2e47ba44",
   "metadata": {},
   "source": [
    "## Import of librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae87e6a-94ac-4ecf-9586-8f9a353fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.densenet import DenseNet121_Weights\n",
    "import pandas as pd\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "\n",
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567f368-0dc6-4eaa-95a6-1f7a6e78c6e7",
   "metadata": {},
   "source": [
    "### I- Adapt the last layer to your classification's goal\n",
    "Here we use the DenseNet model that allows classification through 10000 samples. \n",
    "We could adapt this classification's task to the MedNIST dataset by replacing the last layer with our classifier. \n",
    "The `model.classifier` layer of the `DenseNet-121` model classifies images through 6 classes, in the Training Plan, by adapting the num_classes value (can be done in through `model_args` argument). \n",
    "\n",
    "### Data augmentation\n",
    "You could perform data augmentation through the preprocess part if you need. Here I show random flip, rotation and crops. \n",
    "You could do the preprocessing of images by doing only transforms.resize, transforms.to_tensor and transforms.normalize, as mentionned in the code below (commented lines). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f5b80",
   "metadata": {},
   "source": [
    "## I. Run an expriment for image's classification without Transfer-learning\n",
    "\n",
    "\n",
    "Here we propose to run as first experiment a TrainingPlan0 with the untrained DenseNet model. Then, we will compare the loss value from the two other experiments allowing Transfer-learning methods.\n",
    "\n",
    "We don't use the pre-trained weights. It is important to adapt learning rate. I propose you to start with lr=1e-4 and we could adapt learning rate according to the metric's evaluation. \n",
    "\n",
    "\n",
    "### I -1. Define Training plan experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43761a76-1efc-46cc-80b6-161b3c99731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan1(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "        model = models.densenet121(weights=None)  # here model coefficients are set to random weights\n",
    "\n",
    "        # add the classifier \n",
    "        num_classes = model_args['num_classes'] \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier= nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "      \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\",\n",
    "            \"from torchvision.models import densenet121\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    \n",
    "    # training data\n",
    "    \n",
    "    def training_data(self):\n",
    "\n",
    "        # Transform images and  do data augmentation \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011a997-5fc6-4d01-af73-54c6017da976",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-3}, \n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100, # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "    'random_seed': 1234\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6, # adapt this number to the number of classes in your dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f594a9-8d00-464b-80f1-ff42dac59b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags =  ['#MEDNIST', '#dataset']\n",
    "\n",
    "rounds = 1 # adjsut the number of rounds \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan1,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "# testing section \n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1) \n",
    "exp.set_test_on_global_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eee3f6",
   "metadata": {},
   "source": [
    "### I - 3. Run your experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087e8b5-cad2-4436-9d85-6686717ba8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf6a7-eb26-4b9c-bc24-492c8cb030b8",
   "metadata": {},
   "source": [
    "###### For example,  At the end of training experiment, I obtained\n",
    "\n",
    "```\n",
    "fedbiomed INFO - VALIDATION ON GLOBAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: node_mednist_1_sampled \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 50/50\n",
    " \t\t\t\t\t ACCURACY: 0.740000 \n",
    "\t\t\t\t\t ---------\n",
    "\n",
    "fedbiomed INFO - VALIDATION ON GLOBAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: node_mednist_2_sampled \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.780000 \n",
    "\t\t\t\t\t ---------\n",
    "\t\t\t\t\t \n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600b2ce",
   "metadata": {},
   "source": [
    "### I - 4. Save your model \n",
    "You could save your model to later use it in a new TrainingPlan \n",
    "This save allows to import the model including your layers's modification and weights values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b54a8-43a0-4009-8e3e-07e62fec2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan1_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263f76b",
   "metadata": {},
   "source": [
    "### I - 5. Results in tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ace09-7f4d-40fd-8646-c3f4cb67042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.config import config\n",
    "tensorboard_dir = config.vars['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31041e7e-728d-4b18-a5d7-58f405bd1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bdb39-287e-4cc4-973d-1dfb30838aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569eb49",
   "metadata": {},
   "source": [
    "### I - 6. Training timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa36b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027428-86f9-4f0f-87da-b8b97da6838e",
   "metadata": {},
   "source": [
    "## II - Run an expriment for image's classification using Transfer-learning \n",
    "\n",
    "\n",
    "### II-1. Downloading the pretrained model's weights \n",
    "Here I download and save the model's weights through [Torch.hub](https://pytorch.org/hub/) using the command below in a file `'pretrained_model.pt'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', weights=DenseNet121_Weights.DEFAULT)\n",
    "torch.save(model.state_dict(), 'pretrained_model.pt')\n",
    "torch.save(model.state_dict(), 'pretrained_model2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d6272",
   "metadata": {},
   "source": [
    "### II-2. Adapt the last layer to your classification's goal\n",
    "Here we use the DenseNet model that allows classification through 1500 samples (on 2 nodes). \n",
    "We could adapt this classification's task to the MedNIST dataset by replacing the last layer with our classifier. \n",
    "The `model.classifier` layer of the `DenseNet-121` model classifies images through 6 classes, in the Training Plan, by adapting the num_classes value (can be done in through `model_args` argument). \n",
    "\n",
    "The dataset is defined below, after TrainingPlan as previously shown.\n",
    "\n",
    "You could also import the model you saved to perform your second TrainingPlan experiment (let's see below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33207b0-6d38-4cb6-a1ed-7ea18e55b1ea",
   "metadata": {},
   "source": [
    "In this experiment I will unfreeze two last block layers and the classifier layers. Other layers will stay frozen (i.e. they will not change during the experiment).\n",
    "\n",
    "I introduce a new argument in `model_args` called `num_unfrozen_blocks`. This argument specifies the number of blocks left unfrozen. In DenseNet model, layers are grouped whithin blocks. There is a total of 12 blocks, containing several layers each. In our experiment, we will consider rather freezing blocks of layer than layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62ced6-f7e6-406f-8dfe-77e620aa3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "class MyTrainingPlan2(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "        model = models.densenet121(weights=None)\n",
    "        # let's unfreeze layers of the last dense block\n",
    "        num_unfrozen_layer = model_args['num_unfrozen_blocks']\n",
    "        for param in model.features[:-num_unfrozen_layer].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # add the classifier \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        num_classes = model_args['num_classes'] \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes)       \n",
    "            )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data and transform images and perform data augmentation \n",
    "       \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f3099-b6e6-4395-b9ea-ad2b728d0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-4}, # You could decrease the learning rate\n",
    "    'epochs': 1, # you can increase the epoch's number =10\n",
    "    'dry_run': False,\n",
    "    'random_seed': 1234,\n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "model_args={\n",
    "    'num_classes': 6,\n",
    "    'num_unfrozen_blocks': 2  \n",
    "}\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 1  # you can increase the rounds's number \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan2,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1)\n",
    "exp.set_test_on_global_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3db555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we load the model we have saved with torch-hub weights\n",
    "\n",
    "exp.training_plan().import_model('pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829e80f",
   "metadata": {},
   "source": [
    "### II - 3. Run your experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3e1a9-b0c8-4bbc-b397-0d0b6b14ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75552d69",
   "metadata": {},
   "source": [
    "###### For example,  At the end of training experiment, I obtained :\n",
    "\n",
    "```\n",
    "fedbiomed INFO - VALIDATION ON GLOBAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: node_mednist_1_sampled \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 50/50\n",
    " \t\t\t\t\t ACCURACY: 1.0000\n",
    "\t\t\t\t\t ---------\n",
    "\n",
    "fedbiomed INFO - VALIDATION ON GLOBAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: node_mednist_2_sampled \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 1.0000 \n",
    "\t\t\t\t\t ---------\n",
    "\t\t\t\t\t \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394f0b1-5795-479e-a544-dc07913ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f51d1b-960f-4b4b-b301-7c7ea7c68c9a",
   "metadata": {},
   "source": [
    "### II -  4. Export your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2acea",
   "metadata": {},
   "source": [
    "### II - 5. Display losses on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d301fa3-50e7-4aee-96d6-b85bed457fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73071-f09b-4a87-a0a6-d525ce39c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\" --port 6007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4668ca",
   "metadata": {},
   "source": [
    "### II - 6. Save and Import your model and parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efaf44",
   "metadata": {},
   "source": [
    "You could import your first model from TrainingPlan1 instead of loading the original DenseNet.\n",
    "You could also retrieve the model's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e906de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your model from a file\n",
    "model_features_ = torch.load('./training_plan2_densenet_MedNIST')\n",
    "model_features_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd9b21",
   "metadata": {},
   "source": [
    "### II - 7. check model parameters changed/unchanged\n",
    "\n",
    "Here we are just making sure that the layers that were supoosed to be modified have indeed been modified, between the original model downloaded from pytorch hub and the trained model.\n",
    "\n",
    "We will discard the batch normalization layers, since those may have changed during the transfer learning operation\n",
    "\n",
    "\n",
    "**Let's first have a look to the layers in the model that we left unfrozen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034562d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfrozen layers during transfer learning (MyTrainingPlan2)\n",
    "model_features = exp.training_plan().model()\n",
    "model_features.features[:-model_args['num_unfrozen_blocks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871aabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we check if Layers of the DenseNet model have changed between the initial model and the model extracted\n",
    "# from the training plan (after transfer learning)\n",
    "model_features = exp.training_plan().model()\n",
    "\n",
    "table = pd.DataFrame(columns=[\"Layer name\", \"Layer set to frozen\", \"Is Layer changed?\"])\n",
    "ref_model = torch.load('pretrained_model.pt')  # reloading model downloaded from pytorch hub\n",
    "\n",
    "\n",
    "remove_norm_layers= lambda name : not any([x in name for x in ('norm', 'batch') ])\n",
    "    \n",
    "\n",
    "layers = list(ref_model.keys())\n",
    "ours_layers = model_features.features[:-model_args['num_unfrozen_blocks']]\n",
    "ours_layers = ['features.'+ x for x in ours_layers.state_dict().keys()]\n",
    "\n",
    "_counter = 0\n",
    "for i, (layer_name, param) in enumerate(model_features.state_dict().items()):\n",
    "    if i >= len(layers):\n",
    "        continue\n",
    "    l = layers[i]\n",
    "\n",
    "    if remove_norm_layers(l) :\n",
    "        r_tensor = ref_model[l]\n",
    "        if 'classifier' in layer_name:\n",
    "            table.loc[_counter] = [l, l in ours_layers, \"non comparable\"]\n",
    "\n",
    "        else:\n",
    "            t = model_features.get_parameter(l)\n",
    "            _is_close = bool(torch.isclose(r_tensor, t).all())\n",
    "            table.loc[_counter] = [l, l in ours_layers, not _is_close, ]\n",
    "\n",
    "    _counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display comaprison table content\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902b849",
   "metadata": {},
   "source": [
    "The table displays all layers, the one modified and untouched during the training. `\"non comparable\"` means layers that have been modified from original model to our use case. Those layers are the classifiying layers.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "Through these experiments, we have observed a better accuracy and a faster decreasing loss value with transfer-learning methods instead of using the untrained model.\n",
    "\n",
    "To conclude with the method of transfer learning, it is depending on how many data you have. You could choose to train more layers and compare the metrics with partial fine-tuning. You choose the method that gives the best metrics for your experiment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
