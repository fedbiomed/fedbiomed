{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Process with Training Plan Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Fed-BioMed offers a feature to run only the pre-approved training plans on the nodes by default. The nodes which receive your training plan might require approved training plans. Therefore, if the node accepts only the approved training plan, the training plan files that are sent by a researcher with the training request should be approved by the node side in advance. In this workflow, the training plan approval process is done by a real user/person who reviews the code contained in the training plan file/class. The reviewer makes sure the model doesn't contain any code that might cause privacy issues or harm the node.\n",
    "\n",
    "In this tutorial, we will be creating a node with activated training plan control option.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Node\n",
    "\n",
    "\n",
    "Enabling training plan control can be done both from config file or Fed-BioMed CLI while starting the node. The process of creating and starting a node with training plan control option is not so different from setting up a normal node. By default, if no option is specified in the CLI when the node is launched for the first time, the node disables training plan control in the security section of the config file. It then looks like the snippet below :\n",
    "\n",
    "```shell\n",
    "[security]\n",
    "hashing_algorithm = SHA256\n",
    "allow_default_training_plans = True\n",
    "training_plan_approval = False\n",
    "```\n",
    "It is also possible to manage training plan approval mode using environment variables. `FBM_SECURITY_TRAINING_PLAN_APPROVAL=True` and `FBM_SECURITY_ALLOW_DEFAULT_TRAINING_PLANS=True` to activate training plan approval mode. They enable one-time override of the config file options at each launch of the node.\n",
    "\n",
    "* `FBM_SECURITY_TRAINING_PLAN_APPROVAL=True` : This variable enables training plan control for the node. If there isn't a config file for the node while running CLI, it creates a new config file with enabled training plan approval mode `training_plan_approval = True`. \n",
    "* `FBM_SECURITY_ALLOW_DEFAULT_TRAINING_PLANS=True`  : This variable allows default training plans for train requests. These are the training plans that come for Fed-BioMed tutorials. For example, the training plan for MNIST dataset that we will be using for this tutorial. If the default training plans are enabled, node updates/registers training plan files which are located in `envs/common/default_training_plans` directory during the starting process of the node. This option has no effect if training plan control is not enabled.\n",
    "\n",
    "### Adding MNIST Dataset to The Node. \n",
    "\n",
    "In this section we will add MNIST dataset to the node. While adding the dataset through CLI we'll also specify `FBM_SECURITY_TRAINING_PLAN_APPROVAL=True` and `ALLOW_DEFAULt_TRAINING_PLANS=True` options. This will create new component in the directory`./my-node` with following configuration that will be located in the `my-node/etc/config.ini`. \n",
    "\n",
    "```\n",
    "[security]\n",
    "hashing_algorithm = SHA256\n",
    "allow_default_training_plans = True\n",
    "training_plan_approval = True\n",
    "\n",
    "```\n",
    "Now, let's run the following command. \n",
    "\n",
    "```shell\n",
    "$ FBM_SECURITY_TRAINING_PLAN_APPROVAL=True FBM_SECURITY_ALLOW_DEFAULT_TRAINING_PLANS=True fedbiomed node --path ./my-node dataset add \n",
    "```\n",
    "\n",
    "The CLI will ask you to select the dataset type. Since we will be working on MNIST dataset, please select `2` (default) and continue by typing `y` for the next prompt and select folder that you want to store MNIST dataset. Afterward, if you go to `etc` directory of fedbiomed, you can see `config-n1.ini` file. \n",
    "\n",
    "### Starting the Node\n",
    "\n",
    "Now you can start your node by running following command; \n",
    "\n",
    "```shell\n",
    "$ fedbiomed node --path ./my-node start\n",
    "```\n",
    "\n",
    "Since config file has been configured to enable training plan control mode, you do not need to specify any extra parameter while starting the node. But it is also possible to start node with `FBM_SECURITY_TRAINING_PLAN_APPROVAL=True`, `FBM_SECURITY_ALLOW_DEFAULT_TRAINING_PLANS=True` or `FBM_SECURITY_TRAINING_PLAN_APPROVAL=False`, `FBM_SECURITY_ALLOW_DEFAULT_TRAINING_PLANS=False`. If you start your node with `FBM_SECURITY_TRAINING_PLAN_APPROVAL=False` it will disable training plan control even it is enabled in the config file.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating An Experiment\n",
    "\n",
    "In this section we will be using default MNIST model which has been already registered by the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model is the model that will be sent to the node for training. Since the model files are processed by the Experiment to configure dependencies, import part of the final file might be different from this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the training plan to be used. \n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        loader_arguments = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **loader_arguments)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to get/see the final model file we need to initialize the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, }, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Final Training Plan File From Experiment\n",
    "\n",
    "`training_plan_file()` displays the training plan file that will be sent to the nodes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan_file(display = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `exp.check_training_plan_status()` sends request to the experiment's nodes to check whether the model is approved or not. The nodes that will receive the requests are the nodes that have been found after searching datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = exp.check_training_plan_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs should indicate that the training plan is approved. You can also get status object from the result of the `check_training_plan_status()`. It returns a list of status objects each for different node. Since we have only launched a single node, it returns only one status object. \n",
    "\n",
    "* `approval_obligation` : Indicates whether the training plan control is enabled in the node.  \n",
    "* `status`         : Indicates training plan approval status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Training Plan And Testing Training Plan Approval Status\n",
    "\n",
    "Let's change the training plan network codes and test whether it is approved or not. We will be changing the network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "            self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "            self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we update the training plan class using the setter `set_training_plan_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.set_training_plan_class(MyTrainingPlan, keep_weights=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we changed the model/network structure (we removed dropouts and one dense layer `fc2`) in the experiment, the output of the following method should say that the training plan is not approved by the node and `is_approved` key of the result object should be equal to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = exp.check_training_plan_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training plan is not approved, you won't be able to train your model in the node. The following cell will return an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering and Approving the Training Plan \n",
    "\n",
    "To register/approve the training plan that has been created in the previous section, we can use Fed-BioMed CLI.\n",
    "In Fed-Biomed, there are two ways of approving a model: \n",
    " 1. By sending an `ApprovalRequest` from the researcher to the `Node`\n",
    " 2. By adding it directly to the `Node` through model registration facility\n",
    "\n",
    " \n",
    "### 1. Approving a Training Plan through an `ApprovalRequest`\n",
    "\n",
    "Fed-BioMed 's `Experiment` interface provides a method to submit a training plan to the `Node`, for approval. `Node` can then review the code and approve the training plan using CLI or GUI.\n",
    "\n",
    "The method of `Experiment` sending such request is `training_plan_approve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.training_plan_approve(description=\"my new training plans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training plan has been sent, we need to approve it (or reject it) on `Node` side.\n",
    "\n",
    "Before approving, optionally list models/training plans known to the node with their status (`Approved`, `Pending`, `Rejected`). Your new training plan should appear with `Pending` status and name `my new training plan`.\n",
    "\n",
    "```bash\n",
    "$ fedbiomed node --path ./my-node training-plan list\n",
    "```\n",
    "\n",
    "Then approve the training plan, using the following command on a new terminal:\n",
    "\n",
    "```shell\n",
    "$ fedbiomed node -d my-node training-plan approve\n",
    "```\n",
    "\n",
    "Training plans with both `Pending` or `Rejected` status will be displayed. Select the training plan you have sent to approve it. You might see a message explaining that training plan has successfully been approved.\n",
    "\n",
    "Optionally list again training plans known to the node with their status. Your training plan should now appear with `Approved` status.\n",
    "\n",
    "```bash\n",
    "$ fedbiomed node --path ./my-node training-plan list \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back on the `Researcher` side, let's check it status by running the `check_model_status` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_training_plan_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's status must have changed from `Pending` status to `Approved`, which means model can be trained from now on on the `Node`. `Researcher` can now run an `Experiment` on the `Node`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Registering a Model through Node interface\n",
    "\n",
    "Training plan status must have changed from `Pending` status to `Approved`, which means model can be trained from now on the `Node`. `Researcher` can now run an `Experiment` on the `Node`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `exp.training_plan_file()` is a file path that shows where the final training plan is saved. It also prints the content of the training plan file. You can either get the content of training plan from the output cell or the path where it is saved. Anyway, you need to create a new `txt` file and copy the training plan content in it. You can create new directory in Fed-BioMed called `training_plans` and inside it, you can create new `my-training-plan.txt` file and copy the training plan class content into it.\n",
    "\n",
    "\n",
    "```shell\n",
    "$ mkdir ${FEDBIOMED_DIR}/my_approved_training_plan\n",
    "$ cp <training_plan_path_file> ${FEDBIOMED_DIR}/my_approved_training_plan/my-training-plan.txt\n",
    "```\n",
    "Where `<model_path_file>` is the path of the model that is returned by `exp.training_plan_file(display=False)`\n",
    "\n",
    "Afterward, please run following command in other terminal to register training plan file.\n",
    "\n",
    "```shell\n",
    "$ fedbiomed node --path config-n1.ini training-plan register \n",
    "```\n",
    "\n",
    "You should type a unique name for your training plan e.g. 'MyTestTP-1' and a description. The CLI will ask you select training plan file you want to register. Select the file that you saved and continue.\n",
    "\n",
    "Now, you should be able to train your model defined in the training plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back on the `Researcher` side, you should now be able to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_training_plan_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejecting training plans\n",
    "\n",
    "On `Node` side, it is possible to reject a Model using cli or GUI. Every type of training plan can be `Rejected`, even `Default` models. In Fed-BioMed, `Rejected` means that training plan cannot be trained/executed on the `Node` (but training plan is still `Registered` into the database).\n",
    "\n",
    "Using cli, `Node` can run:\n",
    "\n",
    "```shell\n",
    "$ fedbiomed node --path my-node training-plan reject\n",
    "```\n",
    "\n",
    "and select the training plan to be `Rejected`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.check_training_plan_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
