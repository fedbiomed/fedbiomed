{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYghEGHtzDOB"
   },
   "source": [
    "# Multi-Channel Variational Autoencoder\n",
    "\n",
    "## Goal of this Tutorial\n",
    "This tutorial serves as an example on how to train a model with a custom number of channels. More specifically, it uses a Multi-channel Variational Autoencoder to encode and decode medical data with 5 different modalities.\n",
    "\n",
    "## VAE\n",
    "The Variational Autoencoder is a latent variable model composed by one encoder and one decoder associated to a single channel.\n",
    "The latent distribution and the decoding distribution are implemented as follows:\n",
    "\n",
    "$$q(\\mathbf{z|x}) = \\mathcal{N}(\\mathbf{z|\\mu_x; \\Sigma_x})$$\n",
    "\n",
    "$$p(\\mathbf{x|z}) = \\mathcal{N}(\\mathbf{x|\\mu_z; \\Sigma_z})$$\n",
    "\n",
    "They are Gaussians with moments parametrized by Neural Networks (or a linear transformation layer in a simple case).\n",
    "\n",
    "<img src=\"https://gitlab.inria.fr/epione/flhd/-/raw/master/heterogeneous_data/img/vae.svg\" alt=\"img/vae.svg\">\n",
    "\n",
    "For the variance networks output, it is more common and convenient to use $\\log{\\sigma^2}$. This is due to the fact that neural networks can output any real number, while the variance is strictly positive (${\\sigma^2}>0)$.\n",
    "\n",
    "## MCVAE\n",
    "The last part of this tutorial concerns the use of the *multi-channel variational autoencoder*, a more advanced method for the joint analysis and prediction of several modalities.\n",
    "\n",
    "The MultiChannel VAE is built by stacking multiple VAEs and allowing the decoding distributions to be computed from every input channel.\n",
    "\n",
    "The source code can be found in here: https://gitlab.inria.fr/epione_ML/mcvae\n",
    "\n",
    "<img src=\"https://gitlab.inria.fr/epione/flhd/-/raw/master/heterogeneous_data/img/mcvae.svg\" alt=\"img/mcvae.svg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the Requirements\n",
    "\n",
    "Below, we install the mcvae model, which is necessary for this tutorial. The seaborn library is optionally used for plotting and illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9U9CGgyw_sn",
    "outputId": "e49f5085-7b2e-4adc-e0a2-e9c4a376c9e6"
   },
   "outputs": [],
   "source": [
    "%pip install -q git+https://gitlab.inria.fr/epione_ML/mcvae.git\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVO7EgMk10eK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "The data contains 5 different modalities which are: \n",
    "\n",
    "- Volume: Structural MRI Brain Volumes of the patient.\n",
    "- Demographics: Age, sex and years of education of the patient.\n",
    "- Cognition: Cognitive scores of the patient. It contains scores from Clinical Dementia Rating, Alzheimer's Disease Assessment Scale, Mini-Mental State Examination, Rey Auditory Verbal Learning Test and Functional Activities Questionnaire.\n",
    "- Apoe (Genetic risk): The count of APOE Îµ4 alleles (0, 1 or 2) of the patient, where higher indicates more risk.\n",
    "- Fluid: CerebroSpinal Fluid Biomarkers of the patient, where it contains the baseline values of Amyloid-beta 42 (ABETA), Tau (TAU) and Phospho-tau (PTAU) proteins the patient has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jr5BZDu9putM",
    "outputId": "a847b10c-500c-4e40-9dbb-2d5363e6f4ef"
   },
   "outputs": [],
   "source": [
    "adni = pd.read_csv('https://gitlab.inria.fr/ssilvari/flhd/-/raw/master/heterogeneous_data/pseudo_adni.csv?inline=false')\n",
    "\n",
    "print(f'Loaded {len(adni)} samples.')\n",
    "\n",
    "normalize = lambda x: (x - x.mean(0))/x.std(0)\n",
    "\n",
    "volume_cols = ['WholeBrain.bl', 'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "demog_cols = ['SEX', 'AGE', 'PTEDUCAT']\n",
    "cognition_cols = ['CDRSB.bl', 'ADAS11.bl', 'MMSE.bl', 'RAVLT.immediate.bl', 'RAVLT.learning.bl', 'RAVLT.forgetting.bl', 'FAQ.bl']\n",
    "apoe_cols = ['APOE4']\n",
    "fluid_cols = ['ABETA.MEDIAN.bl', 'PTAU.MEDIAN.bl', 'TAU.MEDIAN.bl']\n",
    "\n",
    "adni_cols = [volume_cols, demog_cols, cognition_cols, apoe_cols, fluid_cols]\n",
    "\n",
    "for cols in adni_cols:\n",
    "  adni[cols] = (adni[cols] - adni[cols].mean())/adni[cols].std()\n",
    "\n",
    "# Creating a list with multimodal data\n",
    "data_adni = [adni[cols].values for cols in adni_cols]\n",
    "\n",
    "# Transform as a pytorch Tensor for compatibility\n",
    "data_adni = [torch.Tensor(_) for _ in data_adni]\n",
    "\n",
    "print(f'We have {len(data_adni)} channels in total as an input for the model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to divide the data into the n number of data centers (hospitals) and leave a certain ratio for each center as holdout for later validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCxTpQAa2H6A",
    "outputId": "c454f450-a247-427d-d740-c4156a056010"
   },
   "outputs": [],
   "source": [
    "train_data_path = f'./data/train'\n",
    "holdout_data_path = f'./data/holdout'\n",
    "\n",
    "def prepare_data_nth_center(n: int, offset: int, n_samples_train: int, n_samples_holdout):\n",
    "  os.makedirs(train_data_path, exist_ok=True)\n",
    "  os.makedirs(holdout_data_path, exist_ok=True)\n",
    "  train_data_df = adni.iloc[offset:offset+n_samples_train,:]\n",
    "  train_data_df.to_csv(train_data_path + '/dataset.csv')\n",
    "  test_data_df = adni.iloc[offset+n_samples_train:offset+n_samples_train+n_samples_holdout,:]\n",
    "  test_data_df.to_csv(holdout_data_path + 'dataset.csv')\n",
    "\n",
    "# Number of centers to divide the data\n",
    "n_centers = 2\n",
    "n_samples_total = len(adni)\n",
    "n_samples_per_center = n_samples_total // n_centers\n",
    "\n",
    "# Holdout ratio\n",
    "holdout_ratio = 0.1\n",
    "\n",
    "n_holdout_samples_per_center = int(n_samples_per_center*holdout_ratio)\n",
    "n_train_samples_per_center = n_samples_per_center - n_holdout_samples_per_center\n",
    "last_offset = 0\n",
    "for i in range(n_centers-1):\n",
    "  prepare_data_nth_center(n=i,\n",
    "                          offset=last_offset,\n",
    "                          n_samples_train=n_train_samples_per_center,\n",
    "                          n_samples_holdout=n_holdout_samples_per_center)\n",
    "  last_offset += n_train_samples_per_center+n_holdout_samples_per_center\n",
    "  print(f'Center {i}: {n_train_samples_per_center} train samples')\n",
    "\n",
    "prepare_data_nth_center(n=n_centers-1,\n",
    "                        offset=last_offset,\n",
    "                        n_samples_train=n_samples_total - last_offset - n_holdout_samples_per_center,\n",
    "                        n_samples_holdout=n_holdout_samples_per_center)\n",
    "print(f'Center {i}: {n_train_samples_per_center} train samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bV92T-kglRt"
   },
   "source": [
    "Add a dataset to the first node (hospital) with the following command\n",
    "```shell\n",
    "fedbiomed node -p CUSTOM/PATH/TO/NODE dataset add\n",
    "```\n",
    "\n",
    "When prompted for data type, select 1) csv\n",
    "```shell\n",
    "Please select the data type that you're configuring:\n",
    "        1) csv\n",
    "        2) default\n",
    "        3) mednist\n",
    "        4) images\n",
    "        5) medical-folder\n",
    "        6) flamby\n",
    "select: 1\n",
    "```\n",
    "\n",
    "For name and description you may input whatever you want.\n",
    "\n",
    "For `tags` it is **VERY important** to input `adni-train`\n",
    "The Experiment will later search for the available data using the tag(s) provided.\n",
    "\n",
    "For the path of the file, input\n",
    "\n",
    "```shell\n",
    "/PATH/TO/NODE/data/train/dataset.csv\n",
    "```\n",
    "\n",
    "Likewise, return all the same steps for the N number of nodes that you want to add.\n",
    "\n",
    "```shell\n",
    "fedbiomed node -p CUSTOM/PATH/TO/NODE_N dataset add\n",
    "```\n",
    "```shell\n",
    "/PATH/TO/NODE_N/data/train/dataset.csv\n",
    "```\n",
    "\n",
    "Finally. start the nodes using the command:\n",
    "\n",
    "```shell\n",
    "fedbiomed node -p CUSTOM/PATH/TO/NODE start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Training Plan\n",
    "\n",
    "To train our custom mcvae, we should initialize the model in the init_model function, and use a Dataset class wrapper around our data in the training_data function. To do both, we define an auxiliary function get_channels to customize and specify the channels our data has. \n",
    "\n",
    "Next, we define our second helper function to create the 5 channels we have as Torch Tensors. We initialize the model and it's parameters. We create a dummy data, again with 5 channels to initialize the dimensionality of our model.\n",
    "\n",
    "For the training_data function, we inherit from the Dataset class and create our own Dataset class. This is especially done to override the __getitem__ function which is fundamental for our training plan. It defines what data item would be retrieved at each training step to train one sample during the training loop. These samples are then batched according to the batch_size parameter.\n",
    "\n",
    "Finally, the training step computes the loss by using:\n",
    "\n",
    "- q: The approximate posterior value $q(z|x)$ the encoder calculates from the (generally Gaussian) distribution of the data over the latent variable z.\n",
    "- x: The input data in tensor format.\n",
    "- p: The likelihood value $p(x|z)$ the decoder calculates by reconstructing from z.\n",
    "- KL: KL divergence\n",
    "- LL: Log likelihood\n",
    "\n",
    "The loss is calculated as the difference of kl to ll. Their formulas can be seen below:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{KL}} = \\frac{1}{2} \\sum_{i=1}^c \\left( \\mu_i^2 + \\sigma_i^2 - \\ln \\sigma_i^2 - 1 \\right)$$\n",
    "\n",
    "$$\\mathcal{L}_{\\text{LL}} = -\\frac{1}{2\\sigma^2} \\| x - \\hat{x} \\|^2 + \\text{const}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Warning\n",
    "\n",
    "The mcvae module tries to detect and utilize the gpu in the system by default. If that is not preferred, the DEVICE variable can be set to cpu as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcvae.gpu import DEVICE\n",
    "print(DEVICE)\n",
    "\n",
    "# DEVICE = torch.device('cpu')\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z03QxQYPz85z"
   },
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "\n",
    "class MCVAETrainingPlan(TorchTrainingPlan):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_channels():\n",
    "      channel_1 = ['WholeBrain.bl', 'Ventricles.bl', 'Hippocampus.bl', 'MidTemp.bl', 'Entorhinal.bl']\n",
    "      channel_2 = ['SEX', 'AGE', 'PTEDUCAT']\n",
    "      channel_3 = ['CDRSB.bl', 'ADAS11.bl', 'MMSE.bl', 'RAVLT.immediate.bl', 'RAVLT.learning.bl', 'RAVLT.forgetting.bl', 'FAQ.bl']\n",
    "      channel_4 = ['APOE4']\n",
    "      channel_5 = ['ABETA.MEDIAN.bl', 'PTAU.MEDIAN.bl', 'TAU.MEDIAN.bl']\n",
    "      return channel_1, channel_2, channel_3, channel_4, channel_5\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data_as_multichannel_tensor_dataset(df):\n",
    "      \"\"\"Takes a dataframe, splits it into multiple channels and parse each channel as a tensor\"\"\"\n",
    "      channel_1, channel_2, channel_3, channel_4, channel_5 = MCVAETrainingPlan.get_channels()\n",
    "\n",
    "      df = (df - df.mean())/df.std()\n",
    "      def as_tensor(cols):\n",
    "          tensor = torch.tensor(df[cols].values).float()\n",
    "          return tensor\n",
    "\n",
    "      return [as_tensor(channel_1), as_tensor(channel_2), as_tensor(channel_3), as_tensor(channel_4), as_tensor(channel_5)]\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "      channels = MCVAETrainingPlan.get_channels()\n",
    "      dummy_data = [torch.zeros((1, len(ch))).to('cpu') for ch in channels]\n",
    "      # print(dummy_data[0].device)\n",
    "      vaeclass = VAE\n",
    "      return Mcvae(data=dummy_data,\n",
    "                   lat_dim=model_args.get('lat_dim', 1),\n",
    "                   vaeclass=vaeclass,\n",
    "                   sparse=model_args.get('sparse', False))\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        optimizer = Adam(self.model().parameters(), lr=optimizer_args.get('lr', 0.001))\n",
    "        return optimizer\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        deps = [\n",
    "            'from mcvae.models import Mcvae, ThreeLayersVAE, VAE',\n",
    "            'from torch.optim import Adam',\n",
    "            'from torchvision import datasets, transforms',\n",
    "            'from torch.utils.data import Dataset',\n",
    "            'from fedbiomed.common.logger import logger',\n",
    "            'import numpy as np',\n",
    "            'import pandas as pd']\n",
    "        return deps\n",
    "\n",
    "    def training_data(self):\n",
    "        df = pd.read_csv(self.dataset_path)\n",
    "        class myDataset(Dataset):\n",
    "          def __init__(self, data):\n",
    "            self._data = data\n",
    "          def __len__(self):\n",
    "            return len(self._data)\n",
    "          def __getitem__(self, idx):\n",
    "            df_ = self._data.iloc[idx,:]\n",
    "            return MCVAETrainingPlan.get_data_as_multichannel_tensor_dataset(df_), []\n",
    "        return DataManager(myDataset(df))\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "      output = self.model().forward(data)\n",
    "      q = output['q']\n",
    "      x = output['x']\n",
    "      p = output['p']\n",
    "      \n",
    "      kl = self.model().compute_kl(q)\n",
    "      kl *= self.model().beta\n",
    "      ll = self.model().compute_ll(p=p, x=x)\n",
    "      \n",
    "      return kl - ll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the model arguments for MCVAE and the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA4VYvr0AVeo"
   },
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'lat_dim': 1,\n",
    "    'sparse': False\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 64, },\n",
    "    'optimizer_args': {'lr': 1e-4},\n",
    "    'num_updates': 50,\n",
    "    'log_interval': 25,\n",
    "    'test_ratio': 0.0,\n",
    "    'test_on_global_updates': False,\n",
    "    'test_on_local_updates': False,\n",
    "    'random_seed': 424242,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an experiment. We select Federated Averaging as aggregator method and use the tags that we initially used on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "gELa1aRnAtrM",
    "outputId": "0f0b5ea5-5ec6-4b22-af5b-da6740b99a1d"
   },
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.federated_workflows import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "tags =  ['adni-train']\n",
    "num_rounds = 50\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MCVAETrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=num_rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 tensorboard=True\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "SZ3-F0gsdSMv",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from fedbiomed.researcher.config import config\n",
    "tensorboard_dir = './tensorboard_results'\n",
    "\n",
    "%tensorboard --logdir \"$tensorboard_dir\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m58dffVeA1mg",
    "outputId": "6e853777-a00c-4d7e-9a77-f1a2e8368003",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import some additional libraries for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9XwXpi-xNf9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4iTh3pAxNly"
   },
   "outputs": [],
   "source": [
    "decoding_weights_dict = {k: w.detach().numpy() for k, w in aggregated_model.state_dict().items() if 'W_out.weight' in k}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the Z values for Volume biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "X2SLUHJhycCb",
    "outputId": "0def64f2-5563-4b11-91f7-a1f6a30af49d"
   },
   "outputs": [],
   "source": [
    "lat_dim_names = [f'$Z_{{{i}}}$' for i in range(model_args['lat_dim'])]\n",
    "col_names = lat_dim_names + [\"biomarker\"]\n",
    "weights = pd.DataFrame()\n",
    "\n",
    "channels = MCVAETrainingPlan.get_channels()\n",
    "\n",
    "for channel_i, weights_i in enumerate(decoding_weights_dict.values()):\n",
    "\n",
    "    channel_df = pd.DataFrame(np.concatenate((weights_i, np.array(channels[channel_i]).reshape(-1, 1)), axis=1),\n",
    "        columns=lat_dim_names + [\"biomarker\"])\n",
    "    channel_df['channel'] = channel_i + 1\n",
    "\n",
    "\n",
    "    weights = pd.concat((weights, channel_df))\n",
    "\n",
    "weights[\"$Z_{0}$\"] = weights[\"$Z_{0}$\"].astype('float32')\n",
    "weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "V9_durGDmnQM",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "e98722e2-1af9-4ca6-8dc8-11c06b22990a"
   },
   "outputs": [],
   "source": [
    "weights_melt = weights.melt(id_vars=['biomarker', 'channel'], var_name='latent_var')\n",
    "weights_melt.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AcQEYVV9m7zm",
    "outputId": "96319fc9-3ad4-40e1-8a40-54f2c7786edf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(data=weights_melt, x='biomarker', y='value', hue='latent_var', kind='bar', col='channel', col_wrap=1, aspect=2.5, sharex=False, palette='Blues_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present two alternative methods for prediction.\n",
    "\n",
    "The first one is to predict a channel/modality from the whole data.\n",
    "\n",
    "The second is to predict a channel from a specific channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmY5RZWQm_TL"
   },
   "outputs": [],
   "source": [
    "# Predict volumes (channel 0) from cognition (channel 2)\n",
    "\n",
    "# Solution 1\n",
    "\n",
    "with torch.no_grad():\n",
    "  # Encode everything\n",
    "  q = aggregated_model.encode(data_adni)\n",
    "  # Take the mean of every encoded distribution q\n",
    "  z = [qi.loc for qi in q]\n",
    "  # Decode all\n",
    "  p = aggregated_model.decode(z)\n",
    "  # Extract what you need: p(x|z) or p[x][z] or p[decoder output channel][encoder input chanenl]\n",
    "  decoding_volume_from_cognition = p[0][2].loc.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "W1gQ7osPAJ1f",
    "outputId": "ab65b0b1-0e31-4fdc-ed17-f0d41533cbc8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 28))\n",
    "\n",
    "for i in range(len(volume_cols)):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.scatter(decoding_volume_from_cognition[:,i], data_adni[0][:,i])\n",
    "    plt.title('reconstruction ' + volume_cols[i])\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the Volume from Cognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoyTW75CpVKb"
   },
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "\n",
    "# Encode the cognition (ch 2)\n",
    "q2 = aggregated_model.vae[2].encode(data_adni[2])\n",
    "# Take the mean of q (location in pytorch jargon)\n",
    "z2 = q2.loc\n",
    "# Decode through the brain volumes decoder (ch 0)\n",
    "p0 = aggregated_model.vae[0].decode(z2)\n",
    "# Take the mean\n",
    "decoding_volume_from_cognition = p0.loc.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z3IBsD0AA25j",
    "outputId": "dbba6643-99d9-4edd-ac53-003c81c3b307"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 28))\n",
    "\n",
    "for i in range(len(volume_cols)):\n",
    "    plt.subplot(5,1,i+1)\n",
    "    plt.scatter(decoding_volume_from_cognition[:,i], data_adni[0][:,i])\n",
    "    plt.title('reconstruction ' + volume_cols[i])\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEpmv-CZA7Y-"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'training_args': {\n",
    "        'num_rounds': training_args['num_rounds'],\n",
    "        'num_updates': training_args['num_updates'],\n",
    "        'loader_args': training_args['loader_args'],\n",
    "        'optimizer_args': training_args['optimizer_args'], \n",
    "        'model_args': training_args['model_args'],\n",
    "    }\n",
    "}, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
